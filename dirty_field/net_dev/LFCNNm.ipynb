{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-27 23:13:29.387037: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-08-27 23:13:29.387064: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import sys\n",
    "import os\n",
    "current_dir = os.path.dirname(os.path.abspath('./'))\n",
    "if not current_dir in sys.path:\n",
    "    sys.path.append(current_dir)\n",
    "current_dir = os.path.dirname(os.path.abspath('../'))\n",
    "if not current_dir in sys.path:\n",
    "    sys.path.append(current_dir)\n",
    "\n",
    "from utils.structures import Pipeline, Deploy\n",
    "from utils.data_management import dict2str\n",
    "from utils.machine_learning import one_hot_encoder, one_hot_decoder\n",
    "from typing import *\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import make_classification\n",
    "import mne\n",
    "from combiners import EpochsCombiner\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from utils.machine_learning.designer import ModelDesign, ParallelDesign, LayerDesign\n",
    "from utils.machine_learning.analyzer import ModelAnalyzer, LFCNNAnalyzer\n",
    "from mne.datasets import multimodal\n",
    "import sklearn\n",
    "import mneflow as mf\n",
    "import tensorflow as tf\n",
    "from mneflow.layers import DeMixing, LFTConv, TempPooling, Dense\n",
    "from mneflow.models import BaseModel\n",
    "import mneflow\n",
    "import logging\n",
    "from time import perf_counter\n",
    "\n",
    "logger= logging.getLogger(__name__)\n",
    "logging.root.handlers = []\n",
    "logger.setLevel(logging.NOTSET)\n",
    "logging.basicConfig(\n",
    "    format='%(asctime)s, %(name)s %(levelname)s %(message)s',\n",
    "    datefmt='%H:%M:%S',\n",
    "    level=logging.DEBUG,\n",
    "    handlers=[\n",
    "        logging.FileHandler('./history.log'),\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# %matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Deconw(tf.keras.layers.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        units=32,\n",
    "        kernel_size=(4, 10),\n",
    "        strides=(1, 1),\n",
    "        padding='valid',\n",
    "        output_padding=None,\n",
    "        data_format=None,\n",
    "        dilation_rate=(1, 1),\n",
    "        activation=None,\n",
    "        use_bias=True,\n",
    "        kernel_initializer='glorot_uniform',\n",
    "        bias_initializer='zeros',\n",
    "        kernel_regularizer=None,\n",
    "        bias_regularizer=None,\n",
    "        activity_regularizer=None,\n",
    "        kernel_constraint=None,\n",
    "        bias_constraint=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.units = units\n",
    "        self.kernel_size = kernel_size\n",
    "        self.strides = strides\n",
    "        self.padding = padding\n",
    "        self.output_padding = output_padding\n",
    "        self.data_format = data_format\n",
    "        self.dilation_rate = dilation_rate\n",
    "        self.activation = activation\n",
    "        self.use_bias = use_bias\n",
    "        self.kernel_initializer = kernel_initializer\n",
    "        self.bias_initializer = bias_initializer\n",
    "        self.kernel_regularizer = kernel_regularizer\n",
    "        self.bias_regularizer = bias_regularizer\n",
    "        self.activity_regularizer = activity_regularizer\n",
    "        self.kernel_constraint = kernel_constraint\n",
    "        self.bias_constraint = bias_constraint\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.n_channels = input_shape[-1]\n",
    "        self.deconws = self.deconv_constructor(self.n_channels)\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        self.build(inputs.shape)\n",
    "        outputs = []\n",
    "        for i in range(self.n_channels):\n",
    "            input_ = tf.expand_dims(inputs[:, :, :, i], axis=3)\n",
    "            outputs.append(self.deconws[i](input_))\n",
    "        return tf.transpose(tf.stack(outputs), (1, 0, 2, 3, 4))\n",
    "\n",
    "    def deconv_constructor(self, n_channels):\n",
    "        return [\n",
    "            tf.keras.layers.Conv2DTranspose(\n",
    "                filters=1,\n",
    "                kernel_size=self.kernel_size,\n",
    "                strides=self.strides,\n",
    "                padding=self.padding,\n",
    "                output_padding=self.output_padding,\n",
    "                data_format=self.data_format,\n",
    "                dilation_rate=self.dilation_rate,\n",
    "                activation=self.activation,\n",
    "                use_bias=self.use_bias,\n",
    "                kernel_initializer=self.kernel_initializer,\n",
    "                bias_initializer=self.bias_initializer,\n",
    "                kernel_regularizer=self.kernel_regularizer,\n",
    "                bias_regularizer=self.bias_regularizer,\n",
    "                activity_regularizer=self.activity_regularizer,\n",
    "                kernel_constraint=self.kernel_constraint,\n",
    "                bias_constraint=self.bias_constraint,\n",
    "                **self.kwargs\n",
    "            )\n",
    "        for _ in range(n_channels)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne.set_log_level(verbose='CRITICAL')\n",
    "fname_raw = os.path.join(multimodal.data_path(), 'multimodal_raw.fif')\n",
    "raw = mne.io.read_raw_fif(fname_raw)\n",
    "cond = raw.acqparser.get_condition(raw, None)\n",
    "condition_names = [k for c in cond for k,v in c['event_id'].items()]\n",
    "epochs_list = [mne.Epochs(raw, **c) for c in cond]\n",
    "epochs = mne.concatenate_epochs(epochs_list)\n",
    "epochs = epochs.pick_types(meg='grad')\n",
    "X = np.array([])\n",
    "Y = list()\n",
    "for i, epochs in enumerate(epochs_list):\n",
    "    data = epochs.get_data()\n",
    "    if i == 0:\n",
    "        X = data.copy()\n",
    "    else:\n",
    "        X = np.append(X, data, axis=0)\n",
    "    Y += [i for _ in range(data.shape[0])]\n",
    "\n",
    "Y = np.array(Y)\n",
    "X = np.array([X[i, epochs._channel_type_idx['grad'], :] for i, _ in enumerate(X)])\n",
    "original_X = X.copy()\n",
    "original_Y = Y.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(940, 1, 361, 204)\n",
      "importing from tuple\n",
      "input shapes: X- (940, 204, 361) targets- (940, 1)\n",
      "Preprocessing:\n",
      "Scaling to interval 0.0 - 60.0\n",
      "Splitting sets\n",
      "Preprocessed: (940, 1, 361, 204) (940, 8) folds: 5 x 188\n",
      "940\n",
      "Prepocessed sample shape: (1, 361, 204)\n",
      "Target shape actual/metadata:  (8,) (8,)\n",
      "Saving TFRecord# 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-27 23:14:20.429734: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-08-27 23:14:20.429769: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-08-27 23:14:20.429787: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (arcolinux-machine): /proc/driver/nvidia/version does not exist\n",
      "2022-08-27 23:14:20.430040: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import_opt = dict(savepath='../tfr/',\n",
    "    out_name='mne_sample_epochs',\n",
    "    fs=600,\n",
    "    input_type='trials',\n",
    "    target_type='int',\n",
    "    picks={'meg':'grad'},\n",
    "    scale=True,  # apply baseline_scaling\n",
    "    crop_baseline=True,  # remove baseline interval after scaling\n",
    "    decimate=None,\n",
    "    scale_interval=(0, 60),  # indices in time axis corresponding to baseline interval\n",
    "    n_folds=5,\n",
    "    overwrite=True,\n",
    "    segment=False,\n",
    ")\n",
    "\n",
    "specs = dict()\n",
    "specs.setdefault('filter_length', 7)\n",
    "specs.setdefault('n_latent', 4)\n",
    "specs.setdefault('pooling', 10)\n",
    "specs.setdefault('stride', 2)\n",
    "specs.setdefault('padding', 'SAME')\n",
    "specs.setdefault('pool_type', 'max')\n",
    "specs.setdefault('nonlin', tf.nn.relu)\n",
    "specs.setdefault('l1', 3e-4)\n",
    "specs.setdefault('l2', 0)\n",
    "specs.setdefault('l1_scope', ['fc', 'dmx', 'tconv', 'fc'])\n",
    "specs.setdefault('l2_scope', [])\n",
    "specs.setdefault('maxnorm_scope', [])\n",
    "specs.setdefault('dropout', .5)\n",
    "\n",
    "specs['filter_length'] = 17\n",
    "specs['pooling'] = 5\n",
    "specs['stride'] = 5\n",
    "specs['l1'] = 3e-3\n",
    "out_dim = len(np.unique(original_Y))\n",
    "Y = original_Y.copy()\n",
    "Y = one_hot_encoder(Y)\n",
    "X = original_X.copy()\n",
    "X = np.transpose(np.expand_dims(X, axis = 1), (0, 1, 3, 2))\n",
    "print(X.shape)\n",
    "n_samples, _, n_times, n_channels = X.shape\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(original_X, original_Y, train_size=.85)\n",
    "\n",
    "# write TFRecord files and metadata file to disk\n",
    "meta = mneflow.produce_tfrecords((original_X, original_Y), **import_opt)\n",
    "dataset = mneflow.Dataset(meta, train_batch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting reg for fc, to l1\n"
     ]
    }
   ],
   "source": [
    "lfcnnd = ModelDesign(\n",
    "    None,\n",
    "    DeMixing(\n",
    "        size=specs['n_latent'],\n",
    "        nonlin=tf.identity,\n",
    "        axis=3, specs=specs\n",
    "    ),\n",
    "    LFTConv(\n",
    "        size=specs['n_latent'],\n",
    "        nonlin=specs['nonlin'],\n",
    "        filter_length=specs['filter_length'],\n",
    "        padding=specs['padding'],\n",
    "        specs=specs\n",
    "    ),\n",
    "    TempPooling(\n",
    "        pooling=specs['pooling'],\n",
    "        pool_type=specs['pool_type'],\n",
    "        stride=specs['stride'],\n",
    "        padding=specs['padding'],\n",
    "    ),\n",
    "    tf.keras.layers.Dropout(specs['dropout'], noise_shape=None),\n",
    "    Dense(size=out_dim, nonlin=tf.identity, specs=specs)\n",
    ")\n",
    "\n",
    "class ZubarevNet(BaseModel):\n",
    "    def __init__(self, Dataset, specs=dict(), design=lfcnnd, design_name='design'):\n",
    "        self.scope = design_name\n",
    "        self.design = design\n",
    "        specs.setdefault('filter_length', 7)\n",
    "        specs.setdefault('n_latent', 4)\n",
    "        specs.setdefault('pooling', 4)\n",
    "        specs.setdefault('stride', 4)\n",
    "        specs.setdefault('padding', 'SAME')\n",
    "        specs.setdefault('pool_type', 'max')\n",
    "        specs.setdefault('nonlin', tf.nn.relu)\n",
    "        specs.setdefault('l1', 3e-4)\n",
    "        specs.setdefault('l2', 0)\n",
    "        specs.setdefault('l1_scope', ['fc', 'demix', 'lf_conv'])\n",
    "        specs.setdefault('l2_scope', [])\n",
    "        specs.setdefault('maxnorm_scope', [])\n",
    "\n",
    "        super().__init__(Dataset, specs)\n",
    "\n",
    "    def build_graph(self):\n",
    "        return self.design(self.inputs)\n",
    "\n",
    "    def set_design(self, design: ModelDesign):\n",
    "        self.design = design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting reg for fc, to l1\n",
      "Setting reg for fc, to l1\n",
      "Setting reg for fc, to l1\n"
     ]
    }
   ],
   "source": [
    "simplenetd = ModelDesign(\n",
    "    tf.keras.Input(shape=(1, n_times, n_channels)),\n",
    "    DeMixing(\n",
    "        size=specs['n_latent'],\n",
    "        nonlin=tf.identity,\n",
    "        axis=3, specs=specs\n",
    "    ),\n",
    "    LFTConv(\n",
    "        size=specs['n_latent'],\n",
    "        nonlin=specs['nonlin'],\n",
    "        filter_length=specs['filter_length'],\n",
    "        padding=specs['padding'],\n",
    "        specs=specs\n",
    "    ),\n",
    "    LFTConv(\n",
    "        size=specs['n_latent'],\n",
    "        nonlin=specs['nonlin'],\n",
    "        filter_length=specs['filter_length'],\n",
    "        padding=specs['padding'],\n",
    "        specs=specs\n",
    "    ),\n",
    "    LayerDesign(\n",
    "        lambda X: X[:, :, ::2, :]\n",
    "    ),\n",
    "    tf.keras.layers.Dropout(specs['dropout'], noise_shape=None),\n",
    "    Dense(size=out_dim, nonlin=tf.identity, specs=specs)\n",
    ")\n",
    "\n",
    "lfrnnd = ModelDesign(\n",
    "    None,\n",
    "    LayerDesign(tf.squeeze, axis=1),\n",
    "    tf.keras.layers.Bidirectional(\n",
    "        tf.keras.layers.LSTM(\n",
    "            specs['n_latent'],\n",
    "            bias_regularizer='l1',\n",
    "            return_sequences=True,\n",
    "            kernel_regularizer=tf.keras.regularizers.L1(.01),\n",
    "            recurrent_regularizer=tf.keras.regularizers.L1(.01),\n",
    "            dropout=0.4,\n",
    "            recurrent_dropout=0.4,\n",
    "        ),\n",
    "        merge_mode='sum'\n",
    "    ),\n",
    "    LayerDesign(tf.expand_dims, axis=1),\n",
    "    LFTConv(\n",
    "        size=specs['n_latent'],\n",
    "        nonlin=specs['nonlin'],\n",
    "        filter_length=specs['filter_length'],\n",
    "        padding=specs['padding'],\n",
    "        specs=specs\n",
    "    ),\n",
    "    TempPooling(\n",
    "        pooling=specs['pooling'],\n",
    "        pool_type=specs['pool_type'],\n",
    "        stride=specs['stride'],\n",
    "        padding=specs['padding'],\n",
    "    ),\n",
    "    tf.keras.layers.Dropout(specs['dropout'], noise_shape=None),\n",
    "    Dense(size=out_dim, nonlin=tf.identity, specs=specs)\n",
    ")\n",
    "\n",
    "\n",
    "# newnetd = ModelDesign(\n",
    "#     tf.keras.Input(shape=(1, n_times, n_channels)),\n",
    "#     Deconw(kernel_size=(specs['n_latent'], specs['filter_length']), activation='relu', kernel_regularizer='l1'),\n",
    "#     tf.keras.layers.Conv2D(1, (1, specs['filter_length']), activation='relu', kernel_regularizer='l2'),\n",
    "#     LayerDesign(\n",
    "#         lambda X: tf.transpose(tf.squeeze(X, axis=-1), (0, 2, 3, 1))\n",
    "#     ),\n",
    "#     tf.keras.layers.Conv2D(1, (1, 204), padding='same'),\n",
    "#     LayerDesign(\n",
    "#         lambda X: tf.transpose(X, (0, 3, 2, 1))\n",
    "#     ),\n",
    "#     LayerDesign(\n",
    "#         lambda X: X[:, :, ::specs['pooling'], :]\n",
    "#     ),\n",
    "#     tf.keras.layers.Dropout(specs['dropout'], noise_shape=None),\n",
    "#     Dense(size=out_dim, nonlin=tf.identity, specs=specs)\n",
    "# )\n",
    "\n",
    "# newnetd = ModelDesign(\n",
    "#     tf.keras.Input(shape=(1, n_times, n_channels)),\n",
    "#     Deconw(kernel_size=(specs['n_latent'], specs['filter_length']), activation='relu', kernel_regularizer='l1'),\n",
    "#     tf.keras.layers.Conv2D(1, (1, specs['filter_length']), activation='relu'),\n",
    "#     LayerDesign(\n",
    "#         lambda X: tf.transpose(tf.squeeze(X, axis=-1), (0, 1, 3, 2))\n",
    "#     ),\n",
    "#     tf.keras.layers.DepthwiseConv2D((204, 1), kernel_regularizer='l1'),\n",
    "#     LayerDesign(\n",
    "#         lambda X: X[:, :, ::2, :]\n",
    "#     ),\n",
    "#     tf.keras.layers.Dropout(specs['dropout'], noise_shape=None),\n",
    "#     Dense(size=out_dim, nonlin=tf.identity, specs=specs)\n",
    "# )\n",
    "\n",
    "newnetd = ModelDesign(\n",
    "    tf.keras.Input(shape=(1, n_times, n_channels)),\n",
    "    Deconw(kernel_size=(specs['n_latent'], specs['filter_length']), activation='relu', kernel_regularizer='l1'),\n",
    "    LayerDesign(\n",
    "        lambda X: tf.transpose(tf.squeeze(X, axis=-1), (0, 1, 3, 2))\n",
    "    ),\n",
    "    tf.keras.layers.DepthwiseConv2D((1, specs['filter_length']), activation='relu', depthwise_regularizer='l1'),\n",
    "    tf.keras.layers.DepthwiseConv2D((n_channels, 1), name='demixing'),\n",
    "    LayerDesign(\n",
    "        lambda X: X[:, :, ::2, :]\n",
    "    ),\n",
    "    tf.keras.layers.Dropout(specs['dropout'], noise_shape=None),\n",
    "    Dense(size=out_dim, nonlin=tf.identity, specs=specs)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built: fc input: (None, 1, 181, 4)\n",
      "Input shape: (1, 361, 204)\n",
      "y_pred: (None, 8)\n",
      "Initialization complete!\n",
      "Epoch 1/25\n",
      "100/100 - 250s - loss: 15.5052 - cat_ACC: 0.1535 - val_loss: 13.6132 - val_cat_ACC: 0.1223 - 250s/epoch - 3s/step\n",
      "Epoch 2/25\n"
     ]
    }
   ],
   "source": [
    "# model = ZubarevNet(dataset, specs, lfcnnd, 'lfcnn')\n",
    "model = ZubarevNet(dataset, specs, newnetd, 'new')\n",
    "model.build()\n",
    "t1 = perf_counter()\n",
    "model.train(n_epochs=25, eval_step=100, early_stopping=5)\n",
    "runtime = perf_counter() - t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-28 10:15:07.321252: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 276901440 exceeds 10% of free system memory.\n",
      "2022-08-28 10:15:07.670907: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 276901440 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No dataset specified using validation dataset (Default)\n",
      "10:15:24, root INFO new performance:\n",
      "\truntime:  6214.2000\n",
      "\ttrain-set: 0.8680851063829788\n",
      "\ttest-set: 0.7712765957446809\n"
     ]
    }
   ],
   "source": [
    "y_true_train, y_pred_train = model.predict(meta['train_paths'])\n",
    "y_true_test, y_pred_test = model.predict(meta['test_paths'])\n",
    "runtime=103.57*60\n",
    "logging.info(\n",
    "    f'{model.scope} performance:\\n'\n",
    "    f'\\truntime: {runtime : .4f}\\n'\n",
    "    f'\\ttrain-set: {sklearn.metrics.accuracy_score(one_hot_decoder(y_true_train), one_hot_decoder(y_pred_train))}\\n'\n",
    "    f'\\ttest-set: {sklearn.metrics.accuracy_score(one_hot_decoder(y_true_test), one_hot_decoder(y_pred_test))}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting reg for fc, to l1\n",
      "input_shape:  (1, 361, 204)\n",
      "Built: fc input: (None, 1, 181, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 8])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples, _, n_times, n_channels = (940, 1, 361, 204)\n",
    "out_dim=8\n",
    "\n",
    "# newnetd = ModelDesign(\n",
    "#     tf.keras.Input(shape=(1, n_times, n_channels)),\n",
    "#     Deconw(kernel_size=(specs['n_latent'], specs['filter_length']), activation='relu', kernel_regularizer='l1'),\n",
    "#     tf.keras.layers.Conv2D(1, (1, specs['filter_length']), activation='relu', kernel_regularizer='l2'),\n",
    "#     LayerDesign(\n",
    "#         lambda X: tf.transpose(tf.squeeze(X, axis=-1), (0, 1, 3, 2))\n",
    "#     ),\n",
    "#     # TensorShape([None, 4, 361, 204])\n",
    "#     tf.keras.layers.Conv2D(1, (204, 1), padding='valid', name='demixing'),\n",
    "#     # LayerDesign(\n",
    "#     #     lambda X: tf.transpose(X, (0, 3, 2, 1))\n",
    "#     # ),\n",
    "#     # LayerDesign(\n",
    "#     #     lambda X: X[:, :, ::specs['pooling'], :]\n",
    "#     # ),\n",
    "#     # tf.keras.layers.Dropout(specs['dropout'], noise_shape=None),\n",
    "#     # Dense(size=out_dim, nonlin=tf.identity, specs=specs)\n",
    "# )\n",
    "\n",
    "# newnetd = ModelDesign(\n",
    "#     tf.keras.Input(shape=(1, n_times, n_channels)),\n",
    "#     Deconw(kernel_size=(4, 10)),\n",
    "#     tf.keras.layers.Conv2D(1, (1, 10)),\n",
    "#     LayerDesign(\n",
    "#         lambda X: tf.transpose(tf.squeeze(X, axis=-1), (0, 1, 3, 2))\n",
    "#     ),\n",
    "#     tf.keras.layers.DepthwiseConv2D((204, 1), name='demixing'),\n",
    "#     LayerDesign(\n",
    "#         lambda X: X[:, :, ::2, :]\n",
    "#     ),\n",
    "#     tf.keras.layers.Dropout(specs['dropout'], noise_shape=None),\n",
    "#     Dense(size=out_dim, nonlin=tf.identity, specs=specs)\n",
    "# )\n",
    "\n",
    "\n",
    "newnetd = ModelDesign(\n",
    "    tf.keras.Input(shape=(1, n_times, n_channels)),\n",
    "    Deconw(kernel_size=(4, 10)),\n",
    "    LayerDesign(\n",
    "        lambda X: tf.transpose(tf.squeeze(X, axis=-1), (0, 1, 3, 2))\n",
    "    ),\n",
    "    tf.keras.layers.DepthwiseConv2D((1, 10)),\n",
    "    tf.keras.layers.DepthwiseConv2D((204, 1), name='demixing'),\n",
    "    LayerDesign(\n",
    "        lambda X: X[:, :, ::2, :]\n",
    "    ),\n",
    "    tf.keras.layers.Dropout(specs['dropout'], noise_shape=None),\n",
    "    Dense(size=out_dim, nonlin=tf.identity, specs=specs)\n",
    ")\n",
    "\n",
    "\n",
    "print('input_shape: ', (1, n_times, n_channels))\n",
    "newnetd().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = tf.keras.Input(shape=(1, n_times, n_channels))\n",
    "model = tf.keras.Model(inp, newnetd(inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmx = model.get_layer('demixing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'demixing/depthwise_kernel:0' shape=(204, 1, 4, 1) dtype=float32, numpy=\n",
       " array([[[[ 0.031633  ],\n",
       "          [ 0.04099584],\n",
       "          [-0.00537659],\n",
       "          [ 0.04578142]]],\n",
       " \n",
       " \n",
       "        [[[-0.02466786],\n",
       "          [-0.05742272],\n",
       "          [-0.03772743],\n",
       "          [ 0.00679388]]],\n",
       " \n",
       " \n",
       "        [[[ 0.02253095],\n",
       "          [-0.02841793],\n",
       "          [-0.03629241],\n",
       "          [-0.00137744]]],\n",
       " \n",
       " \n",
       "        [[[-0.02788217],\n",
       "          [ 0.01266242],\n",
       "          [-0.00487591],\n",
       "          [-0.03959247]]],\n",
       " \n",
       " \n",
       "        [[[-0.0184562 ],\n",
       "          [ 0.06493163],\n",
       "          [ 0.00136462],\n",
       "          [-0.03449699]]],\n",
       " \n",
       " \n",
       "        [[[ 0.02535935],\n",
       "          [-0.0728882 ],\n",
       "          [-0.05114057],\n",
       "          [ 0.00465818]]],\n",
       " \n",
       " \n",
       "        [[[-0.04673408],\n",
       "          [-0.03232426],\n",
       "          [-0.02720003],\n",
       "          [-0.00286223]]],\n",
       " \n",
       " \n",
       "        [[[ 0.02021289],\n",
       "          [-0.02026704],\n",
       "          [-0.02710452],\n",
       "          [-0.01228148]]],\n",
       " \n",
       " \n",
       "        [[[-0.06937988],\n",
       "          [ 0.06833906],\n",
       "          [-0.04465036],\n",
       "          [-0.00226984]]],\n",
       " \n",
       " \n",
       "        [[[ 0.03424645],\n",
       "          [ 0.01678351],\n",
       "          [ 0.00301794],\n",
       "          [-0.04654434]]],\n",
       " \n",
       " \n",
       "        [[[ 0.01759022],\n",
       "          [-0.0262292 ],\n",
       "          [ 0.04873307],\n",
       "          [-0.05982941]]],\n",
       " \n",
       " \n",
       "        [[[-0.05769733],\n",
       "          [ 0.06692398],\n",
       "          [-0.01131625],\n",
       "          [-0.07049779]]],\n",
       " \n",
       " \n",
       "        [[[-0.02758934],\n",
       "          [ 0.05837326],\n",
       "          [-0.05182146],\n",
       "          [-0.04961555]]],\n",
       " \n",
       " \n",
       "        [[[ 0.05720507],\n",
       "          [ 0.0684514 ],\n",
       "          [ 0.06256717],\n",
       "          [ 0.02424463]]],\n",
       " \n",
       " \n",
       "        [[[-0.03246762],\n",
       "          [-0.0498978 ],\n",
       "          [-0.00828964],\n",
       "          [-0.04195514]]],\n",
       " \n",
       " \n",
       "        [[[ 0.01430317],\n",
       "          [-0.0167692 ],\n",
       "          [-0.00751021],\n",
       "          [-0.0215285 ]]],\n",
       " \n",
       " \n",
       "        [[[-0.03152583],\n",
       "          [ 0.02846507],\n",
       "          [-0.07215091],\n",
       "          [ 0.07267414]]],\n",
       " \n",
       " \n",
       "        [[[-0.072378  ],\n",
       "          [ 0.02540828],\n",
       "          [ 0.03772432],\n",
       "          [ 0.04957335]]],\n",
       " \n",
       " \n",
       "        [[[-0.07555184],\n",
       "          [ 0.03481112],\n",
       "          [-0.00147693],\n",
       "          [ 0.04337432]]],\n",
       " \n",
       " \n",
       "        [[[-0.02209902],\n",
       "          [-0.02431886],\n",
       "          [-0.02399103],\n",
       "          [-0.0759595 ]]],\n",
       " \n",
       " \n",
       "        [[[ 0.06567302],\n",
       "          [ 0.00023357],\n",
       "          [ 0.0051073 ],\n",
       "          [-0.05653688]]],\n",
       " \n",
       " \n",
       "        [[[-0.05459066],\n",
       "          [ 0.01626901],\n",
       "          [-0.07080686],\n",
       "          [-0.00951131]]],\n",
       " \n",
       " \n",
       "        [[[-0.06704405],\n",
       "          [ 0.01804342],\n",
       "          [-0.07669142],\n",
       "          [-0.04757322]]],\n",
       " \n",
       " \n",
       "        [[[-0.04946131],\n",
       "          [ 0.0019394 ],\n",
       "          [-0.02996742],\n",
       "          [ 0.06938809]]],\n",
       " \n",
       " \n",
       "        [[[ 0.06420624],\n",
       "          [ 0.00457377],\n",
       "          [ 0.00476991],\n",
       "          [ 0.02596908]]],\n",
       " \n",
       " \n",
       "        [[[ 0.06201902],\n",
       "          [ 0.04323244],\n",
       "          [ 0.03163572],\n",
       "          [-0.01918342]]],\n",
       " \n",
       " \n",
       "        [[[-0.01028324],\n",
       "          [ 0.00089478],\n",
       "          [ 0.07003064],\n",
       "          [ 0.00790564]]],\n",
       " \n",
       " \n",
       "        [[[ 0.00427248],\n",
       "          [-0.00344001],\n",
       "          [ 0.01416577],\n",
       "          [-0.01952918]]],\n",
       " \n",
       " \n",
       "        [[[ 0.03472617],\n",
       "          [-0.01764951],\n",
       "          [-0.0028443 ],\n",
       "          [-0.0307995 ]]],\n",
       " \n",
       " \n",
       "        [[[-0.07300393],\n",
       "          [ 0.02122822],\n",
       "          [-0.02444181],\n",
       "          [ 0.06941856]]],\n",
       " \n",
       " \n",
       "        [[[-0.06049264],\n",
       "          [ 0.07117712],\n",
       "          [ 0.07086699],\n",
       "          [-0.04844971]]],\n",
       " \n",
       " \n",
       "        [[[ 0.02183962],\n",
       "          [-0.03153585],\n",
       "          [ 0.06645048],\n",
       "          [-0.01422277]]],\n",
       " \n",
       " \n",
       "        [[[-0.03534699],\n",
       "          [-0.02892799],\n",
       "          [ 0.04386161],\n",
       "          [-0.02432067]]],\n",
       " \n",
       " \n",
       "        [[[ 0.00584687],\n",
       "          [ 0.05894069],\n",
       "          [-0.00594378],\n",
       "          [ 0.06013155]]],\n",
       " \n",
       " \n",
       "        [[[ 0.07514071],\n",
       "          [ 0.02365819],\n",
       "          [ 0.07319097],\n",
       "          [-0.06110946]]],\n",
       " \n",
       " \n",
       "        [[[ 0.01749976],\n",
       "          [ 0.04058223],\n",
       "          [ 0.06625561],\n",
       "          [ 0.02498424]]],\n",
       " \n",
       " \n",
       "        [[[-0.04548665],\n",
       "          [-0.05646944],\n",
       "          [ 0.07303411],\n",
       "          [ 0.02921382]]],\n",
       " \n",
       " \n",
       "        [[[ 0.03338135],\n",
       "          [-0.01584207],\n",
       "          [-0.07258867],\n",
       "          [ 0.06065105]]],\n",
       " \n",
       " \n",
       "        [[[-0.03626611],\n",
       "          [-0.01462478],\n",
       "          [ 0.04016633],\n",
       "          [ 0.06117286]]],\n",
       " \n",
       " \n",
       "        [[[-0.03442498],\n",
       "          [-0.02445196],\n",
       "          [ 0.03359939],\n",
       "          [-0.01589057]]],\n",
       " \n",
       " \n",
       "        [[[ 0.01841985],\n",
       "          [ 0.06811805],\n",
       "          [-0.05216798],\n",
       "          [-0.05252287]]],\n",
       " \n",
       " \n",
       "        [[[ 0.0083928 ],\n",
       "          [-0.05473272],\n",
       "          [-0.07568303],\n",
       "          [-0.02987138]]],\n",
       " \n",
       " \n",
       "        [[[-0.00867666],\n",
       "          [ 0.05952324],\n",
       "          [ 0.02775804],\n",
       "          [ 0.01950515]]],\n",
       " \n",
       " \n",
       "        [[[-0.0659733 ],\n",
       "          [-0.04198992],\n",
       "          [-0.06577452],\n",
       "          [-0.05118919]]],\n",
       " \n",
       " \n",
       "        [[[ 0.06814905],\n",
       "          [-0.04566807],\n",
       "          [-0.04989486],\n",
       "          [-0.03733433]]],\n",
       " \n",
       " \n",
       "        [[[ 0.03363988],\n",
       "          [-0.02466612],\n",
       "          [-0.05843084],\n",
       "          [ 0.01798967]]],\n",
       " \n",
       " \n",
       "        [[[-0.00840148],\n",
       "          [ 0.06095573],\n",
       "          [ 0.01125684],\n",
       "          [-0.03536645]]],\n",
       " \n",
       " \n",
       "        [[[ 0.00954349],\n",
       "          [-0.04720313],\n",
       "          [ 0.0426914 ],\n",
       "          [ 0.05716228]]],\n",
       " \n",
       " \n",
       "        [[[-0.00734062],\n",
       "          [-0.00291431],\n",
       "          [-0.06176684],\n",
       "          [ 0.00247931]]],\n",
       " \n",
       " \n",
       "        [[[-0.02221973],\n",
       "          [ 0.02996628],\n",
       "          [-0.05252294],\n",
       "          [-0.05040465]]],\n",
       " \n",
       " \n",
       "        [[[ 0.02202546],\n",
       "          [ 0.02921678],\n",
       "          [ 0.00420663],\n",
       "          [ 0.05010411]]],\n",
       " \n",
       " \n",
       "        [[[ 0.02843358],\n",
       "          [-0.02533359],\n",
       "          [-0.03620522],\n",
       "          [-0.03192296]]],\n",
       " \n",
       " \n",
       "        [[[-0.02358349],\n",
       "          [-0.04403457],\n",
       "          [-0.03957382],\n",
       "          [-0.01459745]]],\n",
       " \n",
       " \n",
       "        [[[-0.02364957],\n",
       "          [ 0.07158656],\n",
       "          [-0.02072093],\n",
       "          [ 0.01477607]]],\n",
       " \n",
       " \n",
       "        [[[-0.05576479],\n",
       "          [ 0.05265625],\n",
       "          [ 0.04700922],\n",
       "          [ 0.06104776]]],\n",
       " \n",
       " \n",
       "        [[[-0.05927284],\n",
       "          [ 0.05466649],\n",
       "          [-0.02702511],\n",
       "          [ 0.06629835]]],\n",
       " \n",
       " \n",
       "        [[[-0.06617373],\n",
       "          [-0.07045262],\n",
       "          [ 0.04397734],\n",
       "          [-0.00923177]]],\n",
       " \n",
       " \n",
       "        [[[-0.04086503],\n",
       "          [-0.0761255 ],\n",
       "          [-0.02671441],\n",
       "          [ 0.06781128]]],\n",
       " \n",
       " \n",
       "        [[[-0.0010094 ],\n",
       "          [ 0.03475694],\n",
       "          [-0.05666837],\n",
       "          [-0.02700019]]],\n",
       " \n",
       " \n",
       "        [[[-0.04111898],\n",
       "          [-0.06190491],\n",
       "          [-0.05888405],\n",
       "          [-0.05241743]]],\n",
       " \n",
       " \n",
       "        [[[-0.05160097],\n",
       "          [ 0.03837003],\n",
       "          [-0.06313893],\n",
       "          [-0.07088686]]],\n",
       " \n",
       " \n",
       "        [[[ 0.04514074],\n",
       "          [ 0.01145718],\n",
       "          [ 0.04738774],\n",
       "          [-0.02979611]]],\n",
       " \n",
       " \n",
       "        [[[ 0.01859763],\n",
       "          [ 0.07265952],\n",
       "          [ 0.05328241],\n",
       "          [ 0.06338568]]],\n",
       " \n",
       " \n",
       "        [[[-0.04768666],\n",
       "          [ 0.04327225],\n",
       "          [-0.03198802],\n",
       "          [ 0.02530759]]],\n",
       " \n",
       " \n",
       "        [[[ 0.07403064],\n",
       "          [ 0.0635667 ],\n",
       "          [ 0.04081117],\n",
       "          [-0.03643943]]],\n",
       " \n",
       " \n",
       "        [[[-0.04241879],\n",
       "          [ 0.04204039],\n",
       "          [ 0.04990965],\n",
       "          [-0.00847393]]],\n",
       " \n",
       " \n",
       "        [[[ 0.03468837],\n",
       "          [ 0.01213706],\n",
       "          [-0.03616241],\n",
       "          [ 0.07641028]]],\n",
       " \n",
       " \n",
       "        [[[-0.0313904 ],\n",
       "          [ 0.06117027],\n",
       "          [-0.02320316],\n",
       "          [-0.04511949]]],\n",
       " \n",
       " \n",
       "        [[[-0.0414919 ],\n",
       "          [-0.03918446],\n",
       "          [-0.05033268],\n",
       "          [-0.04111143]]],\n",
       " \n",
       " \n",
       "        [[[-0.01465921],\n",
       "          [-0.04174467],\n",
       "          [ 0.03864196],\n",
       "          [ 0.05462416]]],\n",
       " \n",
       " \n",
       "        [[[ 0.00498486],\n",
       "          [-0.06580012],\n",
       "          [ 0.04895341],\n",
       "          [ 0.00381542]]],\n",
       " \n",
       " \n",
       "        [[[-0.04282267],\n",
       "          [ 0.0589883 ],\n",
       "          [-0.03873394],\n",
       "          [ 0.00941446]]],\n",
       " \n",
       " \n",
       "        [[[-0.01636234],\n",
       "          [-0.02161816],\n",
       "          [ 0.05081914],\n",
       "          [-0.07073674]]],\n",
       " \n",
       " \n",
       "        [[[-0.01298314],\n",
       "          [ 0.05453303],\n",
       "          [ 0.06570075],\n",
       "          [ 0.05875102]]],\n",
       " \n",
       " \n",
       "        [[[-0.01527647],\n",
       "          [-0.03783915],\n",
       "          [ 0.06332932],\n",
       "          [-0.0718137 ]]],\n",
       " \n",
       " \n",
       "        [[[-0.01100471],\n",
       "          [-0.0591156 ],\n",
       "          [-0.06715837],\n",
       "          [ 0.04989769]]],\n",
       " \n",
       " \n",
       "        [[[ 0.00312229],\n",
       "          [ 0.00297557],\n",
       "          [-0.04085883],\n",
       "          [ 0.01744501]]],\n",
       " \n",
       " \n",
       "        [[[-0.00351855],\n",
       "          [ 0.07534327],\n",
       "          [ 0.05058149],\n",
       "          [ 0.02356182]]],\n",
       " \n",
       " \n",
       "        [[[ 0.06732944],\n",
       "          [ 0.04844277],\n",
       "          [-0.00698723],\n",
       "          [-0.03354018]]],\n",
       " \n",
       " \n",
       "        [[[ 0.06034854],\n",
       "          [-0.06198334],\n",
       "          [ 0.07114394],\n",
       "          [ 0.03679761]]],\n",
       " \n",
       " \n",
       "        [[[ 0.07414521],\n",
       "          [ 0.06670979],\n",
       "          [-0.0696118 ],\n",
       "          [-0.03362803]]],\n",
       " \n",
       " \n",
       "        [[[-0.06530716],\n",
       "          [-0.0322313 ],\n",
       "          [-0.01401312],\n",
       "          [-0.06281281]]],\n",
       " \n",
       " \n",
       "        [[[ 0.01694433],\n",
       "          [-0.05059467],\n",
       "          [-0.02006371],\n",
       "          [-0.07411732]]],\n",
       " \n",
       " \n",
       "        [[[ 0.05660734],\n",
       "          [ 0.07282901],\n",
       "          [ 0.03304374],\n",
       "          [-0.03748876]]],\n",
       " \n",
       " \n",
       "        [[[-0.00160241],\n",
       "          [-0.00855393],\n",
       "          [-0.04913137],\n",
       "          [-0.00411948]]],\n",
       " \n",
       " \n",
       "        [[[ 0.06286189],\n",
       "          [-0.06272085],\n",
       "          [ 0.07271783],\n",
       "          [ 0.04091144]]],\n",
       " \n",
       " \n",
       "        [[[-0.07261087],\n",
       "          [ 0.0294513 ],\n",
       "          [ 0.05256553],\n",
       "          [ 0.05961812]]],\n",
       " \n",
       " \n",
       "        [[[-0.03857147],\n",
       "          [ 0.05362687],\n",
       "          [ 0.04242185],\n",
       "          [-0.06052484]]],\n",
       " \n",
       " \n",
       "        [[[-0.05644199],\n",
       "          [-0.07146215],\n",
       "          [ 0.02074654],\n",
       "          [-0.00273386]]],\n",
       " \n",
       " \n",
       "        [[[-0.06290658],\n",
       "          [ 0.04903962],\n",
       "          [ 0.02245536],\n",
       "          [-0.01585873]]],\n",
       " \n",
       " \n",
       "        [[[ 0.06933093],\n",
       "          [-0.01677112],\n",
       "          [ 0.04597298],\n",
       "          [-0.01851688]]],\n",
       " \n",
       " \n",
       "        [[[-0.01095415],\n",
       "          [-0.06207899],\n",
       "          [-0.03043349],\n",
       "          [-0.06377283]]],\n",
       " \n",
       " \n",
       "        [[[ 0.01084184],\n",
       "          [-0.06591572],\n",
       "          [ 0.04797309],\n",
       "          [ 0.04571808]]],\n",
       " \n",
       " \n",
       "        [[[-0.03296979],\n",
       "          [ 0.06297253],\n",
       "          [-0.02127607],\n",
       "          [-0.00640465]]],\n",
       " \n",
       " \n",
       "        [[[-0.04118947],\n",
       "          [ 0.03482758],\n",
       "          [ 0.06799555],\n",
       "          [ 0.05555595]]],\n",
       " \n",
       " \n",
       "        [[[-0.03203015],\n",
       "          [-0.06836436],\n",
       "          [ 0.07358144],\n",
       "          [ 0.01510099]]],\n",
       " \n",
       " \n",
       "        [[[ 0.06573281],\n",
       "          [-0.02218875],\n",
       "          [-0.0262994 ],\n",
       "          [-0.01204678]]],\n",
       " \n",
       " \n",
       "        [[[ 0.05603594],\n",
       "          [-0.0292643 ],\n",
       "          [-0.01497975],\n",
       "          [ 0.07263134]]],\n",
       " \n",
       " \n",
       "        [[[-0.01773665],\n",
       "          [ 0.0460185 ],\n",
       "          [ 0.0378813 ],\n",
       "          [ 0.00386436]]],\n",
       " \n",
       " \n",
       "        [[[-0.06501594],\n",
       "          [ 0.03665108],\n",
       "          [-0.05048071],\n",
       "          [ 0.01497768]]],\n",
       " \n",
       " \n",
       "        [[[-0.04195336],\n",
       "          [ 0.01757433],\n",
       "          [ 0.04161572],\n",
       "          [-0.06816919]]],\n",
       " \n",
       " \n",
       "        [[[-0.04499549],\n",
       "          [-0.00326249],\n",
       "          [-0.03072661],\n",
       "          [-0.06501188]]],\n",
       " \n",
       " \n",
       "        [[[-0.04740478],\n",
       "          [ 0.01913691],\n",
       "          [-0.02463493],\n",
       "          [-0.02824452]]],\n",
       " \n",
       " \n",
       "        [[[-0.00873978],\n",
       "          [ 0.06633751],\n",
       "          [-0.0359037 ],\n",
       "          [ 0.00904527]]],\n",
       " \n",
       " \n",
       "        [[[-0.04202934],\n",
       "          [ 0.02699852],\n",
       "          [ 0.07243255],\n",
       "          [ 0.00501912]]],\n",
       " \n",
       " \n",
       "        [[[ 0.01980078],\n",
       "          [-0.02153269],\n",
       "          [-0.05431361],\n",
       "          [ 0.04284705]]],\n",
       " \n",
       " \n",
       "        [[[-0.02410054],\n",
       "          [-0.01489485],\n",
       "          [-0.05010806],\n",
       "          [ 0.04160736]]],\n",
       " \n",
       " \n",
       "        [[[ 0.06381549],\n",
       "          [ 0.05866718],\n",
       "          [-0.05013269],\n",
       "          [ 0.03029592]]],\n",
       " \n",
       " \n",
       "        [[[-0.05878405],\n",
       "          [-0.02099441],\n",
       "          [-0.07202212],\n",
       "          [ 0.02777876]]],\n",
       " \n",
       " \n",
       "        [[[ 0.05639146],\n",
       "          [-0.07477542],\n",
       "          [ 0.01958479],\n",
       "          [-0.03401512]]],\n",
       " \n",
       " \n",
       "        [[[-0.00997712],\n",
       "          [-0.01384079],\n",
       "          [-0.05350488],\n",
       "          [-0.01205604]]],\n",
       " \n",
       " \n",
       "        [[[ 0.01565076],\n",
       "          [ 0.06707552],\n",
       "          [ 0.01423115],\n",
       "          [ 0.04985921]]],\n",
       " \n",
       " \n",
       "        [[[-0.05622834],\n",
       "          [ 0.05321075],\n",
       "          [-0.01502541],\n",
       "          [-0.02215964]]],\n",
       " \n",
       " \n",
       "        [[[-0.0303036 ],\n",
       "          [-0.02699358],\n",
       "          [-0.03344265],\n",
       "          [-0.0524964 ]]],\n",
       " \n",
       " \n",
       "        [[[ 0.00575076],\n",
       "          [-0.06899286],\n",
       "          [ 0.07604735],\n",
       "          [-0.03300494]]],\n",
       " \n",
       " \n",
       "        [[[-0.05053695],\n",
       "          [ 0.05031937],\n",
       "          [-0.00895853],\n",
       "          [-0.03286642]]],\n",
       " \n",
       " \n",
       "        [[[-0.00857168],\n",
       "          [ 0.05170555],\n",
       "          [ 0.01533841],\n",
       "          [ 0.05885237]]],\n",
       " \n",
       " \n",
       "        [[[ 0.06423149],\n",
       "          [ 0.0152384 ],\n",
       "          [ 0.0464151 ],\n",
       "          [-0.0592149 ]]],\n",
       " \n",
       " \n",
       "        [[[ 0.01860829],\n",
       "          [-0.03264739],\n",
       "          [-0.07642312],\n",
       "          [ 0.05991289]]],\n",
       " \n",
       " \n",
       "        [[[-0.03753793],\n",
       "          [ 0.00940947],\n",
       "          [ 0.00040872],\n",
       "          [ 0.04817665]]],\n",
       " \n",
       " \n",
       "        [[[-0.02923144],\n",
       "          [-0.01490666],\n",
       "          [ 0.01507365],\n",
       "          [-0.00265558]]],\n",
       " \n",
       " \n",
       "        [[[-0.04938772],\n",
       "          [ 0.06710984],\n",
       "          [-0.06016858],\n",
       "          [ 0.01270199]]],\n",
       " \n",
       " \n",
       "        [[[ 0.00325146],\n",
       "          [ 0.0358849 ],\n",
       "          [ 0.00744297],\n",
       "          [ 0.07043032]]],\n",
       " \n",
       " \n",
       "        [[[-0.04297763],\n",
       "          [-0.06899065],\n",
       "          [ 0.01412178],\n",
       "          [ 0.04852761]]],\n",
       " \n",
       " \n",
       "        [[[-0.03873417],\n",
       "          [-0.00974372],\n",
       "          [ 0.07498693],\n",
       "          [-0.00617295]]],\n",
       " \n",
       " \n",
       "        [[[ 0.02220847],\n",
       "          [ 0.02885282],\n",
       "          [ 0.07213163],\n",
       "          [-0.05317592]]],\n",
       " \n",
       " \n",
       "        [[[ 0.02182902],\n",
       "          [-0.07215034],\n",
       "          [-0.06100876],\n",
       "          [-0.01417398]]],\n",
       " \n",
       " \n",
       "        [[[ 0.0365735 ],\n",
       "          [-0.03752423],\n",
       "          [-0.00629524],\n",
       "          [-0.07554676]]],\n",
       " \n",
       " \n",
       "        [[[-0.07492138],\n",
       "          [ 0.03871318],\n",
       "          [-0.0670061 ],\n",
       "          [ 0.01821949]]],\n",
       " \n",
       " \n",
       "        [[[-0.0607497 ],\n",
       "          [-0.04052798],\n",
       "          [ 0.04545908],\n",
       "          [ 0.01937971]]],\n",
       " \n",
       " \n",
       "        [[[ 0.05031714],\n",
       "          [ 0.07133323],\n",
       "          [-0.00478183],\n",
       "          [ 0.01260306]]],\n",
       " \n",
       " \n",
       "        [[[ 0.02533478],\n",
       "          [ 0.02578445],\n",
       "          [ 0.06873913],\n",
       "          [-0.02429551]]],\n",
       " \n",
       " \n",
       "        [[[ 0.01527066],\n",
       "          [-0.06605833],\n",
       "          [ 0.01356155],\n",
       "          [ 0.0205309 ]]],\n",
       " \n",
       " \n",
       "        [[[-0.07327499],\n",
       "          [-0.02830156],\n",
       "          [-0.05420389],\n",
       "          [ 0.04473639]]],\n",
       " \n",
       " \n",
       "        [[[ 0.01924456],\n",
       "          [ 0.04990254],\n",
       "          [ 0.00571891],\n",
       "          [-0.00050524]]],\n",
       " \n",
       " \n",
       "        [[[ 0.03640183],\n",
       "          [-0.01898834],\n",
       "          [ 0.0252729 ],\n",
       "          [ 0.03516602]]],\n",
       " \n",
       " \n",
       "        [[[ 0.02576091],\n",
       "          [ 0.01900465],\n",
       "          [ 0.00984462],\n",
       "          [-0.04659505]]],\n",
       " \n",
       " \n",
       "        [[[-0.01428489],\n",
       "          [-0.07477689],\n",
       "          [ 0.06694916],\n",
       "          [-0.03581284]]],\n",
       " \n",
       " \n",
       "        [[[-0.0587192 ],\n",
       "          [-0.04382169],\n",
       "          [-0.00247618],\n",
       "          [-0.07434346]]],\n",
       " \n",
       " \n",
       "        [[[-0.07451083],\n",
       "          [-0.01884545],\n",
       "          [ 0.07328214],\n",
       "          [-0.07195523]]],\n",
       " \n",
       " \n",
       "        [[[ 0.06052618],\n",
       "          [-0.068244  ],\n",
       "          [ 0.03805654],\n",
       "          [-0.0335556 ]]],\n",
       " \n",
       " \n",
       "        [[[ 0.00098488],\n",
       "          [ 0.01420642],\n",
       "          [ 0.01677703],\n",
       "          [-0.0347582 ]]],\n",
       " \n",
       " \n",
       "        [[[-0.05692115],\n",
       "          [-0.01925775],\n",
       "          [ 0.06858037],\n",
       "          [-0.01731619]]],\n",
       " \n",
       " \n",
       "        [[[-0.06013009],\n",
       "          [-0.03657569],\n",
       "          [-0.01188543],\n",
       "          [-0.03235559]]],\n",
       " \n",
       " \n",
       "        [[[-0.01350199],\n",
       "          [-0.03306433],\n",
       "          [-0.02195506],\n",
       "          [-0.04106516]]],\n",
       " \n",
       " \n",
       "        [[[ 0.05547242],\n",
       "          [-0.07000155],\n",
       "          [-0.02973976],\n",
       "          [ 0.00062133]]],\n",
       " \n",
       " \n",
       "        [[[ 0.05916791],\n",
       "          [-0.06182762],\n",
       "          [-0.01207922],\n",
       "          [-0.05324743]]],\n",
       " \n",
       " \n",
       "        [[[-0.02244548],\n",
       "          [ 0.05565779],\n",
       "          [ 0.0421414 ],\n",
       "          [-0.0365188 ]]],\n",
       " \n",
       " \n",
       "        [[[ 0.05478752],\n",
       "          [ 0.06367248],\n",
       "          [ 0.02826714],\n",
       "          [ 0.07560293]]],\n",
       " \n",
       " \n",
       "        [[[-0.01797102],\n",
       "          [ 0.04107831],\n",
       "          [-0.05634467],\n",
       "          [-0.00709082]]],\n",
       " \n",
       " \n",
       "        [[[-0.05402489],\n",
       "          [ 0.04088472],\n",
       "          [ 0.06811613],\n",
       "          [ 0.0529215 ]]],\n",
       " \n",
       " \n",
       "        [[[-0.07550007],\n",
       "          [-0.05760486],\n",
       "          [-0.04474399],\n",
       "          [-0.03353005]]],\n",
       " \n",
       " \n",
       "        [[[-0.01440791],\n",
       "          [ 0.05649681],\n",
       "          [ 0.06050485],\n",
       "          [ 0.03612643]]],\n",
       " \n",
       " \n",
       "        [[[-0.0588949 ],\n",
       "          [-0.05116085],\n",
       "          [ 0.01872034],\n",
       "          [ 0.04080591]]],\n",
       " \n",
       " \n",
       "        [[[ 0.02466885],\n",
       "          [-0.07533099],\n",
       "          [ 0.01241433],\n",
       "          [-0.03043374]]],\n",
       " \n",
       " \n",
       "        [[[ 0.02852055],\n",
       "          [ 0.02759171],\n",
       "          [ 0.05815512],\n",
       "          [ 0.07268657]]],\n",
       " \n",
       " \n",
       "        [[[-0.02426021],\n",
       "          [ 0.06769916],\n",
       "          [-0.03448949],\n",
       "          [ 0.05833662]]],\n",
       " \n",
       " \n",
       "        [[[ 0.06112711],\n",
       "          [-0.03763175],\n",
       "          [-0.06600966],\n",
       "          [ 0.0629698 ]]],\n",
       " \n",
       " \n",
       "        [[[-0.05524955],\n",
       "          [ 0.01991992],\n",
       "          [-0.06392696],\n",
       "          [-0.01781927]]],\n",
       " \n",
       " \n",
       "        [[[ 0.02940769],\n",
       "          [-0.00269338],\n",
       "          [ 0.02743886],\n",
       "          [-0.05563979]]],\n",
       " \n",
       " \n",
       "        [[[ 0.06332961],\n",
       "          [-0.02765112],\n",
       "          [-0.02075582],\n",
       "          [ 0.05376527]]],\n",
       " \n",
       " \n",
       "        [[[ 0.05927908],\n",
       "          [ 0.0107535 ],\n",
       "          [ 0.03781743],\n",
       "          [ 0.04673132]]],\n",
       " \n",
       " \n",
       "        [[[-0.05177248],\n",
       "          [ 0.04026858],\n",
       "          [-0.0338623 ],\n",
       "          [-0.00937652]]],\n",
       " \n",
       " \n",
       "        [[[-0.02534491],\n",
       "          [-0.0478875 ],\n",
       "          [ 0.04832233],\n",
       "          [-0.01007622]]],\n",
       " \n",
       " \n",
       "        [[[ 0.00863468],\n",
       "          [ 0.00941507],\n",
       "          [-0.02685057],\n",
       "          [ 0.0203128 ]]],\n",
       " \n",
       " \n",
       "        [[[-0.05716082],\n",
       "          [ 0.0687536 ],\n",
       "          [ 0.04350448],\n",
       "          [ 0.02239118]]],\n",
       " \n",
       " \n",
       "        [[[-0.06317518],\n",
       "          [ 0.00449962],\n",
       "          [ 0.04427929],\n",
       "          [-0.00263971]]],\n",
       " \n",
       " \n",
       "        [[[-0.00539353],\n",
       "          [-0.02325926],\n",
       "          [-0.04495448],\n",
       "          [-0.02847008]]],\n",
       " \n",
       " \n",
       "        [[[-0.02133073],\n",
       "          [-0.05480649],\n",
       "          [-0.01920521],\n",
       "          [-0.00451773]]],\n",
       " \n",
       " \n",
       "        [[[ 0.06516862],\n",
       "          [-0.06009222],\n",
       "          [-0.03203509],\n",
       "          [-0.06381127]]],\n",
       " \n",
       " \n",
       "        [[[-0.06161914],\n",
       "          [ 0.02765458],\n",
       "          [ 0.00076334],\n",
       "          [-0.02341595]]],\n",
       " \n",
       " \n",
       "        [[[-0.03521807],\n",
       "          [-0.0512445 ],\n",
       "          [-0.04553136],\n",
       "          [ 0.03952613]]],\n",
       " \n",
       " \n",
       "        [[[-0.06305312],\n",
       "          [ 0.06471267],\n",
       "          [ 0.05175911],\n",
       "          [-0.03899284]]],\n",
       " \n",
       " \n",
       "        [[[ 0.01865565],\n",
       "          [-0.02866892],\n",
       "          [ 0.00359233],\n",
       "          [ 0.01780115]]],\n",
       " \n",
       " \n",
       "        [[[ 0.0635464 ],\n",
       "          [ 0.05596888],\n",
       "          [ 0.00341909],\n",
       "          [-0.03672095]]],\n",
       " \n",
       " \n",
       "        [[[ 0.01869061],\n",
       "          [ 0.00162077],\n",
       "          [-0.07174297],\n",
       "          [ 0.02315887]]],\n",
       " \n",
       " \n",
       "        [[[-0.0386852 ],\n",
       "          [ 0.06972651],\n",
       "          [ 0.07216972],\n",
       "          [ 0.04351075]]],\n",
       " \n",
       " \n",
       "        [[[-0.05567526],\n",
       "          [ 0.06000604],\n",
       "          [ 0.04356591],\n",
       "          [ 0.06704207]]],\n",
       " \n",
       " \n",
       "        [[[ 0.06676905],\n",
       "          [ 0.05407722],\n",
       "          [-0.00673311],\n",
       "          [-0.0378802 ]]],\n",
       " \n",
       " \n",
       "        [[[ 0.02197   ],\n",
       "          [-0.03234253],\n",
       "          [ 0.0638793 ],\n",
       "          [ 0.05282868]]],\n",
       " \n",
       " \n",
       "        [[[-0.01117557],\n",
       "          [ 0.04894984],\n",
       "          [-0.01501518],\n",
       "          [ 0.01449151]]],\n",
       " \n",
       " \n",
       "        [[[ 0.0388476 ],\n",
       "          [-0.02876283],\n",
       "          [ 0.00125187],\n",
       "          [ 0.01369562]]],\n",
       " \n",
       " \n",
       "        [[[ 0.0362259 ],\n",
       "          [-0.03857269],\n",
       "          [-0.06251696],\n",
       "          [ 0.01227375]]],\n",
       " \n",
       " \n",
       "        [[[-0.00073716],\n",
       "          [ 0.01252951],\n",
       "          [ 0.04117594],\n",
       "          [ 0.01149826]]],\n",
       " \n",
       " \n",
       "        [[[-0.0145877 ],\n",
       "          [-0.01517354],\n",
       "          [ 0.03735553],\n",
       "          [-0.00742903]]],\n",
       " \n",
       " \n",
       "        [[[ 0.01742912],\n",
       "          [-0.04918003],\n",
       "          [ 0.04378723],\n",
       "          [ 0.06692867]]],\n",
       " \n",
       " \n",
       "        [[[-0.0553739 ],\n",
       "          [-0.06608559],\n",
       "          [-0.03764657],\n",
       "          [ 0.0446562 ]]],\n",
       " \n",
       " \n",
       "        [[[-0.06474626],\n",
       "          [ 0.00242151],\n",
       "          [-0.02879019],\n",
       "          [ 0.04343704]]],\n",
       " \n",
       " \n",
       "        [[[-0.00388385],\n",
       "          [ 0.01068586],\n",
       "          [ 0.04881589],\n",
       "          [ 0.01623332]]],\n",
       " \n",
       " \n",
       "        [[[-0.04637454],\n",
       "          [-0.03535878],\n",
       "          [-0.04270508],\n",
       "          [-0.03701651]]],\n",
       " \n",
       " \n",
       "        [[[-0.0677362 ],\n",
       "          [-0.02783139],\n",
       "          [-0.05715677],\n",
       "          [-0.02411619]]],\n",
       " \n",
       " \n",
       "        [[[ 0.01555705],\n",
       "          [-0.02790682],\n",
       "          [ 0.04946366],\n",
       "          [ 0.00635401]]],\n",
       " \n",
       " \n",
       "        [[[-0.05587489],\n",
       "          [-0.00714999],\n",
       "          [-0.04331583],\n",
       "          [-0.03824111]]],\n",
       " \n",
       " \n",
       "        [[[-0.00365661],\n",
       "          [-0.01893771],\n",
       "          [ 0.06550425],\n",
       "          [-0.02740172]]],\n",
       " \n",
       " \n",
       "        [[[-0.05918209],\n",
       "          [-0.07218419],\n",
       "          [-0.04538485],\n",
       "          [ 0.04593816]]],\n",
       " \n",
       " \n",
       "        [[[-0.06934953],\n",
       "          [ 0.06122689],\n",
       "          [-0.06020863],\n",
       "          [-0.04966433]]],\n",
       " \n",
       " \n",
       "        [[[ 0.04057161],\n",
       "          [-0.00465961],\n",
       "          [-0.05455284],\n",
       "          [-0.07043318]]],\n",
       " \n",
       " \n",
       "        [[[-0.03152563],\n",
       "          [-0.06410123],\n",
       "          [-0.04771548],\n",
       "          [ 0.0533898 ]]],\n",
       " \n",
       " \n",
       "        [[[-0.0037744 ],\n",
       "          [-0.01437754],\n",
       "          [-0.01408065],\n",
       "          [-0.04272013]]],\n",
       " \n",
       " \n",
       "        [[[-0.03054119],\n",
       "          [ 0.05112138],\n",
       "          [ 0.04627291],\n",
       "          [-0.03019867]]],\n",
       " \n",
       " \n",
       "        [[[ 0.02452536],\n",
       "          [ 0.03871367],\n",
       "          [ 0.01962334],\n",
       "          [-0.01750362]]],\n",
       " \n",
       " \n",
       "        [[[ 0.06855774],\n",
       "          [ 0.00834119],\n",
       "          [-0.04584169],\n",
       "          [-0.00412922]]],\n",
       " \n",
       " \n",
       "        [[[-0.02365164],\n",
       "          [-0.06048335],\n",
       "          [ 0.05996554],\n",
       "          [-0.05813969]]],\n",
       " \n",
       " \n",
       "        [[[ 0.01411338],\n",
       "          [ 0.05008365],\n",
       "          [ 0.02131454],\n",
       "          [-0.06688317]]]], dtype=float32)>,\n",
       " <tf.Variable 'demixing/bias:0' shape=(4,) dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dmx.weights"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "25b6c1d617e3cb25e4067864bcd46322e1b7da41afdae0cf7c23b941b0b9b767"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
