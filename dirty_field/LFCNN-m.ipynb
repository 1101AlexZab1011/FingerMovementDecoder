{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "current_dir = os.path.dirname(os.path.abspath('./'))\n",
    "if not current_dir in sys.path:\n",
    "    sys.path.append(current_dir)\n",
    "\n",
    "import mneflow as mf\n",
    "import mneflow\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from mneflow.models import BaseModel, LFCNN\n",
    "from utils.machine_learning.designer import ModelDesign, ParallelDesign, LayerDesign\n",
    "from utils.machine_learning.analyzer import ModelAnalyzer\n",
    "from mneflow.layers import DeMixing, LFTConv, TempPooling, Dense, VARConv\n",
    "from mne.datasets import multimodal\n",
    "import mne\n",
    "from utils.machine_learning.confusion import ConfusionEstimator\n",
    "from utils.machine_learning import one_hot_decoder\n",
    "import sklearn.metrics as sm\n",
    "import tensorflow.keras.regularizers as k_reg\n",
    "from tensorflow.keras.layers import SeparableConv2D, Conv2D, DepthwiseConv2D\n",
    "from tensorflow.keras.layers import Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.initializers import Constant\n",
    "from mne import channels, evoked, create_info\n",
    "\n",
    "from scipy.signal import freqz, welch\n",
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting reg for fc, to l1\n",
      "Setting reg for fc, to l1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 204, 194, 32])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_times = 200\n",
    "n_channels = 204\n",
    "out_dim = 4\n",
    "\n",
    "specs = dict()\n",
    "specs.setdefault('filter_length', 7)\n",
    "specs.setdefault('n_latent', 32)\n",
    "specs.setdefault('pooling', 3)\n",
    "specs.setdefault('stride', 3)\n",
    "specs.setdefault('padding', 'SAME')\n",
    "specs.setdefault('pool_type', 'max')\n",
    "specs.setdefault('nonlin', tf.nn.relu)\n",
    "specs.setdefault('l1', 3e-4)\n",
    "specs.setdefault('l2', 0)\n",
    "specs.setdefault('l1_scope', ['fc', 'demix', 'lf_conv'])\n",
    "specs.setdefault('l2_scope', [])\n",
    "specs.setdefault('maxnorm_scope', [])\n",
    "specs.setdefault('dropout', .4)\n",
    "\n",
    "lfcnnd = ModelDesign(\n",
    "    tf.keras.Input(shape=(1, n_times, n_channels)),\n",
    "    DeMixing(size=specs['n_latent'], nonlin=tf.identity, axis=3, specs=specs),\n",
    "    LFTConv(\n",
    "        size=specs['n_latent'],\n",
    "        nonlin=specs['nonlin'],\n",
    "        filter_length=specs['filter_length'],\n",
    "        padding=specs['padding'],\n",
    "        specs=specs\n",
    "    ),\n",
    "    TempPooling(\n",
    "        pooling=specs['pooling'],\n",
    "        pool_type=specs['pool_type'],\n",
    "        stride=specs['stride'],\n",
    "        padding=specs['padding'],\n",
    "    ),\n",
    "    tf.keras.layers.Dropout(specs['dropout'], noise_shape=None),\n",
    "    Dense(size=out_dim, nonlin=tf.identity, specs=specs)\n",
    ")\n",
    "\n",
    "\n",
    "varcnnd = ModelDesign(\n",
    "    tf.keras.Input(shape=(1, n_times, n_channels)),\n",
    "    DeMixing(size=specs['n_latent'], nonlin=tf.identity, axis=3, specs=specs),\n",
    "    VARConv(\n",
    "        size=specs['n_latent'],\n",
    "        nonlin=specs['nonlin'],\n",
    "        filter_length=specs['filter_length'],\n",
    "        padding=specs['padding'],\n",
    "        specs=specs\n",
    "    ),\n",
    "    TempPooling(\n",
    "        pooling=specs['pooling'],\n",
    "        pool_type=specs['pool_type'],\n",
    "        stride=specs['stride'],\n",
    "        padding=specs['padding'],\n",
    "    ),\n",
    "    tf.keras.layers.Dropout(specs['dropout'], noise_shape=None),\n",
    "    Dense(size=out_dim, nonlin=tf.identity, specs=specs)\n",
    ")\n",
    "\n",
    "Deep4_d = ModelDesign(\n",
    "    tf.keras.Input(shape=(1, n_times, n_channels)),\n",
    "    LayerDesign(tf.transpose, [0,3,2,1]),\n",
    "    DepthwiseConv2D(\n",
    "        kernel_size=(1, specs['filter_length']),\n",
    "        depth_multiplier = specs['n_latent'],\n",
    "        strides=1,\n",
    "        padding=specs['padding'],\n",
    "        activation = tf.identity,\n",
    "        kernel_initializer=\"he_uniform\",\n",
    "        bias_initializer=Constant(0.1),\n",
    "        data_format=\"channels_last\",\n",
    "        kernel_regularizer=k_reg.l2(specs['l2'])\n",
    "        #kernel_constraint=\"maxnorm\"\n",
    "    ),\n",
    "    *[ModelDesign(\n",
    "        Conv2D(\n",
    "            filters=specs['n_latent'],\n",
    "            kernel_size=(n_channels, 1),\n",
    "            strides=1,\n",
    "            padding=specs['padding'],\n",
    "            activation=specs['nonlin'],\n",
    "            kernel_initializer=\"he_uniform\",\n",
    "            bias_initializer=Constant(0.1),\n",
    "            data_format=\"channels_last\",\n",
    "            #data_format=\"channels_first\",\n",
    "            kernel_regularizer=k_reg.l2(specs['l2'])\n",
    "        ),\n",
    "        TempPooling(\n",
    "            pooling=specs['pooling'],\n",
    "            pool_type=\"avg\",\n",
    "            stride=specs['stride'],\n",
    "            padding='SAME',\n",
    "        )\n",
    "    ) for _ in range(4)],\n",
    "    Dense(size=out_dim, nonlin=tf.identity)\n",
    ")\n",
    "\n",
    "\n",
    "FBCSP_ShallowNet_d = ModelDesign(\n",
    "    tf.keras.Input(shape=(1, n_times, n_channels)),\n",
    "    LayerDesign(tf.transpose, [0,3,2,1]),\n",
    "    Conv2D(\n",
    "        specs['n_latent'],\n",
    "        kernel_size=(1, specs['filter_length']),\n",
    "        # depth_multiplier = specs['n_latent'],\n",
    "        strides=1,\n",
    "        padding=\"VALID\",\n",
    "        activation = tf.identity,\n",
    "        kernel_initializer=\"he_uniform\",\n",
    "        bias_initializer=Constant(0.1),\n",
    "        data_format=\"channels_last\",\n",
    "        kernel_regularizer=k_reg.l2(specs['l2'])\n",
    "        #kernel_constraint=\"maxnorm\"\n",
    "    )\n",
    ")\n",
    "\n",
    "FBCSP_ShallowNet_d().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Info | 22 non-empty values\n",
      " acq_pars: ACQch001 110113 ACQch002 110112 ACQch003 110111 ACQch004 110122 ...\n",
      " acq_stim: 5 10.000000 500.000000 6 10.000000 500.000000\n",
      " bads: []\n",
      " ch_names: MEG 0113, MEG 0112, MEG 0111, MEG 0122, MEG 0123, MEG 0121, MEG ...\n",
      " chs: 204 GRAD, 102 MAG, 9 STIM, 1 EOG\n",
      " custom_ref_applied: False\n",
      " description: Vectorview system at BioMag\n",
      " dev_head_t: MEG device -> head transform\n",
      " dig: 21 items (3 Cardinal, 4 HPI, 14 Extra)\n",
      " events: 1 item (list)\n",
      " experimenter: neuromag\n",
      " file_id: 4 items (dict)\n",
      " highpass: 0.1 Hz\n",
      " hpi_meas: 1 item (list)\n",
      " hpi_results: 1 item (list)\n",
      " lowpass: 172.2 Hz\n",
      " meas_date: 2011-04-26 11:33:18 UTC\n",
      " meas_id: 4 items (dict)\n",
      " nchan: 316\n",
      " proj_id: 1 item (ndarray)\n",
      " proj_name: test\n",
      " projs: grad_ssp_upright.fif : PCA-v1: on, grad_ssp_upright.fif : ...\n",
      " sfreq: 600.6 Hz\n",
      " subject_info: 9 items (dict)\n",
      ">\n"
     ]
    }
   ],
   "source": [
    "mne.set_log_level(verbose='CRITICAL')\n",
    "fname_raw = os.path.join(multimodal.data_path(), 'multimodal_raw.fif')\n",
    "raw = mne.io.read_raw_fif(fname_raw)\n",
    "\n",
    "cond = raw.acqparser.get_condition(raw, None)\n",
    "# get the list of condition names\n",
    "condition_names = [k for c in cond for k,v in c['event_id'].items()]\n",
    "epochs_list = [mne.Epochs(raw, **c) for c in cond]\n",
    "epochs = mne.concatenate_epochs(epochs_list)\n",
    "print(epochs.info)\n",
    "epochs = epochs.pick_types(meg='grad')\n",
    "\n",
    "X = np.array([])\n",
    "Y = list()\n",
    "for i, epochs in enumerate(epochs_list):\n",
    "    data = epochs.get_data()\n",
    "    if i == 0:\n",
    "        X = data.copy()\n",
    "    else:\n",
    "        X = np.append(X, data, axis=0)\n",
    "    Y += [i for _ in range(data.shape[0])]\n",
    "\n",
    "Y = np.array(Y)\n",
    "\n",
    "sample_matrix = X[0].copy()\n",
    "\n",
    "X = np.array([X[i, epochs._channel_type_idx['grad'], :] for i, _ in enumerate(X)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing from tuple\n",
      "input shapes: X- (940, 204, 361) targets- (940, 1)\n",
      "Preprocessing:\n",
      "Scaling to interval 0.0 - 60.0\n",
      "Splitting sets\n",
      "Preprocessed: (940, 1, 361, 204) (940, 8) folds: 6 x 156\n",
      "936\n",
      "Prepocessed sample shape: (1, 361, 204)\n",
      "Target shape actual/metadata:  (8,) (8,)\n",
      "Saving TFRecord# 0\n"
     ]
    }
   ],
   "source": [
    "import_opt = dict(savepath='../tfr/',\n",
    "                out_name='mne_sample_epochs',\n",
    "                fs=600,\n",
    "                input_type='trials',\n",
    "                target_type='int',\n",
    "                picks={'meg':'grad'},\n",
    "                scale=True,  # apply baseline_scaling\n",
    "                crop_baseline=True,  # remove baseline interval after scaling\n",
    "                decimate=None,\n",
    "                scale_interval=(0, 60),  # indices in time axis corresponding to baseline interval\n",
    "            #   n_folds=5,  # validation set size set to 20% of all data\n",
    "                n_folds=5,\n",
    "                overwrite=True,\n",
    "                segment=False,\n",
    "                test_set='holdout'\n",
    ")\n",
    "\n",
    "lf_params = dict(n_latent=32, #number of latent factors\n",
    "                filter_length=17, #convolutional filter length in time samples\n",
    "                nonlin = tf.nn.relu,\n",
    "                padding = 'SAME',\n",
    "                pooling = 5,#pooling factor\n",
    "                stride = 5, #stride parameter for pooling layer\n",
    "                pool_type='max',\n",
    "                model_path = import_opt['savepath'],\n",
    "                dropout = .5,\n",
    "                l1_scope = [\"weights\"],\n",
    "                l1=3e-3\n",
    ")\n",
    "\n",
    "\n",
    "meta = mf.produce_tfrecords((X, Y), **import_opt)  \n",
    "dataset = mf.Dataset(meta, train_batch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-10 13:12:07.603627: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-03-10 13:12:07.603661: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-03-10 13:12:07.603681: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (arcolinux-machine): /proc/driver/nvidia/version does not exist\n",
      "2022-03-10 13:12:07.604007: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# np.array(meta['folds'][0]).shape\n",
    "np.array(meta['test_fold'][0]).shape\n",
    "dataset = mf.Dataset(meta, train_batch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LFCNNm(LFCNN):\n",
    "    def __init__(self, Dataset, specs=dict()):\n",
    "        self.scope = 'lfcnn'\n",
    "        specs.setdefault('filter_length', 7)\n",
    "        specs.setdefault('n_latent', 32)\n",
    "        specs.setdefault('pooling', 2)\n",
    "        specs.setdefault('stride', 2)\n",
    "        specs.setdefault('padding', 'SAME')\n",
    "        specs.setdefault('pool_type', 'max')\n",
    "        specs.setdefault('nonlin', tf.nn.relu)\n",
    "        specs.setdefault('l1', 3e-4)\n",
    "        specs.setdefault('l2', 0)\n",
    "        specs.setdefault('l1_scope', ['fc', 'demix', 'lf_conv'])\n",
    "        specs.setdefault('l2_scope', [])\n",
    "        specs.setdefault('maxnorm_scope', [])\n",
    "        \n",
    "        super(LFCNNm, self).__init__(Dataset, specs)\n",
    "\n",
    "    def build_graph(self):\n",
    "        \n",
    "        # self.dmx\n",
    "        # self.tconv\n",
    "        # self.pool\n",
    "        # self.fin_fc\n",
    "        \n",
    "        # self.design = ModelDesign(\n",
    "        #     self.inputs,\n",
    "        #     DeMixing(size=self.specs['n_latent'], nonlin=tf.identity, axis=3, specs=self.specs),\n",
    "        #     LFTConv(\n",
    "        #         size=self.specs['n_latent'],\n",
    "        #         nonlin=self.specs['nonlin'],\n",
    "        #         filter_length=self.specs['filter_length'],\n",
    "        #         padding=self.specs['padding'],\n",
    "        #         specs=self.specs\n",
    "        #     ),\n",
    "        #     tf.keras.layers.Dropout(self.specs['dropout'], noise_shape=None),\n",
    "        #     tf.keras.layers.DepthwiseConv2D((1, 361), padding='valid', activation='relu', kernel_regularizer='l1'),\n",
    "        #     tf.keras.layers.Flatten(),\n",
    "        #     tf.keras.layers.Dense(self.out_dim, kernel_regularizer='l1'),\n",
    "        # )\n",
    "        \n",
    "        # self.design = ModelDesign(\n",
    "        #     self.inputs,\n",
    "        #     tf.keras.layers.Conv2D(self.specs['n_latent'], (1, 204), padding='same', kernel_regularizer='l1'),\n",
    "        #     tf.keras.layers.DepthwiseConv2D((1, self.specs['filter_length']), padding='same', kernel_regularizer='l1'),\n",
    "        #     # LayerDesign(tf.nn.avg_pool2d, ksize=(1, 1, 10, 1), strides=(1, 1, 10, 1), padding='SAME'),\n",
    "        #     tf.keras.layers.Dropout(self.specs['dropout'], noise_shape=None),\n",
    "        #     # tf.keras.layers.Flatten(),\n",
    "        #     # tf.keras.layers.Dense(self.out_dim),\n",
    "        #     tf.keras.layers.DepthwiseConv2D((1, 361), padding='valid', activation='relu', kernel_regularizer='l1'),\n",
    "        #     tf.keras.layers.Flatten(),\n",
    "        #     tf.keras.layers.Dense(self.out_dim, kernel_regularizer='l1'),\n",
    "        # )\n",
    "        \n",
    "        # self.design = ModelDesign(\n",
    "        #     self.inputs,\n",
    "        #     LayerDesign(tf.squeeze, axis=1),\n",
    "        #     tf.keras.layers.Bidirectional(\n",
    "        #         tf.keras.layers.LSTM(\n",
    "        #             self.specs['n_latent'],\n",
    "        #             bias_regularizer='l1',\n",
    "        #             return_sequences=True,\n",
    "        #             kernel_regularizer=tf.keras.regularizers.L1(.01),\n",
    "        #             recurrent_regularizer=tf.keras.regularizers.L1(.01),\n",
    "        #             dropout=0.4,\n",
    "        #             recurrent_dropout=0.4,\n",
    "        #         ),\n",
    "        #         merge_mode='sum'\n",
    "        #     ),\n",
    "        #     LayerDesign(tf.expand_dims, axis=1),\n",
    "        #     tf.keras.layers.DepthwiseConv2D((1, self.specs['filter_length']), padding='same', kernel_regularizer='l1'),\n",
    "        #     # LayerDesign(tf.nn.avg_pool2d, ksize=(1, 1, 10, 1), strides=(1, 1, 10, 1), padding='SAME'),\n",
    "        #     tf.keras.layers.Dropout(self.specs['dropout'], noise_shape=None),\n",
    "        #     # tf.keras.layers.Flatten(),\n",
    "        #     # tf.keras.layers.Dense(self.out_dim),\n",
    "        #     tf.keras.layers.DepthwiseConv2D((1, 361), padding='valid', activation='relu', kernel_regularizer='l1'),\n",
    "        #     tf.keras.layers.Flatten(),\n",
    "        #     tf.keras.layers.Dense(self.out_dim, kernel_regularizer='l1'),\n",
    "        # )\n",
    "        \n",
    "        # self.design = ModelDesign(\n",
    "        #     self.inputs,\n",
    "        #     DeMixing(size=self.specs['n_latent'], nonlin=tf.identity, axis=3, specs=self.specs),\n",
    "        #     ParallelDesign(\n",
    "        #         LFTConv(\n",
    "        #             size=self.specs['n_latent'],\n",
    "        #             nonlin=self.specs['nonlin'],\n",
    "        #             filter_length=self.specs['filter_length']//2,\n",
    "        #             padding=self.specs['padding'],\n",
    "        #             specs=self.specs\n",
    "        #         ),\n",
    "        #         LFTConv(\n",
    "        #             size=self.specs['n_latent'],\n",
    "        #             nonlin=self.specs['nonlin'],\n",
    "        #             filter_length=self.specs['filter_length'],\n",
    "        #             padding=self.specs['padding'],\n",
    "        #             specs=self.specs\n",
    "        #         ),\n",
    "        #         LFTConv(\n",
    "        #             size=self.specs['n_latent'],\n",
    "        #             nonlin=self.specs['nonlin'],\n",
    "        #             filter_length=self.specs['filter_length']*2,\n",
    "        #             padding=self.specs['padding'],\n",
    "        #             specs=self.specs\n",
    "        #         ),\n",
    "        #     ),\n",
    "        #     TempPooling(\n",
    "        #         pooling=self.specs['pooling'],\n",
    "        #         pool_type=self.specs['pool_type'],\n",
    "        #         stride=self.specs['stride'],\n",
    "        #         padding=self.specs['padding'],\n",
    "        #     ),\n",
    "        #     tf.keras.layers.Dropout(self.specs['dropout'], noise_shape=None),\n",
    "        #     Dense(size=self.out_dim, nonlin=tf.identity, specs=self.specs)\n",
    "        # )\n",
    "        \n",
    "        self.design = ModelDesign(\n",
    "            self.inputs,\n",
    "            LayerDesign(tf.squeeze, axis=1),\n",
    "            tf.keras.layers.Bidirectional(\n",
    "                tf.keras.layers.LSTM(\n",
    "                    self.specs['n_latent'],\n",
    "                    bias_regularizer='l1',\n",
    "                    return_sequences=True,\n",
    "                    kernel_regularizer=tf.keras.regularizers.L1(.01),\n",
    "                    recurrent_regularizer=tf.keras.regularizers.L1(.01),\n",
    "                    dropout=0.4,\n",
    "                    recurrent_dropout=0.4,\n",
    "                ),\n",
    "                merge_mode='sum'\n",
    "            ),\n",
    "            LayerDesign(tf.expand_dims, axis=1),\n",
    "            ParallelDesign(\n",
    "                LFTConv(\n",
    "                    size=self.specs['n_latent'],\n",
    "                    nonlin=self.specs['nonlin'],\n",
    "                    filter_length=self.specs['filter_length']//2,\n",
    "                    padding=self.specs['padding'],\n",
    "                    specs=self.specs\n",
    "                ),\n",
    "                LFTConv(\n",
    "                    size=self.specs['n_latent'],\n",
    "                    nonlin=self.specs['nonlin'],\n",
    "                    filter_length=self.specs['filter_length'],\n",
    "                    padding=self.specs['padding'],\n",
    "                    specs=self.specs\n",
    "                ),\n",
    "                LFTConv(\n",
    "                    size=self.specs['n_latent'],\n",
    "                    nonlin=self.specs['nonlin'],\n",
    "                    filter_length=self.specs['filter_length']*2,\n",
    "                    padding=self.specs['padding'],\n",
    "                    specs=self.specs\n",
    "                ),\n",
    "            ),\n",
    "            \n",
    "            TempPooling(\n",
    "                pooling=self.specs['pooling'],\n",
    "                pool_type=self.specs['pool_type'],\n",
    "                stride=self.specs['stride'],\n",
    "                padding=self.specs['padding'],\n",
    "            ),\n",
    "            tf.keras.layers.Dropout(self.specs['dropout'], noise_shape=None),\n",
    "            Dense(size=self.out_dim, nonlin=tf.identity, specs=self.specs)\n",
    "        )\n",
    "        \n",
    "        # self.design = ModelDesign(\n",
    "        #     self.inputs,\n",
    "        #     LayerDesign(tf.squeeze, axis=1),\n",
    "        #     tf.keras.layers.Bidirectional(\n",
    "        #         tf.keras.layers.LSTM(\n",
    "        #             self.specs['n_latent'],\n",
    "        #             bias_regularizer='l1',\n",
    "        #             return_sequences=True,\n",
    "        #             kernel_regularizer=tf.keras.regularizers.L1(.01),\n",
    "        #             recurrent_regularizer=tf.keras.regularizers.L1(.01),\n",
    "        #             dropout=0.4,\n",
    "        #             recurrent_dropout=0.4,\n",
    "        #         ),\n",
    "        #         merge_mode='sum'\n",
    "        #     ),\n",
    "        #     LayerDesign(tf.expand_dims, axis=1),\n",
    "        #     ParallelDesign(\n",
    "        #         LFTConv(\n",
    "        #             size=self.specs['n_latent'],\n",
    "        #             nonlin=self.specs['nonlin'],\n",
    "        #             filter_length=self.specs['filter_length']//2,\n",
    "        #             padding=self.specs['padding'],\n",
    "        #             specs=self.specs\n",
    "        #         ),\n",
    "        #         LFTConv(\n",
    "        #             size=self.specs['n_latent'],\n",
    "        #             nonlin=self.specs['nonlin'],\n",
    "        #             filter_length=self.specs['filter_length'],\n",
    "        #             padding=self.specs['padding'],\n",
    "        #             specs=self.specs\n",
    "        #         ),\n",
    "        #         LFTConv(\n",
    "        #             size=self.specs['n_latent'],\n",
    "        #             nonlin=self.specs['nonlin'],\n",
    "        #             filter_length=self.specs['filter_length']*2,\n",
    "        #             padding=self.specs['padding'],\n",
    "        #             specs=self.specs\n",
    "        #         ),\n",
    "        #     ),\n",
    "        #     tf.keras.layers.DepthwiseConv2D((1, 361), padding='valid', activation='relu', kernel_regularizer='l1'),\n",
    "        #     tf.keras.layers.Dropout(self.specs['dropout'], noise_shape=None),\n",
    "        #     tf.keras.layers.Flatten(),\n",
    "        #     tf.keras.layers.Dense(self.out_dim, kernel_regularizer='l1'),\n",
    "        # )\n",
    "        \n",
    "        # self.design = ModelDesign(\n",
    "        #     self.inputs,\n",
    "        #     LayerDesign(tf.squeeze, axis=1),\n",
    "        #     tf.keras.layers.Bidirectional(\n",
    "        #         tf.keras.layers.LSTM(\n",
    "        #             self.specs['n_latent'],\n",
    "        #             bias_regularizer='l1',\n",
    "        #             return_sequences=True,\n",
    "        #             kernel_regularizer=tf.keras.regularizers.L1(.01),\n",
    "        #             recurrent_regularizer=tf.keras.regularizers.L1(.01),\n",
    "        #             dropout=0.4,\n",
    "        #             recurrent_dropout=0.4,\n",
    "        #         ),\n",
    "        #         merge_mode='sum'\n",
    "        #     ),\n",
    "        #     LayerDesign(tf.expand_dims, axis=1),\n",
    "        #     LFTConv(\n",
    "        #         size=self.specs['n_latent'],\n",
    "        #         nonlin=self.specs['nonlin'],\n",
    "        #         filter_length=self.specs['filter_length']*2,\n",
    "        #         padding=self.specs['padding'],\n",
    "        #         specs=self.specs\n",
    "        #     ),\n",
    "        #     tf.keras.layers.DepthwiseConv2D((1, 361), padding='valid', activation='relu', kernel_regularizer='l1'),\n",
    "        #     tf.keras.layers.Dropout(self.specs['dropout'], noise_shape=None),\n",
    "        #     tf.keras.layers.Flatten(),\n",
    "        #     tf.keras.layers.Dense(self.out_dim, kernel_regularizer='l1'),\n",
    "        # )\n",
    "        \n",
    "\n",
    "        return self.design()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting reg for fc, to l1\n",
      "Setting reg for tconv, to l1\n",
      "Built: tconv input: (None, 1, 361, 32)\n",
      "Setting reg for tconv, to l1\n",
      "Built: tconv input: (None, 1, 361, 32)\n",
      "Setting reg for tconv, to l1\n",
      "Built: tconv input: (None, 1, 361, 32)\n",
      "Built: fc input: (None, 1, 73, 32)\n",
      "Setting reg for fc, to l1\n",
      "Setting reg for tconv, to l1\n",
      "Built: tconv input: (None, 1, 361, 32)\n",
      "Setting reg for tconv, to l1\n",
      "Built: tconv input: (None, 1, 361, 32)\n",
      "Setting reg for tconv, to l1\n",
      "Built: tconv input: (None, 1, 361, 32)\n",
      "Built: fc input: (None, 1, 73, 32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "361"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LFCNNm(dataset, lf_params)\n",
    "model.build_graph().shape\n",
    "model.inputs.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting reg for fc, to l1\n",
      "Setting reg for tconv, to l1\n",
      "Built: tconv input: (None, 1, 361, 32)\n",
      "Setting reg for tconv, to l1\n",
      "Built: tconv input: (None, 1, 361, 32)\n",
      "Setting reg for tconv, to l1\n",
      "Built: tconv input: (None, 1, 361, 32)\n",
      "Built: fc input: (None, 1, 73, 32)\n",
      "Input shape: (1, 361, 204)\n",
      "y_pred: (None, 8)\n",
      "Initialization complete!\n",
      "Epoch 1/100\n",
      "100/100 - 48s - loss: 37.7052 - cat_ACC: 0.1358 - val_loss: 30.0122 - val_cat_ACC: 0.1000 - 48s/epoch - 481ms/step\n",
      "Epoch 2/100\n",
      "100/100 - 47s - loss: 23.9661 - cat_ACC: 0.2185 - val_loss: 18.1793 - val_cat_ACC: 0.3154 - 47s/epoch - 468ms/step\n",
      "Epoch 3/100\n",
      "100/100 - 46s - loss: 13.8301 - cat_ACC: 0.3760 - val_loss: 9.9082 - val_cat_ACC: 0.5154 - 46s/epoch - 462ms/step\n",
      "Epoch 4/100\n",
      "100/100 - 48s - loss: 7.3029 - cat_ACC: 0.5582 - val_loss: 5.2342 - val_cat_ACC: 0.6846 - 48s/epoch - 477ms/step\n",
      "Epoch 5/100\n",
      "100/100 - 45s - loss: 4.1885 - cat_ACC: 0.7194 - val_loss: 3.6553 - val_cat_ACC: 0.7538 - 45s/epoch - 449ms/step\n",
      "Epoch 6/100\n",
      "100/100 - 46s - loss: 3.2409 - cat_ACC: 0.8163 - val_loss: 3.0967 - val_cat_ACC: 0.8077 - 46s/epoch - 455ms/step\n",
      "Epoch 7/100\n",
      "100/100 - 45s - loss: 2.7933 - cat_ACC: 0.8791 - val_loss: 2.7805 - val_cat_ACC: 0.7923 - 45s/epoch - 450ms/step\n",
      "Epoch 8/100\n",
      "100/100 - 43s - loss: 2.5078 - cat_ACC: 0.9093 - val_loss: 2.5659 - val_cat_ACC: 0.8231 - 43s/epoch - 427ms/step\n",
      "Epoch 9/100\n",
      "100/100 - 40s - loss: 2.3109 - cat_ACC: 0.9300 - val_loss: 2.4019 - val_cat_ACC: 0.8385 - 40s/epoch - 403ms/step\n",
      "Epoch 10/100\n",
      "100/100 - 42s - loss: 2.1539 - cat_ACC: 0.9416 - val_loss: 2.2572 - val_cat_ACC: 0.8538 - 42s/epoch - 421ms/step\n",
      "Epoch 11/100\n",
      "100/100 - 44s - loss: 2.0164 - cat_ACC: 0.9518 - val_loss: 2.1411 - val_cat_ACC: 0.8462 - 44s/epoch - 437ms/step\n",
      "Epoch 12/100\n",
      "100/100 - 44s - loss: 1.8944 - cat_ACC: 0.9584 - val_loss: 2.0423 - val_cat_ACC: 0.8462 - 44s/epoch - 438ms/step\n",
      "Epoch 13/100\n",
      "100/100 - 45s - loss: 1.7809 - cat_ACC: 0.9643 - val_loss: 1.9402 - val_cat_ACC: 0.8615 - 45s/epoch - 448ms/step\n",
      "Epoch 14/100\n",
      "100/100 - 40s - loss: 1.6826 - cat_ACC: 0.9686 - val_loss: 1.8406 - val_cat_ACC: 0.8538 - 40s/epoch - 400ms/step\n",
      "Epoch 15/100\n",
      "100/100 - 43s - loss: 1.5890 - cat_ACC: 0.9701 - val_loss: 1.7654 - val_cat_ACC: 0.8615 - 43s/epoch - 432ms/step\n",
      "Epoch 16/100\n",
      "100/100 - 45s - loss: 1.5048 - cat_ACC: 0.9713 - val_loss: 1.6642 - val_cat_ACC: 0.9000 - 45s/epoch - 448ms/step\n",
      "Epoch 17/100\n",
      "100/100 - 45s - loss: 1.4279 - cat_ACC: 0.9719 - val_loss: 1.6101 - val_cat_ACC: 0.8923 - 45s/epoch - 453ms/step\n",
      "Epoch 18/100\n",
      "100/100 - 46s - loss: 1.3625 - cat_ACC: 0.9740 - val_loss: 1.5299 - val_cat_ACC: 0.9000 - 46s/epoch - 456ms/step\n",
      "Epoch 19/100\n",
      "100/100 - 46s - loss: 1.3041 - cat_ACC: 0.9710 - val_loss: 1.4874 - val_cat_ACC: 0.8923 - 46s/epoch - 456ms/step\n",
      "Epoch 20/100\n",
      "100/100 - 46s - loss: 1.2428 - cat_ACC: 0.9755 - val_loss: 1.4122 - val_cat_ACC: 0.9154 - 46s/epoch - 461ms/step\n",
      "Epoch 21/100\n",
      "100/100 - 43s - loss: 1.1918 - cat_ACC: 0.9784 - val_loss: 1.3694 - val_cat_ACC: 0.8923 - 43s/epoch - 432ms/step\n",
      "Epoch 22/100\n",
      "100/100 - 44s - loss: 1.1545 - cat_ACC: 0.9752 - val_loss: 1.3369 - val_cat_ACC: 0.8846 - 44s/epoch - 439ms/step\n",
      "Epoch 23/100\n",
      "100/100 - 43s - loss: 1.1102 - cat_ACC: 0.9770 - val_loss: 1.2910 - val_cat_ACC: 0.8923 - 43s/epoch - 430ms/step\n",
      "Epoch 24/100\n",
      "100/100 - 43s - loss: 1.0825 - cat_ACC: 0.9733 - val_loss: 1.2702 - val_cat_ACC: 0.8769 - 43s/epoch - 429ms/step\n",
      "Epoch 25/100\n",
      "100/100 - 43s - loss: 1.0564 - cat_ACC: 0.9725 - val_loss: 1.2486 - val_cat_ACC: 0.8769 - 43s/epoch - 435ms/step\n",
      "Epoch 26/100\n",
      "100/100 - 43s - loss: 1.0229 - cat_ACC: 0.9731 - val_loss: 1.2126 - val_cat_ACC: 0.8846 - 43s/epoch - 435ms/step\n",
      "Epoch 27/100\n",
      "100/100 - 46s - loss: 0.9917 - cat_ACC: 0.9766 - val_loss: 1.1993 - val_cat_ACC: 0.8769 - 46s/epoch - 455ms/step\n",
      "Epoch 28/100\n",
      "100/100 - 45s - loss: 0.9680 - cat_ACC: 0.9738 - val_loss: 1.1670 - val_cat_ACC: 0.8769 - 45s/epoch - 450ms/step\n",
      "Epoch 29/100\n",
      "100/100 - 42s - loss: 0.9431 - cat_ACC: 0.9733 - val_loss: 1.1619 - val_cat_ACC: 0.8692 - 42s/epoch - 421ms/step\n",
      "Epoch 30/100\n",
      "100/100 - 42s - loss: 0.9195 - cat_ACC: 0.9761 - val_loss: 1.1295 - val_cat_ACC: 0.8923 - 42s/epoch - 419ms/step\n",
      "Epoch 31/100\n",
      "100/100 - 46s - loss: 0.8962 - cat_ACC: 0.9770 - val_loss: 1.1221 - val_cat_ACC: 0.8615 - 46s/epoch - 459ms/step\n",
      "Epoch 32/100\n",
      "100/100 - 38s - loss: 0.8698 - cat_ACC: 0.9763 - val_loss: 1.0807 - val_cat_ACC: 0.8692 - 38s/epoch - 381ms/step\n",
      "Epoch 33/100\n",
      "100/100 - 38s - loss: 0.8502 - cat_ACC: 0.9733 - val_loss: 1.0840 - val_cat_ACC: 0.8615 - 38s/epoch - 381ms/step\n",
      "Epoch 34/100\n",
      "100/100 - 37s - loss: 0.8258 - cat_ACC: 0.9762 - val_loss: 1.0528 - val_cat_ACC: 0.8615 - 37s/epoch - 373ms/step\n",
      "Epoch 35/100\n",
      "100/100 - 42s - loss: 0.8230 - cat_ACC: 0.9726 - val_loss: 1.0417 - val_cat_ACC: 0.8692 - 42s/epoch - 422ms/step\n",
      "Epoch 36/100\n",
      "100/100 - 42s - loss: 0.8087 - cat_ACC: 0.9733 - val_loss: 1.0460 - val_cat_ACC: 0.8692 - 42s/epoch - 423ms/step\n",
      "Epoch 37/100\n",
      "100/100 - 41s - loss: 0.7983 - cat_ACC: 0.9736 - val_loss: 1.0689 - val_cat_ACC: 0.8538 - 41s/epoch - 413ms/step\n",
      "Epoch 38/100\n",
      "100/100 - 42s - loss: 0.7908 - cat_ACC: 0.9740 - val_loss: 1.0366 - val_cat_ACC: 0.8692 - 42s/epoch - 418ms/step\n",
      "Epoch 39/100\n",
      "100/100 - 43s - loss: 0.7888 - cat_ACC: 0.9736 - val_loss: 1.0295 - val_cat_ACC: 0.8692 - 43s/epoch - 426ms/step\n",
      "Epoch 40/100\n",
      "100/100 - 42s - loss: 0.7853 - cat_ACC: 0.9688 - val_loss: 0.9912 - val_cat_ACC: 0.8846 - 42s/epoch - 423ms/step\n",
      "Epoch 41/100\n",
      "100/100 - 42s - loss: 0.7723 - cat_ACC: 0.9724 - val_loss: 1.0134 - val_cat_ACC: 0.8615 - 42s/epoch - 419ms/step\n",
      "Epoch 42/100\n",
      "100/100 - 42s - loss: 0.7684 - cat_ACC: 0.9710 - val_loss: 1.0053 - val_cat_ACC: 0.8769 - 42s/epoch - 417ms/step\n",
      "Epoch 43/100\n",
      "100/100 - 45s - loss: 0.7591 - cat_ACC: 0.9713 - val_loss: 1.0028 - val_cat_ACC: 0.8538 - 45s/epoch - 447ms/step\n",
      "Epoch 44/100\n",
      "100/100 - 45s - loss: 0.7522 - cat_ACC: 0.9683 - val_loss: 0.9849 - val_cat_ACC: 0.8846 - 45s/epoch - 448ms/step\n",
      "Epoch 45/100\n",
      "100/100 - 42s - loss: 0.7465 - cat_ACC: 0.9708 - val_loss: 1.0169 - val_cat_ACC: 0.8692 - 42s/epoch - 422ms/step\n",
      "Epoch 46/100\n",
      "100/100 - 42s - loss: 0.7355 - cat_ACC: 0.9719 - val_loss: 0.9938 - val_cat_ACC: 0.8692 - 42s/epoch - 424ms/step\n",
      "Epoch 47/100\n",
      "100/100 - 42s - loss: 0.7363 - cat_ACC: 0.9709 - val_loss: 0.9940 - val_cat_ACC: 0.8692 - 42s/epoch - 415ms/step\n",
      "Epoch 48/100\n",
      "100/100 - 39s - loss: 0.7387 - cat_ACC: 0.9672 - val_loss: 1.0051 - val_cat_ACC: 0.8538 - 39s/epoch - 386ms/step\n",
      "Epoch 49/100\n",
      "100/100 - 40s - loss: 0.7201 - cat_ACC: 0.9725 - val_loss: 0.9962 - val_cat_ACC: 0.8692 - 40s/epoch - 396ms/step\n",
      "Epoch 50/100\n",
      "100/100 - 41s - loss: 0.7099 - cat_ACC: 0.9734 - val_loss: 0.9784 - val_cat_ACC: 0.8692 - 41s/epoch - 413ms/step\n",
      "Epoch 51/100\n",
      "100/100 - 39s - loss: 0.7067 - cat_ACC: 0.9740 - val_loss: 0.9647 - val_cat_ACC: 0.8615 - 39s/epoch - 394ms/step\n",
      "Epoch 52/100\n",
      "100/100 - 37s - loss: 0.7098 - cat_ACC: 0.9700 - val_loss: 0.9613 - val_cat_ACC: 0.8769 - 37s/epoch - 374ms/step\n",
      "Epoch 53/100\n",
      "100/100 - 40s - loss: 0.7020 - cat_ACC: 0.9710 - val_loss: 0.9811 - val_cat_ACC: 0.8615 - 40s/epoch - 400ms/step\n",
      "Epoch 54/100\n",
      "100/100 - 41s - loss: 0.7054 - cat_ACC: 0.9688 - val_loss: 0.9742 - val_cat_ACC: 0.8615 - 41s/epoch - 407ms/step\n",
      "Epoch 55/100\n",
      "100/100 - 41s - loss: 0.7034 - cat_ACC: 0.9706 - val_loss: 0.9526 - val_cat_ACC: 0.8769 - 41s/epoch - 409ms/step\n",
      "Epoch 56/100\n",
      "100/100 - 41s - loss: 0.6990 - cat_ACC: 0.9710 - val_loss: 0.9477 - val_cat_ACC: 0.8615 - 41s/epoch - 407ms/step\n",
      "Epoch 57/100\n",
      "100/100 - 41s - loss: 0.6901 - cat_ACC: 0.9747 - val_loss: 0.9325 - val_cat_ACC: 0.8769 - 41s/epoch - 407ms/step\n",
      "Epoch 58/100\n",
      "100/100 - 41s - loss: 0.6922 - cat_ACC: 0.9723 - val_loss: 0.9255 - val_cat_ACC: 0.8615 - 41s/epoch - 411ms/step\n",
      "Epoch 59/100\n",
      "100/100 - 41s - loss: 0.6881 - cat_ACC: 0.9716 - val_loss: 0.9570 - val_cat_ACC: 0.8615 - 41s/epoch - 408ms/step\n",
      "Epoch 60/100\n",
      "100/100 - 41s - loss: 0.6880 - cat_ACC: 0.9734 - val_loss: 0.9587 - val_cat_ACC: 0.8462 - 41s/epoch - 408ms/step\n",
      "Epoch 61/100\n",
      "100/100 - 41s - loss: 0.6886 - cat_ACC: 0.9686 - val_loss: 0.9612 - val_cat_ACC: 0.8615 - 41s/epoch - 408ms/step\n",
      "Epoch 62/100\n",
      "100/100 - 41s - loss: 0.6883 - cat_ACC: 0.9703 - val_loss: 0.9465 - val_cat_ACC: 0.8615 - 41s/epoch - 408ms/step\n",
      "Epoch 63/100\n",
      "100/100 - 41s - loss: 0.6842 - cat_ACC: 0.9700 - val_loss: 0.9484 - val_cat_ACC: 0.8538 - 41s/epoch - 405ms/step\n",
      "Epoch 64/100\n",
      "100/100 - 41s - loss: 0.6884 - cat_ACC: 0.9706 - val_loss: 0.9110 - val_cat_ACC: 0.8769 - 41s/epoch - 413ms/step\n",
      "Epoch 65/100\n",
      "100/100 - 43s - loss: 0.6861 - cat_ACC: 0.9700 - val_loss: 0.9308 - val_cat_ACC: 0.8692 - 43s/epoch - 429ms/step\n",
      "Epoch 66/100\n",
      "100/100 - 39s - loss: 0.6813 - cat_ACC: 0.9703 - val_loss: 0.9445 - val_cat_ACC: 0.8615 - 39s/epoch - 388ms/step\n",
      "Epoch 67/100\n",
      "100/100 - 39s - loss: 0.6821 - cat_ACC: 0.9713 - val_loss: 0.9268 - val_cat_ACC: 0.8692 - 39s/epoch - 385ms/step\n",
      "Epoch 68/100\n",
      "100/100 - 44s - loss: 0.6772 - cat_ACC: 0.9721 - val_loss: 0.9029 - val_cat_ACC: 0.8846 - 44s/epoch - 438ms/step\n",
      "Epoch 69/100\n",
      "100/100 - 43s - loss: 0.6755 - cat_ACC: 0.9709 - val_loss: 0.9183 - val_cat_ACC: 0.8615 - 43s/epoch - 432ms/step\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/user/Projects/FingerMovementDecoder/dirty_field/LFCNN-m.ipynb Cell 6'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/user/Projects/FingerMovementDecoder/dirty_field/LFCNN-m.ipynb#ch0000005?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m LFCNNm(dataset, lf_params)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/user/Projects/FingerMovementDecoder/dirty_field/LFCNN-m.ipynb#ch0000005?line=1'>2</a>\u001b[0m model\u001b[39m.\u001b[39mbuild()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/user/Projects/FingerMovementDecoder/dirty_field/LFCNN-m.ipynb#ch0000005?line=2'>3</a>\u001b[0m model\u001b[39m.\u001b[39;49mtrain(n_epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, eval_step\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, early_stopping\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n",
      "File \u001b[0;32m~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/mneflow/models.py:215\u001b[0m, in \u001b[0;36mBaseModel.train\u001b[0;34m(self, n_epochs, eval_step, min_delta, early_stopping, mode)\u001b[0m\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/mneflow/models.py?line=208'>209</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_params \u001b[39m=\u001b[39m [n_epochs, eval_step, early_stopping, mode]\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/mneflow/models.py?line=211'>212</a>\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39msingle_fold\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/mneflow/models.py?line=212'>213</a>\u001b[0m     \u001b[39m#self.dataset.train, self.dataset.val = self.dataset._build_dataset()\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/mneflow/models.py?line=214'>215</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mt_hist \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkm\u001b[39m.\u001b[39;49mfit(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset\u001b[39m.\u001b[39;49mtrain,\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/mneflow/models.py?line=215'>216</a>\u001b[0m                            validation_data\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset\u001b[39m.\u001b[39;49mval,\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/mneflow/models.py?line=216'>217</a>\u001b[0m                            epochs\u001b[39m=\u001b[39;49mn_epochs, steps_per_epoch\u001b[39m=\u001b[39;49meval_step,\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/mneflow/models.py?line=217'>218</a>\u001b[0m                            shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, \n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/mneflow/models.py?line=218'>219</a>\u001b[0m                            validation_steps\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset\u001b[39m.\u001b[39;49mvalidation_steps,\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/mneflow/models.py?line=219'>220</a>\u001b[0m                            callbacks\u001b[39m=\u001b[39;49m[stop_early], verbose\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/mneflow/models.py?line=220'>221</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mv_loss, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mv_metric \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39mval)\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/mneflow/models.py?line=221'>222</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mv_loss_sd \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=61'>62</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=62'>63</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=63'>64</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/keras/engine/training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/keras/engine/training.py?line=1376'>1377</a>\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/keras/engine/training.py?line=1377'>1378</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/keras/engine/training.py?line=1378'>1379</a>\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/keras/engine/training.py?line=1379'>1380</a>\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[1;32m   <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/keras/engine/training.py?line=1380'>1381</a>\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/keras/engine/training.py?line=1381'>1382</a>\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/keras/engine/training.py?line=1382'>1383</a>\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/keras/engine/training.py?line=1383'>1384</a>\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/keras/engine/training.py?line=1384'>1385</a>\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/keras/engine/training.py?line=1385'>1386</a>\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=147'>148</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=148'>149</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=149'>150</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=150'>151</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=151'>152</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=911'>912</a>\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=913'>914</a>\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=914'>915</a>\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=916'>917</a>\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=917'>918</a>\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=943'>944</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=944'>945</a>\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=945'>946</a>\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=946'>947</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=947'>948</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=948'>949</a>\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=949'>950</a>\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=950'>951</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=2952'>2953</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=2953'>2954</a>\u001b[0m   (graph_function,\n\u001b[1;32m   <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=2954'>2955</a>\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=2955'>2956</a>\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=2956'>2957</a>\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1848'>1849</a>\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1849'>1850</a>\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1850'>1851</a>\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1851'>1852</a>\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1852'>1853</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1853'>1854</a>\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1854'>1855</a>\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1855'>1856</a>\u001b[0m     args,\n\u001b[1;32m   <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1856'>1857</a>\u001b[0m     possible_gradient_type,\n\u001b[1;32m   <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1857'>1858</a>\u001b[0m     executing_eagerly)\n\u001b[1;32m   <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1858'>1859</a>\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=496'>497</a>\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=497'>498</a>\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=498'>499</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=499'>500</a>\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=500'>501</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=501'>502</a>\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=502'>503</a>\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=503'>504</a>\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=504'>505</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=505'>506</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=506'>507</a>\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=507'>508</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=510'>511</a>\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=511'>512</a>\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/execute.py?line=51'>52</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/execute.py?line=52'>53</a>\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/execute.py?line=53'>54</a>\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/execute.py?line=54'>55</a>\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/execute.py?line=55'>56</a>\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/execute.py?line=56'>57</a>\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = LFCNNm(dataset, lf_params)\n",
    "model.build()\n",
    "model.train(n_epochs=100, eval_step=100, early_stopping=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting reg for dmx, to l1\n",
      "Built: dmx input: (None, 1, 361, 204)\n",
      "Setting reg for tconv, to l1\n",
      "Built: tconv input: (None, 1, 361, 32)\n",
      "Setting reg for fc, to l1\n",
      "Built: fc input: (None, 1, 73, 32)\n",
      "Input shape: (1, 361, 204)\n",
      "y_pred: (None, 8)\n",
      "Initialization complete!\n",
      "Epoch 1/25\n",
      "100/100 - 5s - loss: 5.3246 - cat_ACC: 0.1810 - val_loss: 4.8471 - val_cat_ACC: 0.3308 - 5s/epoch - 47ms/step\n",
      "Epoch 2/25\n",
      "100/100 - 3s - loss: 4.5279 - cat_ACC: 0.3858 - val_loss: 4.2526 - val_cat_ACC: 0.5154 - 3s/epoch - 32ms/step\n",
      "Epoch 3/25\n",
      "100/100 - 3s - loss: 3.8354 - cat_ACC: 0.6004 - val_loss: 3.6906 - val_cat_ACC: 0.6615 - 3s/epoch - 31ms/step\n",
      "Epoch 4/25\n",
      "100/100 - 3s - loss: 3.2909 - cat_ACC: 0.7507 - val_loss: 3.2359 - val_cat_ACC: 0.7846 - 3s/epoch - 30ms/step\n",
      "Epoch 5/25\n",
      "100/100 - 3s - loss: 2.8711 - cat_ACC: 0.8366 - val_loss: 2.8711 - val_cat_ACC: 0.8462 - 3s/epoch - 32ms/step\n",
      "Epoch 6/25\n",
      "100/100 - 3s - loss: 2.5458 - cat_ACC: 0.8862 - val_loss: 2.5833 - val_cat_ACC: 0.8769 - 3s/epoch - 30ms/step\n",
      "Epoch 7/25\n",
      "100/100 - 3s - loss: 2.2644 - cat_ACC: 0.9213 - val_loss: 2.3437 - val_cat_ACC: 0.8846 - 3s/epoch - 31ms/step\n",
      "Epoch 8/25\n",
      "100/100 - 3s - loss: 2.0273 - cat_ACC: 0.9403 - val_loss: 2.1232 - val_cat_ACC: 0.9000 - 3s/epoch - 31ms/step\n",
      "Epoch 9/25\n",
      "100/100 - 3s - loss: 1.8162 - cat_ACC: 0.9563 - val_loss: 1.9346 - val_cat_ACC: 0.9077 - 3s/epoch - 30ms/step\n",
      "Epoch 10/25\n",
      "100/100 - 3s - loss: 1.6321 - cat_ACC: 0.9634 - val_loss: 1.7678 - val_cat_ACC: 0.9077 - 3s/epoch - 31ms/step\n",
      "Epoch 11/25\n",
      "100/100 - 3s - loss: 1.4686 - cat_ACC: 0.9712 - val_loss: 1.6116 - val_cat_ACC: 0.9154 - 3s/epoch - 30ms/step\n",
      "Epoch 12/25\n",
      "100/100 - 3s - loss: 1.3224 - cat_ACC: 0.9756 - val_loss: 1.4733 - val_cat_ACC: 0.9077 - 3s/epoch - 30ms/step\n",
      "Epoch 13/25\n",
      "100/100 - 3s - loss: 1.1995 - cat_ACC: 0.9759 - val_loss: 1.3536 - val_cat_ACC: 0.9000 - 3s/epoch - 30ms/step\n",
      "Epoch 14/25\n",
      "100/100 - 3s - loss: 1.0854 - cat_ACC: 0.9784 - val_loss: 1.2485 - val_cat_ACC: 0.8923 - 3s/epoch - 31ms/step\n",
      "Epoch 15/25\n",
      "100/100 - 3s - loss: 0.9894 - cat_ACC: 0.9810 - val_loss: 1.1622 - val_cat_ACC: 0.8923 - 3s/epoch - 30ms/step\n",
      "Epoch 16/25\n",
      "100/100 - 3s - loss: 0.9079 - cat_ACC: 0.9813 - val_loss: 1.0884 - val_cat_ACC: 0.9000 - 3s/epoch - 29ms/step\n",
      "Epoch 17/25\n",
      "100/100 - 3s - loss: 0.8383 - cat_ACC: 0.9810 - val_loss: 1.0255 - val_cat_ACC: 0.8846 - 3s/epoch - 29ms/step\n",
      "Epoch 18/25\n",
      "100/100 - 3s - loss: 0.7749 - cat_ACC: 0.9838 - val_loss: 0.9694 - val_cat_ACC: 0.8923 - 3s/epoch - 28ms/step\n",
      "Epoch 19/25\n",
      "100/100 - 3s - loss: 0.7251 - cat_ACC: 0.9862 - val_loss: 0.9347 - val_cat_ACC: 0.8923 - 3s/epoch - 30ms/step\n",
      "Epoch 20/25\n",
      "100/100 - 3s - loss: 0.6840 - cat_ACC: 0.9868 - val_loss: 0.8848 - val_cat_ACC: 0.8846 - 3s/epoch - 29ms/step\n",
      "Epoch 21/25\n",
      "100/100 - 3s - loss: 0.6450 - cat_ACC: 0.9846 - val_loss: 0.8509 - val_cat_ACC: 0.8769 - 3s/epoch - 30ms/step\n",
      "Epoch 22/25\n",
      "100/100 - 3s - loss: 0.6200 - cat_ACC: 0.9841 - val_loss: 0.8237 - val_cat_ACC: 0.8923 - 3s/epoch - 29ms/step\n",
      "Epoch 23/25\n",
      "100/100 - 3s - loss: 0.5906 - cat_ACC: 0.9857 - val_loss: 0.8038 - val_cat_ACC: 0.8846 - 3s/epoch - 30ms/step\n",
      "Epoch 24/25\n",
      "100/100 - 3s - loss: 0.5736 - cat_ACC: 0.9852 - val_loss: 0.7830 - val_cat_ACC: 0.8769 - 3s/epoch - 30ms/step\n",
      "Epoch 25/25\n",
      "100/100 - 3s - loss: 0.5513 - cat_ACC: 0.9869 - val_loss: 0.7721 - val_cat_ACC: 0.8692 - 3s/epoch - 30ms/step\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.7721 - cat_ACC: 0.8692\n",
      "Training complete: loss: 0.7721281051635742, Metric: 0.8692307472229004\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5001 - cat_ACC: 1.0000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7659 - cat_ACC: 0.8910\n",
      "Updating log: test loss: 0.7659 test metric: 0.8910\n"
     ]
    }
   ],
   "source": [
    "model = LFCNN(dataset, lf_params)\n",
    "model.build()\n",
    "model.train(n_epochs=25, eval_step=100, early_stopping=5)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "25b6c1d617e3cb25e4067864bcd46322e1b7da41afdae0cf7c23b941b0b9b767"
  },
  "kernelspec": {
   "display_name": "FingerMovementsDecoder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
