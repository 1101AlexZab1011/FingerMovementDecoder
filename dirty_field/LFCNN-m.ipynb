{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-12 22:46:50.700835: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-12 22:46:50.700867: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "current_dir = os.path.dirname(os.path.abspath('./'))\n",
    "if not current_dir in sys.path:\n",
    "    sys.path.append(current_dir)\n",
    "\n",
    "import mneflow as mf\n",
    "import mneflow\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from mneflow.models import BaseModel, LFCNN\n",
    "from utils.machine_learning.designer import ModelDesign, ParallelDesign, LayerDesign\n",
    "from utils.machine_learning.analyzer import ModelAnalyzer\n",
    "from mneflow.layers import DeMixing, LFTConv, TempPooling, Dense, VARConv\n",
    "from mne.datasets import multimodal\n",
    "import mne\n",
    "from utils.machine_learning.confusion import ConfusionEstimator\n",
    "from utils.machine_learning import one_hot_decoder\n",
    "import sklearn.metrics as sm\n",
    "import tensorflow.keras.regularizers as k_reg\n",
    "from tensorflow.keras.layers import SeparableConv2D, Conv2D, DepthwiseConv2D\n",
    "from tensorflow.keras.layers import Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras import constraints, layers\n",
    "from tensorflow.keras.initializers import Constant\n",
    "from tensorflow.keras.layers import Activation, Permute, Dropout\n",
    "from mne import channels, evoked, create_info\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from tensorflow.keras.layers import SeparableConv2D, DepthwiseConv2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import SpatialDropout2D\n",
    "\n",
    "from scipy.signal import freqz, welch\n",
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting reg for fc, to l1\n",
      "Setting reg for fc, to l1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 4])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_times = 200\n",
    "n_channels = 204\n",
    "out_dim = 4\n",
    "\n",
    "specs = dict()\n",
    "specs.setdefault('filter_length', 7)\n",
    "specs.setdefault('n_latent', 32)\n",
    "specs.setdefault('pooling', 3)\n",
    "specs.setdefault('stride', 3)\n",
    "specs.setdefault('padding', 'SAME')\n",
    "specs.setdefault('pool_type', 'max')\n",
    "specs.setdefault('nonlin', tf.nn.relu)\n",
    "specs.setdefault('l1', 3e-4)\n",
    "specs.setdefault('l2', 0)\n",
    "specs.setdefault('l1_scope', ['fc', 'demix', 'lf_conv'])\n",
    "specs.setdefault('l2_scope', [])\n",
    "specs.setdefault('maxnorm_scope', [])\n",
    "specs.setdefault('dropout', .4)\n",
    "\n",
    "lfcnnd = ModelDesign(\n",
    "    tf.keras.Input(shape=(1, n_times, n_channels)),\n",
    "    DeMixing(size=specs['n_latent'], nonlin=tf.identity, axis=3, specs=specs),\n",
    "    LFTConv(\n",
    "        size=specs['n_latent'],\n",
    "        nonlin=specs['nonlin'],\n",
    "        filter_length=specs['filter_length'],\n",
    "        padding=specs['padding'],\n",
    "        specs=specs\n",
    "    ),\n",
    "    TempPooling(\n",
    "        pooling=specs['pooling'],\n",
    "        pool_type=specs['pool_type'],\n",
    "        stride=specs['stride'],\n",
    "        padding=specs['padding'],\n",
    "    ),\n",
    "    tf.keras.layers.Dropout(specs['dropout'], noise_shape=None),\n",
    "    Dense(size=out_dim, nonlin=tf.identity, specs=specs)\n",
    ")\n",
    "\n",
    "\n",
    "varcnnd = ModelDesign(\n",
    "    tf.keras.Input(shape=(1, n_times, n_channels)),\n",
    "    DeMixing(size=specs['n_latent'], nonlin=tf.identity, axis=3, specs=specs),\n",
    "    VARConv(\n",
    "        size=specs['n_latent'],\n",
    "        nonlin=specs['nonlin'],\n",
    "        filter_length=specs['filter_length'],\n",
    "        padding=specs['padding'],\n",
    "        specs=specs\n",
    "    ),\n",
    "    TempPooling(\n",
    "        pooling=specs['pooling'],\n",
    "        pool_type=specs['pool_type'],\n",
    "        stride=specs['stride'],\n",
    "        padding=specs['padding'],\n",
    "    ),\n",
    "    tf.keras.layers.Dropout(specs['dropout'], noise_shape=None),\n",
    "    Dense(size=out_dim, nonlin=tf.identity, specs=specs)\n",
    ")\n",
    "\n",
    "Deep4_d = ModelDesign(\n",
    "    tf.keras.Input(shape=(1, n_times, n_channels)),\n",
    "    LayerDesign(tf.transpose, [0,3,2,1]),\n",
    "    DepthwiseConv2D(\n",
    "        kernel_size=(1, specs['filter_length']),\n",
    "        depth_multiplier = specs['n_latent'],\n",
    "        strides=1,\n",
    "        padding=specs['padding'],\n",
    "        activation = tf.identity,\n",
    "        kernel_initializer=\"he_uniform\",\n",
    "        bias_initializer=Constant(0.1),\n",
    "        data_format=\"channels_last\",\n",
    "        kernel_regularizer=k_reg.l2(specs['l2'])\n",
    "        #kernel_constraint=\"maxnorm\"\n",
    "    ),\n",
    "    *[ModelDesign(\n",
    "        Conv2D(\n",
    "            filters=specs['n_latent'],\n",
    "            kernel_size=(n_channels, 1),\n",
    "            strides=1,\n",
    "            padding=specs['padding'],\n",
    "            activation=specs['nonlin'],\n",
    "            kernel_initializer=\"he_uniform\",\n",
    "            bias_initializer=Constant(0.1),\n",
    "            data_format=\"channels_last\",\n",
    "            #data_format=\"channels_first\",\n",
    "            kernel_regularizer=k_reg.l2(specs['l2'])\n",
    "        ),\n",
    "        TempPooling(\n",
    "            pooling=specs['pooling'],\n",
    "            pool_type=\"avg\",\n",
    "            stride=specs['stride'],\n",
    "            padding='SAME',\n",
    "        )\n",
    "    ) for _ in range(4)],\n",
    "    Dense(size=out_dim, nonlin=tf.softmax)\n",
    ")\n",
    "\n",
    "\n",
    "specs['pooling'] = 75\n",
    "specs['stride'] = 15\n",
    "FBCSP_ShallowNet_d = ModelDesign(\n",
    "    tf.keras.Input(shape=(1, n_times, n_channels)),\n",
    "    LayerDesign(tf.transpose, [0,3,2,1]),\n",
    "    DepthwiseConv2D(\n",
    "        kernel_size=(1, specs['filter_length']),\n",
    "        depth_multiplier = specs['n_latent'],\n",
    "        strides=1,\n",
    "        padding=\"VALID\",\n",
    "        activation = tf.identity,\n",
    "        kernel_initializer=\"he_uniform\",\n",
    "        bias_initializer=Constant(0.1),\n",
    "        data_format=\"channels_last\",\n",
    "        kernel_regularizer=k_reg.l2(specs['l2'])\n",
    "        #kernel_constraint=\"maxnorm\"\n",
    "    ),\n",
    "    Conv2D(\n",
    "        filters=specs['n_latent'],\n",
    "        kernel_size=(n_channels, 1),\n",
    "        strides=1,\n",
    "        padding=\"VALID\",\n",
    "        activation = tf.square,\n",
    "        kernel_initializer=\"he_uniform\",\n",
    "        bias_initializer=Constant(0.1),\n",
    "        data_format=\"channels_last\",\n",
    "        #data_format=\"channels_first\",\n",
    "        kernel_regularizer=k_reg.l2(specs['l2'])\n",
    "    ),\n",
    "    TempPooling(\n",
    "        pooling=specs['pooling'],\n",
    "        pool_type=\"avg\",\n",
    "        stride=specs['stride'],\n",
    "        padding='SAME',\n",
    "    )\n",
    ")\n",
    "\n",
    "EEGNet_d = ModelDesign(\n",
    "    tf.keras.Input(shape=(1, n_times, n_channels)),\n",
    "    LayerDesign(tf.transpose, [0,3,2,1]),\n",
    "    Conv2D(\n",
    "        specs['n_latent'], \n",
    "        (2, specs['filter_length']), \n",
    "        padding = specs['padding'],\n",
    "        use_bias = False\n",
    "    ),\n",
    "    BatchNormalization(axis = 1),\n",
    "    DepthwiseConv2D(\n",
    "        (n_channels, 1), \n",
    "        use_bias = False, \n",
    "        depth_multiplier = 1,\n",
    "        depthwise_constraint = constraints.MaxNorm(1.)\n",
    "    ),\n",
    "    BatchNormalization(),\n",
    "    Activation('elu'),\n",
    "    AveragePooling2D((1, specs['pooling'])),\n",
    "    Dropout(specs['dropout']),\n",
    "    SeparableConv2D(\n",
    "        specs['n_latent'], \n",
    "        (1, specs['filter_length']//specs[\"pooling\"]),\n",
    "        use_bias = False,\n",
    "        padding = 'same'\n",
    "    ),\n",
    "    BatchNormalization(),\n",
    "    Activation('elu'),\n",
    "    AveragePooling2D((1, specs['pooling']*2)),\n",
    "    Dropout(specs['dropout']),\n",
    "    Flatten(),\n",
    "    Dense(size=out_dim)\n",
    ")\n",
    "\n",
    "EEGNet_d().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Info | 22 non-empty values\n",
      " acq_pars: ACQch001 110113 ACQch002 110112 ACQch003 110111 ACQch004 110122 ...\n",
      " acq_stim: 5 10.000000 500.000000 6 10.000000 500.000000\n",
      " bads: []\n",
      " ch_names: MEG 0113, MEG 0112, MEG 0111, MEG 0122, MEG 0123, MEG 0121, MEG ...\n",
      " chs: 204 GRAD, 102 MAG, 9 STIM, 1 EOG\n",
      " custom_ref_applied: False\n",
      " description: Vectorview system at BioMag\n",
      " dev_head_t: MEG device -> head transform\n",
      " dig: 21 items (3 Cardinal, 4 HPI, 14 Extra)\n",
      " events: 1 item (list)\n",
      " experimenter: neuromag\n",
      " file_id: 4 items (dict)\n",
      " highpass: 0.1 Hz\n",
      " hpi_meas: 1 item (list)\n",
      " hpi_results: 1 item (list)\n",
      " lowpass: 172.2 Hz\n",
      " meas_date: 2011-04-26 11:33:18 UTC\n",
      " meas_id: 4 items (dict)\n",
      " nchan: 316\n",
      " proj_id: 1 item (ndarray)\n",
      " proj_name: test\n",
      " projs: grad_ssp_upright.fif : PCA-v1: on, grad_ssp_upright.fif : ...\n",
      " sfreq: 600.6 Hz\n",
      " subject_info: 9 items (dict)\n",
      ">\n"
     ]
    }
   ],
   "source": [
    "mne.set_log_level(verbose='CRITICAL')\n",
    "fname_raw = os.path.join(multimodal.data_path(), 'multimodal_raw.fif')\n",
    "raw = mne.io.read_raw_fif(fname_raw)\n",
    "\n",
    "cond = raw.acqparser.get_condition(raw, None)\n",
    "# get the list of condition names\n",
    "condition_names = [k for c in cond for k,v in c['event_id'].items()]\n",
    "epochs_list = [mne.Epochs(raw, **c) for c in cond]\n",
    "epochs = mne.concatenate_epochs(epochs_list)\n",
    "print(epochs.info)\n",
    "epochs = epochs.pick_types(meg='grad')\n",
    "\n",
    "X = np.array([])\n",
    "Y = list()\n",
    "for i, epochs in enumerate(epochs_list):\n",
    "    data = epochs.get_data()\n",
    "    if i == 0:\n",
    "        X = data.copy()\n",
    "    else:\n",
    "        X = np.append(X, data, axis=0)\n",
    "    Y += [i for _ in range(data.shape[0])]\n",
    "\n",
    "Y = np.array(Y)\n",
    "\n",
    "sample_matrix = X[0].copy()\n",
    "\n",
    "X = np.array([X[i, epochs._channel_type_idx['grad'], :] for i, _ in enumerate(X)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing from tuple\n",
      "input shapes: X- (940, 204, 361) targets- (940, 1)\n",
      "Preprocessing:\n",
      "Scaling to interval 0.0 - 60.0\n",
      "Splitting sets\n",
      "Preprocessed: (940, 1, 361, 204) (940, 8) folds: 6 x 156\n",
      "936\n",
      "Prepocessed sample shape: (1, 361, 204)\n",
      "Target shape actual/metadata:  (8,) (8,)\n",
      "Saving TFRecord# 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-12 22:47:29.777468: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-03-12 22:47:29.777497: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-03-12 22:47:29.777517: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (arcolinux-machine): /proc/driver/nvidia/version does not exist\n",
      "2022-03-12 22:47:29.777774: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import_opt = dict(savepath='../tfr/',\n",
    "                out_name='mne_sample_epochs',\n",
    "                fs=600,\n",
    "                input_type='trials',\n",
    "                target_type='int',\n",
    "                picks={'meg':'grad'},\n",
    "                scale=True,  # apply baseline_scaling\n",
    "                crop_baseline=True,  # remove baseline interval after scaling\n",
    "                decimate=None,\n",
    "                scale_interval=(0, 60),  # indices in time axis corresponding to baseline interval\n",
    "            #   n_folds=5,  # validation set size set to 20% of all data\n",
    "                n_folds=5,\n",
    "                overwrite=True,\n",
    "                segment=False,\n",
    "                test_set='holdout'\n",
    ")\n",
    "\n",
    "lf_params = dict(n_latent=32, #number of latent factors\n",
    "                filter_length=17, #convolutional filter length in time samples\n",
    "                nonlin = tf.nn.relu,\n",
    "                padding = 'SAME',\n",
    "                pooling = 5,#pooling factor\n",
    "                stride = 5, #stride parameter for pooling layer\n",
    "                pool_type='max',\n",
    "                model_path = import_opt['savepath'],\n",
    "                dropout = .5,\n",
    "                l1_scope = [\"weights\"],\n",
    "                l1=3e-3\n",
    ")\n",
    "\n",
    "\n",
    "meta = mf.produce_tfrecords((X, Y), **import_opt)  \n",
    "dataset = mf.Dataset(meta, train_batch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LFCNNm(LFCNN):\n",
    "    def __init__(self, Dataset, specs=dict()):\n",
    "        self.scope = 'lfcnn'\n",
    "        specs.setdefault('filter_length', 7)\n",
    "        specs.setdefault('n_latent', 32)\n",
    "        specs.setdefault('pooling', 2)\n",
    "        specs.setdefault('stride', 2)\n",
    "        specs.setdefault('padding', 'SAME')\n",
    "        specs.setdefault('pool_type', 'max')\n",
    "        specs.setdefault('nonlin', tf.nn.relu)\n",
    "        specs.setdefault('l1', 3e-4)\n",
    "        specs.setdefault('l2', 0)\n",
    "        specs.setdefault('l1_scope', ['fc', 'demix', 'lf_conv'])\n",
    "        specs.setdefault('l2_scope', [])\n",
    "        specs.setdefault('maxnorm_scope', [])\n",
    "        \n",
    "        super(LFCNNm, self).__init__(Dataset, specs)\n",
    "\n",
    "    def build_graph(self):\n",
    "        \n",
    "        # self.dmx\n",
    "        # self.tconv\n",
    "        # self.pool\n",
    "        # self.fin_fc\n",
    "        \n",
    "        # self.design = ModelDesign(\n",
    "        #     self.inputs,\n",
    "        #     DeMixing(size=self.specs['n_latent'], nonlin=tf.identity, axis=3, specs=self.specs),\n",
    "        #     LFTConv(\n",
    "        #         size=self.specs['n_latent'],\n",
    "        #         nonlin=self.specs['nonlin'],\n",
    "        #         filter_length=self.specs['filter_length'],\n",
    "        #         padding=self.specs['padding'],\n",
    "        #         specs=self.specs\n",
    "        #     ),\n",
    "        #     tf.keras.layers.Dropout(self.specs['dropout'], noise_shape=None),\n",
    "        #     tf.keras.layers.DepthwiseConv2D((1, 361), padding='valid', activation='relu', kernel_regularizer='l1'),\n",
    "        #     tf.keras.layers.Flatten(),\n",
    "        #     tf.keras.layers.Dense(self.out_dim, kernel_regularizer='l1'),\n",
    "        # )\n",
    "        \n",
    "        self.design = ModelDesign(\n",
    "            self.inputs,\n",
    "            DeMixing(size=self.specs['n_latent'], nonlin=tf.identity, axis=3, specs=self.specs),\n",
    "            LFTConv(\n",
    "                size=self.specs['n_latent'],\n",
    "                nonlin=self.specs['nonlin'],\n",
    "                filter_length=self.specs['filter_length'],\n",
    "                padding=self.specs['padding'],\n",
    "                specs=self.specs\n",
    "            ),\n",
    "            tf.keras.layers.Dropout(self.specs['dropout'], noise_shape=None),\n",
    "            LayerDesign(tf.transpose, [0, 1, 3, 2]),\n",
    "            tf.keras.layers.DepthwiseConv2D((1, 32), padding='valid', activation='relu', kernel_regularizer='l1'),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(self.out_dim, kernel_regularizer='l1')\n",
    "        )\n",
    "        \n",
    "        # self.design = ModelDesign(\n",
    "        #     self.inputs,\n",
    "        #     tf.keras.layers.Conv2D(self.specs['n_latent'], (1, 204), padding='same', kernel_regularizer='l1'),\n",
    "        #     tf.keras.layers.DepthwiseConv2D((1, self.specs['filter_length']), padding='same', kernel_regularizer='l1'),\n",
    "        #     # LayerDesign(tf.nn.avg_pool2d, ksize=(1, 1, 10, 1), strides=(1, 1, 10, 1), padding='SAME'),\n",
    "        #     tf.keras.layers.Dropout(self.specs['dropout'], noise_shape=None),\n",
    "        #     # tf.keras.layers.Flatten(),\n",
    "        #     # tf.keras.layers.Dense(self.out_dim),\n",
    "        #     tf.keras.layers.DepthwiseConv2D((1, 361), padding='valid', activation='relu', kernel_regularizer='l1'),\n",
    "        #     tf.keras.layers.Flatten(),\n",
    "        #     tf.keras.layers.Dense(self.out_dim, kernel_regularizer='l1'),\n",
    "        # )\n",
    "        \n",
    "        # self.design = ModelDesign(\n",
    "        #     self.inputs,\n",
    "        #     LayerDesign(tf.squeeze, axis=1),\n",
    "        #     # tf.keras.layers.Bidirectional(\n",
    "        #     tf.keras.layers.LSTM(\n",
    "        #         self.specs['n_latent'],\n",
    "        #         bias_regularizer='l1',\n",
    "        #         return_sequences=True,\n",
    "        #         kernel_regularizer=tf.keras.regularizers.L1(.01),\n",
    "        #         recurrent_regularizer=tf.keras.regularizers.L1(.01),\n",
    "        #         dropout=0.4,\n",
    "        #         recurrent_dropout=0.4,\n",
    "        #     ),\n",
    "        #     #     merge_mode='sum'\n",
    "        #     # ),\n",
    "        #     LayerDesign(tf.expand_dims, axis=1),\n",
    "        #     LFTConv(\n",
    "        #         size=self.specs['n_latent'],\n",
    "        #         nonlin=self.specs['nonlin'],\n",
    "        #         filter_length=self.specs['filter_length'],\n",
    "        #         padding=self.specs['padding'],\n",
    "        #         specs=self.specs\n",
    "        #     ),\n",
    "        #     tf.keras.layers.Dropout(self.specs['dropout'], noise_shape=None),\n",
    "        #     LayerDesign(tf.transpose, [0, 1, 3, 2]),\n",
    "        #     tf.keras.layers.DepthwiseConv2D((1, 32), padding='valid', activation='relu', kernel_regularizer='l1'),\n",
    "        #     tf.keras.layers.Flatten(),\n",
    "        #     tf.keras.layers.Dense(self.out_dim, kernel_regularizer='l1'),\n",
    "        # )\n",
    "        \n",
    "        \n",
    "        # self.design = ModelDesign(\n",
    "        #     self.inputs,\n",
    "        #     LayerDesign(tf.squeeze, axis=1),\n",
    "        #     tf.keras.layers.Bidirectional(\n",
    "        #         tf.keras.layers.LSTM(\n",
    "        #             self.specs['n_latent'],\n",
    "        #             bias_regularizer='l1',\n",
    "        #             return_sequences=True,\n",
    "        #             kernel_regularizer=tf.keras.regularizers.L1(.01),\n",
    "        #             recurrent_regularizer=tf.keras.regularizers.L1(.01),\n",
    "        #             dropout=0.4,\n",
    "        #             recurrent_dropout=0.4,\n",
    "        #         ),\n",
    "        #         merge_mode='sum'\n",
    "        #     ),\n",
    "        #     LayerDesign(tf.expand_dims, axis=1),\n",
    "        #     tf.keras.layers.DepthwiseConv2D((1, self.specs['filter_length']), padding='same', kernel_regularizer='l1'),\n",
    "        #     # LayerDesign(tf.nn.avg_pool2d, ksize=(1, 1, 10, 1), strides=(1, 1, 10, 1), padding='SAME'),\n",
    "        #     tf.keras.layers.Dropout(self.specs['dropout'], noise_shape=None),\n",
    "        #     # tf.keras.layers.Flatten(),\n",
    "        #     # tf.keras.layers.Dense(self.out_dim),\n",
    "        #     tf.keras.layers.DepthwiseConv2D((1, 361), padding='valid', activation='relu', kernel_regularizer='l1'),\n",
    "        #     tf.keras.layers.Flatten(),\n",
    "        #     tf.keras.layers.Dense(self.out_dim, kernel_regularizer='l1'),\n",
    "        # )\n",
    "        \n",
    "        # self.design = ModelDesign(\n",
    "        #     self.inputs,\n",
    "        #     DeMixing(size=self.specs['n_latent'], nonlin=tf.identity, axis=3, specs=self.specs),\n",
    "        #     ParallelDesign(\n",
    "        #         LFTConv(\n",
    "        #             size=self.specs['n_latent'],\n",
    "        #             nonlin=self.specs['nonlin'],\n",
    "        #             filter_length=self.specs['filter_length']//2,\n",
    "        #             padding=self.specs['padding'],\n",
    "        #             specs=self.specs\n",
    "        #         ),\n",
    "        #         LFTConv(\n",
    "        #             size=self.specs['n_latent'],\n",
    "        #             nonlin=self.specs['nonlin'],\n",
    "        #             filter_length=self.specs['filter_length'],\n",
    "        #             padding=self.specs['padding'],\n",
    "        #             specs=self.specs\n",
    "        #         ),\n",
    "        #         LFTConv(\n",
    "        #             size=self.specs['n_latent'],\n",
    "        #             nonlin=self.specs['nonlin'],\n",
    "        #             filter_length=self.specs['filter_length']*2,\n",
    "        #             padding=self.specs['padding'],\n",
    "        #             specs=self.specs\n",
    "        #         ),\n",
    "        #     ),\n",
    "        #     TempPooling(\n",
    "        #         pooling=self.specs['pooling'],\n",
    "        #         pool_type=self.specs['pool_type'],\n",
    "        #         stride=self.specs['stride'],\n",
    "        #         padding=self.specs['padding'],\n",
    "        #     ),\n",
    "        #     tf.keras.layers.Dropout(self.specs['dropout'], noise_shape=None),\n",
    "        #     Dense(size=self.out_dim, nonlin=tf.identity, specs=self.specs)\n",
    "        # )\n",
    "        \n",
    "        # self.design = ModelDesign(\n",
    "        #     self.inputs,\n",
    "        #     LayerDesign(tf.squeeze, axis=1),\n",
    "        #     tf.keras.layers.Bidirectional(\n",
    "        #         tf.keras.layers.LSTM(\n",
    "        #             self.specs['n_latent'],\n",
    "        #             bias_regularizer='l1',\n",
    "        #             return_sequences=True,\n",
    "        #             kernel_regularizer=tf.keras.regularizers.L1(.01),\n",
    "        #             recurrent_regularizer=tf.keras.regularizers.L1(.01),\n",
    "        #             dropout=0.4,\n",
    "        #             recurrent_dropout=0.4,\n",
    "        #         ),\n",
    "        #         merge_mode='sum'\n",
    "        #     ),\n",
    "        #     LayerDesign(tf.expand_dims, axis=1),\n",
    "        #     ParallelDesign(\n",
    "        #         LFTConv(\n",
    "        #             size=self.specs['n_latent'],\n",
    "        #             nonlin=self.specs['nonlin'],\n",
    "        #             filter_length=self.specs['filter_length']//2,\n",
    "        #             padding=self.specs['padding'],\n",
    "        #             specs=self.specs\n",
    "        #         ),\n",
    "        #         LFTConv(\n",
    "        #             size=self.specs['n_latent'],\n",
    "        #             nonlin=self.specs['nonlin'],\n",
    "        #             filter_length=self.specs['filter_length'],\n",
    "        #             padding=self.specs['padding'],\n",
    "        #             specs=self.specs\n",
    "        #         ),\n",
    "        #         LFTConv(\n",
    "        #             size=self.specs['n_latent'],\n",
    "        #             nonlin=self.specs['nonlin'],\n",
    "        #             filter_length=self.specs['filter_length']*2,\n",
    "        #             padding=self.specs['padding'],\n",
    "        #             specs=self.specs\n",
    "        #         ),\n",
    "        #     ),\n",
    "            \n",
    "        #     TempPooling(\n",
    "        #         pooling=self.specs['pooling'],\n",
    "        #         pool_type=self.specs['pool_type'],\n",
    "        #         stride=self.specs['stride'],\n",
    "        #         padding=self.specs['padding'],\n",
    "        #     ),\n",
    "        #     tf.keras.layers.Dropout(self.specs['dropout'], noise_shape=None),\n",
    "        #     Dense(size=self.out_dim, nonlin=tf.identity, specs=self.specs)\n",
    "        # )\n",
    "        \n",
    "        # self.design = ModelDesign(\n",
    "        #     self.inputs,\n",
    "        #     LayerDesign(tf.squeeze, axis=1),\n",
    "        #     tf.keras.layers.Bidirectional(\n",
    "        #         tf.keras.layers.LSTM(\n",
    "        #             self.specs['n_latent'],\n",
    "        #             bias_regularizer='l1',\n",
    "        #             return_sequences=True,\n",
    "        #             kernel_regularizer=tf.keras.regularizers.L1(.01),\n",
    "        #             recurrent_regularizer=tf.keras.regularizers.L1(.01),\n",
    "        #             dropout=0.4,\n",
    "        #             recurrent_dropout=0.4,\n",
    "        #         ),\n",
    "        #         merge_mode='sum'\n",
    "        #     ),\n",
    "        #     LayerDesign(tf.expand_dims, axis=1),\n",
    "        #     ParallelDesign(\n",
    "        #         LFTConv(\n",
    "        #             size=self.specs['n_latent'],\n",
    "        #             nonlin=self.specs['nonlin'],\n",
    "        #             filter_length=self.specs['filter_length']//2,\n",
    "        #             padding=self.specs['padding'],\n",
    "        #             specs=self.specs\n",
    "        #         ),\n",
    "        #         LFTConv(\n",
    "        #             size=self.specs['n_latent'],\n",
    "        #             nonlin=self.specs['nonlin'],\n",
    "        #             filter_length=self.specs['filter_length'],\n",
    "        #             padding=self.specs['padding'],\n",
    "        #             specs=self.specs\n",
    "        #         ),\n",
    "        #         LFTConv(\n",
    "        #             size=self.specs['n_latent'],\n",
    "        #             nonlin=self.specs['nonlin'],\n",
    "        #             filter_length=self.specs['filter_length']*2,\n",
    "        #             padding=self.specs['padding'],\n",
    "        #             specs=self.specs\n",
    "        #         ),\n",
    "        #     ),\n",
    "        #     tf.keras.layers.DepthwiseConv2D((1, 361), padding='valid', activation='relu', kernel_regularizer='l1'),\n",
    "        #     tf.keras.layers.Dropout(self.specs['dropout'], noise_shape=None),\n",
    "        #     tf.keras.layers.Flatten(),\n",
    "        #     tf.keras.layers.Dense(self.out_dim, kernel_regularizer='l1'),\n",
    "        # )\n",
    "        \n",
    "        # self.design = ModelDesign(\n",
    "        #     self.inputs,\n",
    "        #     LayerDesign(tf.squeeze, axis=1),\n",
    "        #     tf.keras.layers.Bidirectional(\n",
    "        #         tf.keras.layers.LSTM(\n",
    "        #             self.specs['n_latent'],\n",
    "        #             bias_regularizer='l1',\n",
    "        #             return_sequences=True,\n",
    "        #             kernel_regularizer=tf.keras.regularizers.L1(.01),\n",
    "        #             recurrent_regularizer=tf.keras.regularizers.L1(.01),\n",
    "        #             dropout=0.4,\n",
    "        #             recurrent_dropout=0.4,\n",
    "        #         ),\n",
    "        #         merge_mode='sum'\n",
    "        #     ),\n",
    "        #     LayerDesign(tf.expand_dims, axis=1),\n",
    "        #     LFTConv(\n",
    "        #         size=self.specs['n_latent'],\n",
    "        #         nonlin=self.specs['nonlin'],\n",
    "        #         filter_length=self.specs['filter_length']*2,\n",
    "        #         padding=self.specs['padding'],\n",
    "        #         specs=self.specs\n",
    "        #     ),\n",
    "        #     tf.keras.layers.DepthwiseConv2D((1, 361), padding='valid', activation='relu', kernel_regularizer='l1'),\n",
    "        #     tf.keras.layers.Dropout(self.specs['dropout'], noise_shape=None),\n",
    "        #     tf.keras.layers.Flatten(),\n",
    "        #     tf.keras.layers.Dense(self.out_dim, kernel_regularizer='l1'),\n",
    "        # )\n",
    "        \n",
    "\n",
    "        return self.design()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting reg for tconv, to l1\n",
      "Built: tconv input: (None, 1, 361, 32)\n",
      "Setting reg for tconv, to l1\n",
      "Built: tconv input: (None, 1, 361, 32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 8])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LFCNNm(dataset, lf_params)\n",
    "model.build_graph().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting reg for dmx, to l1\n",
      "Built: dmx input: (None, 1, 361, 204)\n",
      "Setting reg for tconv, to l1\n",
      "Built: tconv input: (None, 1, 361, 32)\n",
      "Input shape: (1, 361, 204)\n",
      "y_pred: (None, 8)\n",
      "Initialization complete!\n",
      "Epoch 1/100\n",
      "100/100 - 4s - loss: 5.0309 - cat_ACC: 0.1231 - val_loss: 4.4111 - val_cat_ACC: 0.1278 - 4s/epoch - 43ms/step\n",
      "Epoch 2/100\n",
      "100/100 - 3s - loss: 3.9116 - cat_ACC: 0.1177 - val_loss: 3.4551 - val_cat_ACC: 0.1278 - 3s/epoch - 33ms/step\n",
      "Epoch 3/100\n",
      "100/100 - 3s - loss: 3.1135 - cat_ACC: 0.1177 - val_loss: 2.8019 - val_cat_ACC: 0.1278 - 3s/epoch - 35ms/step\n",
      "Epoch 4/100\n",
      "100/100 - 3s - loss: 2.5990 - cat_ACC: 0.1099 - val_loss: 2.3926 - val_cat_ACC: 0.1278 - 3s/epoch - 35ms/step\n",
      "Epoch 5/100\n",
      "100/100 - 3s - loss: 2.2871 - cat_ACC: 0.1187 - val_loss: 2.1764 - val_cat_ACC: 0.1278 - 3s/epoch - 35ms/step\n",
      "Epoch 6/100\n",
      "100/100 - 3s - loss: 2.1287 - cat_ACC: 0.1316 - val_loss: 2.0674 - val_cat_ACC: 0.1805 - 3s/epoch - 34ms/step\n",
      "Epoch 7/100\n",
      "100/100 - 4s - loss: 2.0591 - cat_ACC: 0.1739 - val_loss: 1.9949 - val_cat_ACC: 0.2556 - 4s/epoch - 35ms/step\n",
      "Epoch 8/100\n",
      "100/100 - 3s - loss: 1.9746 - cat_ACC: 0.2425 - val_loss: 1.9264 - val_cat_ACC: 0.2857 - 3s/epoch - 35ms/step\n",
      "Epoch 9/100\n",
      "100/100 - 3s - loss: 1.9052 - cat_ACC: 0.2755 - val_loss: 1.8624 - val_cat_ACC: 0.2932 - 3s/epoch - 35ms/step\n",
      "Epoch 10/100\n",
      "100/100 - 3s - loss: 1.8658 - cat_ACC: 0.2849 - val_loss: 1.8119 - val_cat_ACC: 0.2857 - 3s/epoch - 35ms/step\n",
      "Epoch 11/100\n",
      "100/100 - 3s - loss: 1.8025 - cat_ACC: 0.3023 - val_loss: 1.7788 - val_cat_ACC: 0.2857 - 3s/epoch - 35ms/step\n",
      "Epoch 12/100\n",
      "100/100 - 4s - loss: 1.7703 - cat_ACC: 0.3036 - val_loss: 1.7561 - val_cat_ACC: 0.3008 - 4s/epoch - 36ms/step\n",
      "Epoch 13/100\n",
      "100/100 - 3s - loss: 1.7565 - cat_ACC: 0.3037 - val_loss: 1.7405 - val_cat_ACC: 0.3008 - 3s/epoch - 33ms/step\n",
      "Epoch 14/100\n",
      "100/100 - 3s - loss: 1.7201 - cat_ACC: 0.3190 - val_loss: 1.7295 - val_cat_ACC: 0.3083 - 3s/epoch - 33ms/step\n",
      "Epoch 15/100\n",
      "100/100 - 3s - loss: 1.6996 - cat_ACC: 0.3303 - val_loss: 1.7210 - val_cat_ACC: 0.3233 - 3s/epoch - 34ms/step\n",
      "Epoch 16/100\n",
      "100/100 - 3s - loss: 1.6915 - cat_ACC: 0.3370 - val_loss: 1.7123 - val_cat_ACC: 0.3534 - 3s/epoch - 34ms/step\n",
      "Epoch 17/100\n",
      "100/100 - 3s - loss: 1.6602 - cat_ACC: 0.3493 - val_loss: 1.7034 - val_cat_ACC: 0.3684 - 3s/epoch - 33ms/step\n",
      "Epoch 18/100\n",
      "100/100 - 3s - loss: 1.6419 - cat_ACC: 0.3560 - val_loss: 1.6943 - val_cat_ACC: 0.3835 - 3s/epoch - 33ms/step\n",
      "Epoch 19/100\n",
      "100/100 - 3s - loss: 1.6359 - cat_ACC: 0.3652 - val_loss: 1.6838 - val_cat_ACC: 0.3835 - 3s/epoch - 34ms/step\n",
      "Epoch 20/100\n",
      "100/100 - 3s - loss: 1.6030 - cat_ACC: 0.3824 - val_loss: 1.6710 - val_cat_ACC: 0.4060 - 3s/epoch - 34ms/step\n",
      "Epoch 21/100\n",
      "100/100 - 3s - loss: 1.5734 - cat_ACC: 0.4035 - val_loss: 1.6526 - val_cat_ACC: 0.4211 - 3s/epoch - 34ms/step\n",
      "Epoch 22/100\n",
      "100/100 - 3s - loss: 1.5701 - cat_ACC: 0.4157 - val_loss: 1.6341 - val_cat_ACC: 0.4586 - 3s/epoch - 34ms/step\n",
      "Epoch 23/100\n",
      "100/100 - 3s - loss: 1.5287 - cat_ACC: 0.4412 - val_loss: 1.6079 - val_cat_ACC: 0.4586 - 3s/epoch - 34ms/step\n",
      "Epoch 24/100\n",
      "100/100 - 3s - loss: 1.5001 - cat_ACC: 0.4681 - val_loss: 1.5728 - val_cat_ACC: 0.4962 - 3s/epoch - 34ms/step\n",
      "Epoch 25/100\n",
      "100/100 - 4s - loss: 1.4681 - cat_ACC: 0.4948 - val_loss: 1.5399 - val_cat_ACC: 0.4887 - 4s/epoch - 35ms/step\n",
      "Epoch 26/100\n",
      "100/100 - 3s - loss: 1.4217 - cat_ACC: 0.5267 - val_loss: 1.5008 - val_cat_ACC: 0.5338 - 3s/epoch - 35ms/step\n",
      "Epoch 27/100\n",
      "100/100 - 3s - loss: 1.3875 - cat_ACC: 0.5474 - val_loss: 1.4595 - val_cat_ACC: 0.5714 - 3s/epoch - 34ms/step\n",
      "Epoch 28/100\n",
      "100/100 - 3s - loss: 1.3616 - cat_ACC: 0.5632 - val_loss: 1.4204 - val_cat_ACC: 0.5865 - 3s/epoch - 34ms/step\n",
      "Epoch 29/100\n",
      "100/100 - 3s - loss: 1.2972 - cat_ACC: 0.6005 - val_loss: 1.3766 - val_cat_ACC: 0.6165 - 3s/epoch - 34ms/step\n",
      "Epoch 30/100\n",
      "100/100 - 3s - loss: 1.2657 - cat_ACC: 0.6149 - val_loss: 1.3366 - val_cat_ACC: 0.6241 - 3s/epoch - 33ms/step\n",
      "Epoch 31/100\n",
      "100/100 - 3s - loss: 1.2423 - cat_ACC: 0.6230 - val_loss: 1.3083 - val_cat_ACC: 0.6241 - 3s/epoch - 34ms/step\n",
      "Epoch 32/100\n",
      "100/100 - 3s - loss: 1.2047 - cat_ACC: 0.6531 - val_loss: 1.2860 - val_cat_ACC: 0.6241 - 3s/epoch - 33ms/step\n",
      "Epoch 33/100\n",
      "100/100 - 3s - loss: 1.1928 - cat_ACC: 0.6563 - val_loss: 1.2614 - val_cat_ACC: 0.6391 - 3s/epoch - 33ms/step\n",
      "Epoch 34/100\n",
      "100/100 - 3s - loss: 1.1651 - cat_ACC: 0.6716 - val_loss: 1.2389 - val_cat_ACC: 0.6391 - 3s/epoch - 34ms/step\n",
      "Epoch 35/100\n",
      "100/100 - 3s - loss: 1.1328 - cat_ACC: 0.6897 - val_loss: 1.2151 - val_cat_ACC: 0.6541 - 3s/epoch - 32ms/step\n",
      "Epoch 36/100\n",
      "100/100 - 3s - loss: 1.1210 - cat_ACC: 0.6986 - val_loss: 1.1982 - val_cat_ACC: 0.6391 - 3s/epoch - 33ms/step\n",
      "Epoch 37/100\n",
      "100/100 - 3s - loss: 1.1100 - cat_ACC: 0.6926 - val_loss: 1.1850 - val_cat_ACC: 0.6466 - 3s/epoch - 33ms/step\n",
      "Epoch 38/100\n",
      "100/100 - 3s - loss: 1.0876 - cat_ACC: 0.7110 - val_loss: 1.1772 - val_cat_ACC: 0.6617 - 3s/epoch - 34ms/step\n",
      "Epoch 39/100\n",
      "100/100 - 3s - loss: 1.0657 - cat_ACC: 0.7242 - val_loss: 1.1727 - val_cat_ACC: 0.6692 - 3s/epoch - 33ms/step\n",
      "Epoch 40/100\n",
      "100/100 - 3s - loss: 1.0597 - cat_ACC: 0.7249 - val_loss: 1.1556 - val_cat_ACC: 0.6617 - 3s/epoch - 33ms/step\n",
      "Epoch 41/100\n",
      "100/100 - 3s - loss: 1.0482 - cat_ACC: 0.7299 - val_loss: 1.1500 - val_cat_ACC: 0.6767 - 3s/epoch - 33ms/step\n",
      "Epoch 42/100\n",
      "100/100 - 3s - loss: 1.0309 - cat_ACC: 0.7411 - val_loss: 1.1416 - val_cat_ACC: 0.6767 - 3s/epoch - 33ms/step\n",
      "Epoch 43/100\n",
      "100/100 - 3s - loss: 1.0314 - cat_ACC: 0.7432 - val_loss: 1.1428 - val_cat_ACC: 0.6992 - 3s/epoch - 34ms/step\n",
      "Epoch 44/100\n",
      "100/100 - 3s - loss: 1.0162 - cat_ACC: 0.7469 - val_loss: 1.1371 - val_cat_ACC: 0.6917 - 3s/epoch - 33ms/step\n",
      "Epoch 45/100\n",
      "100/100 - 3s - loss: 1.0084 - cat_ACC: 0.7509 - val_loss: 1.1373 - val_cat_ACC: 0.6917 - 3s/epoch - 33ms/step\n",
      "Epoch 46/100\n",
      "100/100 - 3s - loss: 1.0036 - cat_ACC: 0.7523 - val_loss: 1.1201 - val_cat_ACC: 0.6917 - 3s/epoch - 33ms/step\n",
      "Epoch 47/100\n",
      "100/100 - 4s - loss: 0.9732 - cat_ACC: 0.7686 - val_loss: 1.1169 - val_cat_ACC: 0.6992 - 4s/epoch - 37ms/step\n",
      "Epoch 48/100\n",
      "100/100 - 3s - loss: 0.9806 - cat_ACC: 0.7665 - val_loss: 1.1156 - val_cat_ACC: 0.6992 - 3s/epoch - 34ms/step\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/user/Projects/FingerMovementDecoder/dirty_field/LFCNN-m.ipynb Cell 7'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/user/Projects/FingerMovementDecoder/dirty_field/LFCNN-m.ipynb#ch0000006?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m LFCNNm(dataset, lf_params)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/user/Projects/FingerMovementDecoder/dirty_field/LFCNN-m.ipynb#ch0000006?line=1'>2</a>\u001b[0m model\u001b[39m.\u001b[39mbuild()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/user/Projects/FingerMovementDecoder/dirty_field/LFCNN-m.ipynb#ch0000006?line=2'>3</a>\u001b[0m model\u001b[39m.\u001b[39;49mtrain(n_epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, eval_step\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, early_stopping\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n",
      "File \u001b[0;32m~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/mneflow/models.py:215\u001b[0m, in \u001b[0;36mBaseModel.train\u001b[0;34m(self, n_epochs, eval_step, min_delta, early_stopping, mode)\u001b[0m\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/mneflow/models.py?line=208'>209</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_params \u001b[39m=\u001b[39m [n_epochs, eval_step, early_stopping, mode]\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/mneflow/models.py?line=211'>212</a>\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39msingle_fold\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/mneflow/models.py?line=212'>213</a>\u001b[0m     \u001b[39m#self.dataset.train, self.dataset.val = self.dataset._build_dataset()\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/mneflow/models.py?line=214'>215</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mt_hist \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkm\u001b[39m.\u001b[39;49mfit(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset\u001b[39m.\u001b[39;49mtrain,\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/mneflow/models.py?line=215'>216</a>\u001b[0m                            validation_data\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset\u001b[39m.\u001b[39;49mval,\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/mneflow/models.py?line=216'>217</a>\u001b[0m                            epochs\u001b[39m=\u001b[39;49mn_epochs, steps_per_epoch\u001b[39m=\u001b[39;49meval_step,\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/mneflow/models.py?line=217'>218</a>\u001b[0m                            shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, \n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/mneflow/models.py?line=218'>219</a>\u001b[0m                            validation_steps\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset\u001b[39m.\u001b[39;49mvalidation_steps,\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/mneflow/models.py?line=219'>220</a>\u001b[0m                            callbacks\u001b[39m=\u001b[39;49m[stop_early], verbose\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/mneflow/models.py?line=220'>221</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mv_loss, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mv_metric \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39mval)\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/mneflow/models.py?line=221'>222</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mv_loss_sd \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=61'>62</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=62'>63</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=63'>64</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/keras/engine/training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/keras/engine/training.py?line=1376'>1377</a>\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/keras/engine/training.py?line=1377'>1378</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/keras/engine/training.py?line=1378'>1379</a>\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/keras/engine/training.py?line=1379'>1380</a>\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[1;32m   <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/keras/engine/training.py?line=1380'>1381</a>\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/keras/engine/training.py?line=1381'>1382</a>\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/keras/engine/training.py?line=1382'>1383</a>\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/keras/engine/training.py?line=1383'>1384</a>\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/keras/engine/training.py?line=1384'>1385</a>\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/keras/engine/training.py?line=1385'>1386</a>\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=147'>148</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=148'>149</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=149'>150</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=150'>151</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=151'>152</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=911'>912</a>\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=913'>914</a>\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=914'>915</a>\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=916'>917</a>\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=917'>918</a>\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=943'>944</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=944'>945</a>\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=945'>946</a>\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=946'>947</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=947'>948</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=948'>949</a>\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=949'>950</a>\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=950'>951</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=2952'>2953</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=2953'>2954</a>\u001b[0m   (graph_function,\n\u001b[1;32m   <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=2954'>2955</a>\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=2955'>2956</a>\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=2956'>2957</a>\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1848'>1849</a>\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1849'>1850</a>\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1850'>1851</a>\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1851'>1852</a>\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1852'>1853</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1853'>1854</a>\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1854'>1855</a>\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1855'>1856</a>\u001b[0m     args,\n\u001b[1;32m   <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1856'>1857</a>\u001b[0m     possible_gradient_type,\n\u001b[1;32m   <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1857'>1858</a>\u001b[0m     executing_eagerly)\n\u001b[1;32m   <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1858'>1859</a>\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=496'>497</a>\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=497'>498</a>\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=498'>499</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=499'>500</a>\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=500'>501</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=501'>502</a>\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=502'>503</a>\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=503'>504</a>\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=504'>505</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=505'>506</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=506'>507</a>\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=507'>508</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=510'>511</a>\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=511'>512</a>\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/execute.py?line=51'>52</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/execute.py?line=52'>53</a>\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/execute.py?line=53'>54</a>\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/execute.py?line=54'>55</a>\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/execute.py?line=55'>56</a>\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     <a href='file:///home/user/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/eager/execute.py?line=56'>57</a>\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = LFCNNm(dataset, lf_params)\n",
    "model.build()\n",
    "model.train(n_epochs=100, eval_step=100, early_stopping=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting reg for dmx, to l1\n",
      "Built: dmx input: (None, 1, 361, 204)\n",
      "Setting reg for tconv, to l1\n",
      "Built: tconv input: (None, 1, 361, 32)\n",
      "Setting reg for fc, to l1\n",
      "Built: fc input: (None, 1, 73, 32)\n",
      "Input shape: (1, 361, 204)\n",
      "y_pred: (None, 8)\n",
      "Initialization complete!\n",
      "Epoch 1/100\n",
      "100/100 - 4s - loss: 5.3149 - cat_ACC: 0.1720 - val_loss: 4.9199 - val_cat_ACC: 0.1825 - 4s/epoch - 44ms/step\n",
      "Epoch 2/100\n",
      "100/100 - 3s - loss: 4.5731 - cat_ACC: 0.3550 - val_loss: 4.3783 - val_cat_ACC: 0.3333 - 3s/epoch - 32ms/step\n",
      "Epoch 3/100\n",
      "100/100 - 3s - loss: 3.9398 - cat_ACC: 0.5304 - val_loss: 3.8819 - val_cat_ACC: 0.5238 - 3s/epoch - 30ms/step\n",
      "Epoch 4/100\n",
      "100/100 - 3s - loss: 3.4060 - cat_ACC: 0.7010 - val_loss: 3.4279 - val_cat_ACC: 0.7063 - 3s/epoch - 32ms/step\n",
      "Epoch 5/100\n",
      "100/100 - 3s - loss: 2.9393 - cat_ACC: 0.8137 - val_loss: 3.0576 - val_cat_ACC: 0.7063 - 3s/epoch - 32ms/step\n",
      "Epoch 6/100\n",
      "100/100 - 3s - loss: 2.5730 - cat_ACC: 0.8838 - val_loss: 2.7648 - val_cat_ACC: 0.7460 - 3s/epoch - 29ms/step\n",
      "Epoch 7/100\n",
      "100/100 - 3s - loss: 2.2916 - cat_ACC: 0.9185 - val_loss: 2.5156 - val_cat_ACC: 0.7937 - 3s/epoch - 29ms/step\n",
      "Epoch 8/100\n",
      "100/100 - 3s - loss: 2.0521 - cat_ACC: 0.9465 - val_loss: 2.3069 - val_cat_ACC: 0.8016 - 3s/epoch - 29ms/step\n",
      "Epoch 9/100\n",
      "100/100 - 3s - loss: 1.8446 - cat_ACC: 0.9629 - val_loss: 2.1150 - val_cat_ACC: 0.8016 - 3s/epoch - 32ms/step\n",
      "Epoch 10/100\n",
      "100/100 - 3s - loss: 1.6634 - cat_ACC: 0.9707 - val_loss: 1.9431 - val_cat_ACC: 0.8175 - 3s/epoch - 31ms/step\n",
      "Epoch 11/100\n",
      "100/100 - 3s - loss: 1.5032 - cat_ACC: 0.9756 - val_loss: 1.7806 - val_cat_ACC: 0.8254 - 3s/epoch - 31ms/step\n",
      "Epoch 12/100\n",
      "100/100 - 3s - loss: 1.3594 - cat_ACC: 0.9784 - val_loss: 1.6399 - val_cat_ACC: 0.8492 - 3s/epoch - 33ms/step\n",
      "Epoch 13/100\n",
      "100/100 - 3s - loss: 1.2383 - cat_ACC: 0.9783 - val_loss: 1.5140 - val_cat_ACC: 0.8413 - 3s/epoch - 35ms/step\n",
      "Epoch 14/100\n",
      "100/100 - 3s - loss: 1.1232 - cat_ACC: 0.9828 - val_loss: 1.4019 - val_cat_ACC: 0.8492 - 3s/epoch - 31ms/step\n",
      "Epoch 15/100\n",
      "100/100 - 3s - loss: 1.0293 - cat_ACC: 0.9836 - val_loss: 1.3011 - val_cat_ACC: 0.8571 - 3s/epoch - 30ms/step\n",
      "Epoch 16/100\n",
      "100/100 - 3s - loss: 0.9472 - cat_ACC: 0.9810 - val_loss: 1.2170 - val_cat_ACC: 0.8571 - 3s/epoch - 30ms/step\n",
      "Epoch 17/100\n",
      "100/100 - 4s - loss: 0.8680 - cat_ACC: 0.9859 - val_loss: 1.1346 - val_cat_ACC: 0.8571 - 4s/epoch - 40ms/step\n",
      "Epoch 18/100\n",
      "100/100 - 4s - loss: 0.8028 - cat_ACC: 0.9856 - val_loss: 1.0667 - val_cat_ACC: 0.8730 - 4s/epoch - 36ms/step\n",
      "Epoch 19/100\n",
      "100/100 - 3s - loss: 0.7493 - cat_ACC: 0.9850 - val_loss: 1.0092 - val_cat_ACC: 0.8810 - 3s/epoch - 33ms/step\n",
      "Epoch 20/100\n",
      "100/100 - 4s - loss: 0.7013 - cat_ACC: 0.9858 - val_loss: 0.9609 - val_cat_ACC: 0.8810 - 4s/epoch - 35ms/step\n",
      "Epoch 21/100\n",
      "100/100 - 3s - loss: 0.6613 - cat_ACC: 0.9859 - val_loss: 0.9229 - val_cat_ACC: 0.8571 - 3s/epoch - 34ms/step\n",
      "Epoch 22/100\n",
      "100/100 - 3s - loss: 0.6287 - cat_ACC: 0.9847 - val_loss: 0.8874 - val_cat_ACC: 0.8810 - 3s/epoch - 35ms/step\n",
      "Epoch 23/100\n",
      "100/100 - 3s - loss: 0.6030 - cat_ACC: 0.9855 - val_loss: 0.8640 - val_cat_ACC: 0.8730 - 3s/epoch - 35ms/step\n",
      "Epoch 24/100\n",
      "100/100 - 3s - loss: 0.5815 - cat_ACC: 0.9859 - val_loss: 0.8393 - val_cat_ACC: 0.8968 - 3s/epoch - 32ms/step\n",
      "Epoch 25/100\n",
      "100/100 - 3s - loss: 0.5628 - cat_ACC: 0.9851 - val_loss: 0.8123 - val_cat_ACC: 0.9048 - 3s/epoch - 33ms/step\n",
      "Epoch 26/100\n",
      "100/100 - 3s - loss: 0.5448 - cat_ACC: 0.9869 - val_loss: 0.8021 - val_cat_ACC: 0.8968 - 3s/epoch - 32ms/step\n",
      "Epoch 27/100\n",
      "100/100 - 3s - loss: 0.5295 - cat_ACC: 0.9867 - val_loss: 0.7872 - val_cat_ACC: 0.8889 - 3s/epoch - 32ms/step\n",
      "Epoch 28/100\n",
      "100/100 - 3s - loss: 0.5199 - cat_ACC: 0.9869 - val_loss: 0.7677 - val_cat_ACC: 0.8968 - 3s/epoch - 31ms/step\n",
      "Epoch 29/100\n",
      "100/100 - 3s - loss: 0.5088 - cat_ACC: 0.9869 - val_loss: 0.7502 - val_cat_ACC: 0.9048 - 3s/epoch - 30ms/step\n",
      "Epoch 30/100\n",
      "100/100 - 3s - loss: 0.4998 - cat_ACC: 0.9864 - val_loss: 0.7475 - val_cat_ACC: 0.9127 - 3s/epoch - 33ms/step\n",
      "Epoch 31/100\n",
      "100/100 - 3s - loss: 0.4901 - cat_ACC: 0.9891 - val_loss: 0.7359 - val_cat_ACC: 0.9048 - 3s/epoch - 34ms/step\n",
      "Epoch 32/100\n",
      "100/100 - 3s - loss: 0.4829 - cat_ACC: 0.9873 - val_loss: 0.7318 - val_cat_ACC: 0.9286 - 3s/epoch - 33ms/step\n",
      "Epoch 33/100\n",
      "100/100 - 3s - loss: 0.4763 - cat_ACC: 0.9886 - val_loss: 0.7128 - val_cat_ACC: 0.9286 - 3s/epoch - 33ms/step\n",
      "Epoch 34/100\n",
      "100/100 - 3s - loss: 0.4771 - cat_ACC: 0.9864 - val_loss: 0.7089 - val_cat_ACC: 0.9127 - 3s/epoch - 31ms/step\n",
      "Epoch 35/100\n",
      "100/100 - 4s - loss: 0.4648 - cat_ACC: 0.9884 - val_loss: 0.7107 - val_cat_ACC: 0.9127 - 4s/epoch - 44ms/step\n",
      "Epoch 36/100\n",
      "100/100 - 3s - loss: 0.4587 - cat_ACC: 0.9881 - val_loss: 0.7046 - val_cat_ACC: 0.8968 - 3s/epoch - 34ms/step\n",
      "Epoch 37/100\n",
      "100/100 - 4s - loss: 0.4546 - cat_ACC: 0.9881 - val_loss: 0.7141 - val_cat_ACC: 0.8889 - 4s/epoch - 37ms/step\n",
      "Epoch 38/100\n",
      "100/100 - 4s - loss: 0.4448 - cat_ACC: 0.9908 - val_loss: 0.6873 - val_cat_ACC: 0.9127 - 4s/epoch - 36ms/step\n",
      "Epoch 39/100\n",
      "100/100 - 3s - loss: 0.4506 - cat_ACC: 0.9882 - val_loss: 0.6915 - val_cat_ACC: 0.8810 - 3s/epoch - 34ms/step\n",
      "Epoch 40/100\n",
      "100/100 - 3s - loss: 0.4444 - cat_ACC: 0.9874 - val_loss: 0.6912 - val_cat_ACC: 0.9206 - 3s/epoch - 33ms/step\n",
      "Epoch 41/100\n",
      "100/100 - 3s - loss: 0.4417 - cat_ACC: 0.9872 - val_loss: 0.6786 - val_cat_ACC: 0.8889 - 3s/epoch - 30ms/step\n",
      "Epoch 42/100\n",
      "100/100 - 3s - loss: 0.4351 - cat_ACC: 0.9887 - val_loss: 0.6701 - val_cat_ACC: 0.8889 - 3s/epoch - 30ms/step\n",
      "Epoch 43/100\n",
      "100/100 - 3s - loss: 0.4314 - cat_ACC: 0.9895 - val_loss: 0.6802 - val_cat_ACC: 0.8730 - 3s/epoch - 31ms/step\n",
      "Epoch 44/100\n",
      "100/100 - 3s - loss: 0.4326 - cat_ACC: 0.9888 - val_loss: 0.6747 - val_cat_ACC: 0.8810 - 3s/epoch - 31ms/step\n",
      "Epoch 45/100\n",
      "100/100 - 3s - loss: 0.4265 - cat_ACC: 0.9897 - val_loss: 0.6763 - val_cat_ACC: 0.8889 - 3s/epoch - 31ms/step\n",
      "Epoch 46/100\n",
      "100/100 - 3s - loss: 0.4307 - cat_ACC: 0.9869 - val_loss: 0.6820 - val_cat_ACC: 0.8889 - 3s/epoch - 29ms/step\n",
      "Epoch 47/100\n",
      "100/100 - 3s - loss: 0.4269 - cat_ACC: 0.9871 - val_loss: 0.6818 - val_cat_ACC: 0.8810 - 3s/epoch - 30ms/step\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.6701 - cat_ACC: 0.8889\n",
      "Training complete: loss: 0.670089840888977, Metric: 0.8888888955116272\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3931 - cat_ACC: 1.0000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7841 - cat_ACC: 0.8782\n",
      "Updating log: test loss: 0.7841 test metric: 0.8782\n"
     ]
    }
   ],
   "source": [
    "model = LFCNN(dataset, lf_params)\n",
    "model.build()\n",
    "model.train(n_epochs=100, eval_step=100, early_stopping=5)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "25b6c1d617e3cb25e4067864bcd46322e1b7da41afdae0cf7c23b941b0b9b767"
  },
  "kernelspec": {
   "display_name": "FingerMovementsDecoder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
