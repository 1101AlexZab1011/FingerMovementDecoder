{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-05 22:22:55.288443: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-05 22:22:55.288473: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import sys\n",
    "import os\n",
    "current_dir = os.path.dirname(os.path.abspath('./'))\n",
    "if not current_dir in sys.path:\n",
    "    sys.path.append(current_dir)\n",
    "    \n",
    "from utils.structures import Pipeline, Deploy\n",
    "from utils.data_management import dict2str\n",
    "from typing import *\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import make_classification\n",
    "import mne\n",
    "from combiners import EpochsCombiner\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from utils.machine_learning.designer import ModelDesign, ParallelDesign, LayerDesign\n",
    "from utils.machine_learning.analyzer import ModelAnalyzer, LFCNNAnalyzer\n",
    "from mne.datasets import multimodal\n",
    "\n",
    "# %matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne.set_log_level(verbose='CRITICAL')\n",
    "fname_raw = os.path.join(multimodal.data_path(), 'multimodal_raw.fif')\n",
    "raw = mne.io.read_raw_fif(fname_raw)\n",
    "\n",
    "cond = raw.acqparser.get_condition(raw, None)\n",
    "# get the list of condition names\n",
    "condition_names = [k for c in cond for k,v in c['event_id'].items()]\n",
    "epochs_list = [mne.Epochs(raw, **c) for c in cond]\n",
    "epochs = mne.concatenate_epochs(epochs_list)\n",
    "print(epochs.info)\n",
    "epochs = epochs.pick_types(meg='grad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(dict2str(vars(epochs)))\n",
    "print(epochs._channel_type_idx['grad'])\n",
    "print(len(epochs._channel_type_idx['grad']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([])\n",
    "Y = list()\n",
    "for i, epochs in enumerate(epochs_list):\n",
    "    data = epochs.get_data()\n",
    "    if i == 0:\n",
    "        X = data.copy()\n",
    "    else:\n",
    "        X = np.append(X, data, axis=0)\n",
    "    Y += [i for _ in range(data.shape[0])]\n",
    "\n",
    "Y = np.array(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_matrix = X[0].copy()\n",
    "\n",
    "X = np.array([X[i, epochs._channel_type_idx['grad'], :] for i, _ in enumerate(X)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X[0, 0:10, 0:10], vmin=-1e-11, vmax=1e-11)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, epochs in enumerate(epochs_list):\n",
    "    epochs.plot()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding\n",
    "\n",
    "def one_hot_encoder(Y: np.ndarray) -> np.ndarray:\n",
    "    y = list()\n",
    "    n_classes = len(np.unique(Y))\n",
    "\n",
    "    for val in Y:\n",
    "        new_y_value = np.zeros(n_classes)\n",
    "        new_y_value[val] = 1\n",
    "        y.append(new_y_value)\n",
    "\n",
    "    return np.array(y)\n",
    "\n",
    "y = list()\n",
    "n_classes = len(np.unique(Y))\n",
    "\n",
    "for val in Y:\n",
    "    new_y_value = np.zeros(n_classes)\n",
    "    new_y_value[val] = 1\n",
    "    y.append(new_y_value)\n",
    "\n",
    "y = np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mAll tests passed\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from utils.console.colored import success\n",
    "\n",
    "def shuffle_x_y(X: np.ndarray, Y: np.ndarray) -> tuple[np.ndarray, np.ndarray]:\n",
    "    indices = [i for i in range(X.shape[0])]\n",
    "    random.shuffle(indices)\n",
    "    X = X[indices, :, :]\n",
    "    Y = Y[indices]\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "def test_shuffle_x_y():\n",
    "    X = np.random.rand(10, 10, 10)\n",
    "    Y = X[:, 0, 0]\n",
    "    \n",
    "    assert np.all(Y == X[:, 0, 0])\n",
    "    \n",
    "    i = np.random.randint(0, 9)\n",
    "    X, Y = shuffle_x_y(X, Y)\n",
    "    \n",
    "    for i in range(10):\n",
    "        assert np.all(Y[i] == X[i, 0, 0])\n",
    "    \n",
    "    success('All tests passed')\n",
    "    \n",
    "\n",
    "test_shuffle_x_y()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, n_channels, n_times = X.shape\n",
    "n_classes = len(np.unique(Y))\n",
    "\n",
    "lfcnn_design = ModelDesign(\n",
    "    tf.keras.Input(shape=(n_channels, n_times, 1), name='input_layer'),\n",
    "    tf.keras.layers.Conv2D(32, (n_channels, 1), activation=tf.nn.relu, name='spatial_filters_layer'),\n",
    "    tf.keras.layers.DepthwiseConv2D((1, 15), padding='same', activation=tf.nn.relu, name='temporal_filters_layer'),\n",
    "    LayerDesign(tf.transpose, perm=(0, 3, 2, 1)),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(1, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(.2),\n",
    "    tf.keras.layers.Dense(400, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(200, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(100, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(50, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(n_classes, activation=tf.nn.softmax)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.machine_learning.analyzer import LFCNNAnalyzer\n",
    "\n",
    "model = lfcnn_design.build()\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    metrics=['acc']\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=50,\n",
    "    validation_split=0.4,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "\n",
    "model_analyzer = LFCNNAnalyzer(model)\n",
    "\n",
    "model_analyzer.plot_metrics(['loss', 'val_loss'])\n",
    "model_analyzer.plot_metrics(['acc', 'val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_analyzer.plot_spatial_weights()\n",
    "model_analyzer.plot_temporal_weights(transpose=True)\n",
    "model_analyzer.plot_patterns(epochs.load_data().pick_types(meg='grad').info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy as cp\n",
    "print(model_analyzer.layers['spatial_filters_layer'].data.shape)\n",
    "p = model_analyzer.layers['spatial_filters_layer'].data\n",
    "e = epochs.load_data().pick_types(meg='grad')\n",
    "info = cp.deepcopy(e.info)\n",
    "\n",
    "with info._unlock():\n",
    "    info['sfreq'] = 1.\n",
    "\n",
    "patterns = mne.EvokedArray(p, info, tmin=0)\n",
    "\n",
    "patterns.plot_topomap(\n",
    "    times=range(32),\n",
    "    cmap='RdBu_r', sensors=True,\n",
    "    colorbar=False, units='a.u.', res=64,\n",
    "    size=1, cbar_fmt='%3.1f', time_format='Latent\\nSource %01d',\n",
    "    show=True, show_names=False, title=None,\n",
    "    outlines='head', contours=6,\n",
    "    image_interp='bilinear', average=None,\n",
    "    sphere=None\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred = model(X_test).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred_int = np.round(y_pred, 1)\n",
    "\n",
    "def one_hot_decoder(y: np.array) -> np.array:\n",
    "    y_decoded = list()\n",
    "    for val in y:\n",
    "        y_decoded.append(np.where(val == val.max())[0][0])\n",
    "    \n",
    "    return np.array(y_decoded)\n",
    "    \n",
    "y_pred_decoded = one_hot_decoder(y_pred_int)\n",
    "y_test_decoded = one_hot_decoder(y_test)\n",
    "print('                 Actual prediction             |         Rounded prediction       |  Decoded | Actual')\n",
    "for ap, rp, p, a in zip(y_pred, y_pred_int, y_pred_decoded, y_test_decoded):\n",
    "    print('             ', np.round(ap, 3), '            ', rp, '        ', p, '       ', a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, n_channels, n_times = X.shape\n",
    "n_classes = len(np.unique(Y))\n",
    "\n",
    "w = n_channels\n",
    "h = n_times\n",
    "c = 1\n",
    "\n",
    "simple_conv_net = ModelDesign(\n",
    "    tf.keras.Input(shape=(w, h, c), name='input_layer'),\n",
    "    tf.keras.layers.Conv2D(32, (w//4, h//4), strides=(w//8, h//8), activation=tf.nn.relu),\n",
    "    tf.keras.layers.Conv2D(16, (4, 4), activation=tf.nn.relu),\n",
    "    tf.keras.layers.Conv2D(8, (2, 2), strides=(w//8, h//8), activation=tf.nn.relu),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(400, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(200, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(100, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(50, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(n_classes, activation=tf.nn.softmax)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = simple_conv_net.build()\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    metrics=['acc']\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=50,\n",
    "    validation_split=0.4,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "\n",
    "model_analyzer = ModelAnalyzer(model)\n",
    "\n",
    "model_analyzer.plot_metrics(['loss', 'val_loss'])\n",
    "model_analyzer.plot_metrics(['acc', 'val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model(X_test).numpy()\n",
    "y_pred_int = np.round(y_pred, 1)\n",
    "\n",
    "    \n",
    "\n",
    "# for y_p, y in zip(y_pred_decoded, y_test_decoded):\n",
    "#     print(y_p, y)\n",
    "\n",
    "def one_hot_decoder(y: np.array) -> np.array:\n",
    "    y_decoded = list()\n",
    "    for val in y:\n",
    "        y_decoded.append(np.where(val == val.max())[0][0])\n",
    "    \n",
    "    return np.array(y_decoded)\n",
    "    \n",
    "y_pred_decoded = one_hot_decoder(y_pred_int)\n",
    "y_test_decoded = one_hot_decoder(y_test)\n",
    "print('                 Actual prediction               |       Rounded prediction        | Decoded | Actual')\n",
    "for ap, rp, p, a in zip(y_pred, y_pred_int, y_pred_decoded, y_test_decoded):\n",
    "    print(np.round(ap, 3), rp, '    ', p, '     ', a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 8])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slfcnn_design = ModelDesign(\n",
    "    tf.keras.Input(shape=(n_channels, n_times, 1), name='input_layer'),\n",
    "    tf.keras.layers.Conv2D(32, (n_channels, 1), activation=tf.nn.relu, name='spatial_filters_layer'),\n",
    "    tf.keras.layers.DepthwiseConv2D((1, 15), padding='same', activation=tf.nn.relu, name='temporal_filters_layer'),\n",
    "    LayerDesign(tf.transpose, perm=(0, 3, 2, 1)),\n",
    "    tf.keras.layers.Conv2D(1, (32, 1), activation=tf.nn.relu, name='selection_filters_layer'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(400, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(200, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(100, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(50, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(n_classes, activation=tf.nn.softmax)\n",
    ")\n",
    "\n",
    "slfcnn_design().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = slfcnn_design.build()\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    metrics=['acc']\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=50,\n",
    "    validation_split=0.4,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "\n",
    "model_analyzer = LFCNNAnalyzer(model)\n",
    "\n",
    "model_analyzer.plot_metrics(['loss', 'val_loss'])\n",
    "model_analyzer.plot_metrics(['acc', 'val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_analyzer.plot_spatial_weights()\n",
    "model_analyzer.plot_temporal_weights(transpose=True)\n",
    "model_analyzer.plot_1d_weights(layer_identifier='selection_filters_layer', xlabel='latent sources')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model(X_test).numpy()\n",
    "y_pred_int = np.round(y_pred, 1)\n",
    "\n",
    "    \n",
    "\n",
    "# for y_p, y in zip(y_pred_decoded, y_test_decoded):\n",
    "#     print(y_p, y)\n",
    "\n",
    "def one_hot_decoder(y: np.array) -> np.array:\n",
    "    y_decoded = list()\n",
    "    for val in y:\n",
    "        y_decoded.append(np.where(val == val.max())[0][0])\n",
    "    \n",
    "    return np.array(y_decoded)\n",
    "    \n",
    "y_pred_decoded = one_hot_decoder(y_pred_int)\n",
    "y_test_decoded = one_hot_decoder(y_test)\n",
    "print('                 Actual prediction             |         Rounded prediction       |  Decoded | Actual')\n",
    "for ap, rp, p, a in zip(y_pred, y_pred_int, y_pred_decoded, y_test_decoded):\n",
    "    print('             ', np.round(ap, 3), '            ', rp, '        ', p, '       ', a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, n_channels, n_times = X.shape\n",
    "n_classes = len(np.unique(Y))\n",
    "\n",
    "cslfcnn_design = ModelDesign(\n",
    "    tf.keras.Input(shape=(n_channels, n_times, 1), name='input_layer'), \n",
    "    tf.keras.layers.Conv2D(32, (n_channels, 1), activation=tf.nn.relu, name='spatial_filters_layer'),\n",
    "    tf.keras.layers.DepthwiseConv2D((1, 15), padding='same', activation=tf.nn.relu, name='temporal_filters_layer'), \n",
    "    LayerDesign(tf.transpose, perm=(0, 3, 1, 2)),\n",
    "    tf.keras.layers.DepthwiseConv2D((32, 1), padding='valid', activation=tf.nn.relu, name='selection_filters_layer'), \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(400, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(200, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(100, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(50, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(n_classes, activation=tf.nn.softmax)\n",
    ")\n",
    "\n",
    "cslfcnn_design().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cslfcnn_design.build()\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    metrics=['acc']\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=50,\n",
    "    validation_split=0.4,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "\n",
    "model_analyzer = LFCNNAnalyzer(model)\n",
    "\n",
    "model_analyzer.plot_metrics(['loss', 'val_loss'])\n",
    "model_analyzer.plot_metrics(['acc', 'val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_analyzer.plot_spatial_weights()\n",
    "model_analyzer.plot_temporal_weights(transpose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for layer_name, layer in model_analyzer.layers.items():\n",
    "#     print(layer_name, layer.shape)\n",
    "\n",
    "model_analyzer.plot_2d_weights('selection_filters_layer', title='Selection Weights', xlabel='Timepoints', ylabel='Latent Sources')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selective_layer = model_analyzer.layers['selection_filters_layer']\n",
    "# tmin=-0.1, tmax=0.5\n",
    "print(epochs.times[180])\n",
    "x = list()\n",
    "y = list()\n",
    "for i, weights in enumerate(selective_layer.data.T):\n",
    "    x.append(np.round(epochs.times[i], 3))\n",
    "    y.append(np.where(weights == weights.max())[0][0])\n",
    "    # print(f'{np.round(epochs.times[i], 3)}: {np.where(weights == weights.max())[0][0]}')\n",
    "\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "figure(figsize=(10, 8), dpi=80)\n",
    "plt.plot(x, y, 'x')\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('Latent Sources')\n",
    "plt.title('Maximum weighted latent sources over time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, n_channels, n_times = X.shape\n",
    "n_classes = len(np.unique(Y))\n",
    "\n",
    "min_lfcnn_design = ModelDesign(\n",
    "    tf.keras.Input(shape=(n_channels, n_times, 1), name='input_layer'),\n",
    "    tf.keras.layers.Conv2D(32, (n_channels, 1), activation=tf.nn.relu, name='spatial_filters_layer'),\n",
    "    tf.keras.layers.DepthwiseConv2D((1, 15), padding='same', activation=tf.nn.relu, name='temporal_filters_layer'),\n",
    "    LayerDesign(tf.transpose, perm=(0, 3, 2, 1)),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(1, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(.2),\n",
    "    tf.keras.layers.Dense(n_classes, activation=tf.nn.softmax)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = min_lfcnn_design.build()\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    metrics=['acc']\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=50,\n",
    "    validation_split=0.4,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "\n",
    "model_analyzer = LFCNNAnalyzer(model)\n",
    "\n",
    "model_analyzer.plot_metrics(['loss', 'val_loss'])\n",
    "model_analyzer.plot_metrics(['acc', 'val_acc'])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a2e51f741df055a4a926fa50967fa9e78e24edd001455e85d9cbe16dc8a6ebab"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
