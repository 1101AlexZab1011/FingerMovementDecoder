{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-20 21:01:11.758741: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-02-20 21:01:11.758790: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "import os\n",
    "current_dir = os.path.dirname(os.path.abspath('./'))\n",
    "if not current_dir in sys.path:\n",
    "    sys.path.append(current_dir)\n",
    "from combiners import EpochsCombiner\n",
    "from typing import *\n",
    "import mne\n",
    "import tensorflow as tf\n",
    "import mneflow as mf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne.set_log_level('CRITICAL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_root = '../'\n",
    "subjects_folder_path = os.path.join(content_root, 'Source/Subjects')\n",
    "subject_path = os.path.join(subjects_folder_path, 'Ga_Fed_06')\n",
    "info_path = os.path.join(subject_path, 'Info',\n",
    "                        'ML_Subject05_P1_tsss_mc_trans_info.pkl')\n",
    "resp_lock_lm_B1_epochs_path = os.path.join(\n",
    "    subject_path, 'Epochs', 'RespCor_LM_B1_epochs.fif')\n",
    "resp_lock_rm_B1_epochs_path = os.path.join(\n",
    "    subject_path, 'Epochs', 'RespCor_RM_B1_epochs.fif')\n",
    "resp_lock_li_B1_epochs_path = os.path.join(\n",
    "    subject_path, 'Epochs', 'RespCor_LI_B1_epochs.fif')\n",
    "resp_lock_ri_B1_epochs_path = os.path.join(\n",
    "    subject_path, 'Epochs', 'RespCor_RI_B1_epochs.fif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<table class=\"table table-hover\">\n",
       "    <tr>\n",
       "        <th>Number of events</th>\n",
       "        <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Events</th>\n",
       "        <td>0: 60<br></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Time range</th>\n",
       "        <td>-0.500 â€“ 0.495 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Baseline</th>\n",
       "        <td>off</td>\n",
       "    </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<EpochsFIF |  60 events (all good), -0.5 - 0.495 sec, baseline off, ~23.8 MB, data loaded,\n",
       " '0': 60>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp_lock_lm_B1_epochs = mne.read_epochs(resp_lock_lm_B1_epochs_path)\n",
    "resp_lock_li_B1_epochs = mne.read_epochs(resp_lock_li_B1_epochs_path)\n",
    "resp_lock_rm_B1_epochs = mne.read_epochs(resp_lock_rm_B1_epochs_path)\n",
    "resp_lock_ri_B1_epochs = mne.read_epochs(resp_lock_ri_B1_epochs_path)\n",
    "\n",
    "resp_lock_li_B1_epochs.resample(200)\n",
    "resp_lock_lm_B1_epochs.resample(200)\n",
    "resp_lock_ri_B1_epochs.resample(200)\n",
    "resp_lock_rm_B1_epochs.resample(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EpochsCombiner([<EpochsFIF |  58 events (all good), -0.5 - 0.495 sec, baseline off, ~23.2 MB, data loaded,\n",
       "                 '0': 58>,\n",
       "                <EpochsFIF |  30 events (all good), -0.5 - 0.495 sec, baseline off, ~14.4 MB, data loaded,\n",
       "                 '0': 30>,\n",
       "                <EpochsFIF |  60 events (all good), -0.5 - 0.495 sec, baseline off, ~23.8 MB, data loaded,\n",
       "                 '0': 60>,\n",
       "                <EpochsFIF |  60 events (all good), -0.5 - 0.495 sec, baseline off, ~23.8 MB, data loaded,\n",
       "                 '0': 60>])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combiner = EpochsCombiner(\n",
    "    resp_lock_lm_B1_epochs.copy(),\n",
    "    resp_lock_li_B1_epochs.copy(),\n",
    "    resp_lock_rm_B1_epochs.copy(),\n",
    "    resp_lock_ri_B1_epochs.copy()\n",
    ")\n",
    "first_class_indices = (0, 1)\n",
    "second_class_indices = (2, 3)\n",
    "combiner.combine(first_class_indices, second_class_indices, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing from tuple\n",
      "input shapes: X- (208, 204, 200) targets- (208, 1)\n",
      "Preprocessing:\n",
      "Scaling to interval 0.0 - 60.0\n",
      "Splitting sets\n",
      "Preprocessed: (208, 1, 200, 204) (208, 2) folds: 6 x 34\n",
      "Prepocessed sample shape: (1, 200, 204)\n",
      "Target shape actual/metadata:  (2,) (2,)\n",
      "Saving TFRecord# 0\n",
      "Setting reg for dmx, to l2\n",
      "Built: dmx input: (None, 1, 200, 204)\n",
      "Setting reg for tconv, to l2\n",
      "Built: tconv input: (None, 1, 200, 32)\n",
      "Setting reg for fc, to l1\n",
      "Built: fc input: (None, 1, 20, 32)\n",
      "Input shape: (1, 200, 204)\n",
      "y_pred: (None, 2)\n",
      "Initialization complete!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "savepath = '../Source/Subjects/Az_Mar_05/TFR/left_vs_right/'\n",
    "project_name = 'fake_name'\n",
    "\n",
    "import_opt = dict(\n",
    "        savepath=savepath+'/',\n",
    "        out_name=project_name,\n",
    "        fs=200,\n",
    "        input_type='trials',\n",
    "        target_type='int',\n",
    "        picks={'meg': 'grad'},\n",
    "        scale=True,\n",
    "        crop_baseline=True,\n",
    "        decimate=None,\n",
    "        scale_interval=(0, 60),\n",
    "        n_folds=5,\n",
    "        overwrite=True,\n",
    "        segment=False,\n",
    "        test_set='holdout'\n",
    "    )\n",
    "meta = mf.produce_tfrecords((combiner.X, combiner.Y), **import_opt)\n",
    "dataset = mf.Dataset(meta, train_batch=100)\n",
    "lf_params = dict(\n",
    "        n_latent=32,\n",
    "        filter_length=50,\n",
    "        nonlin=tf.keras.activations.elu,\n",
    "        padding='SAME',\n",
    "        pooling=10,\n",
    "        stride=10,\n",
    "        pool_type='max',\n",
    "        model_path=import_opt['savepath'],\n",
    "        dropout=.4,\n",
    "        l2_scope=[\"weights\"],\n",
    "        l2=1e-6\n",
    ")\n",
    "\n",
    "model = mf.models.LFCNN(dataset, lf_params)\n",
    "model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path = os.path.join(subject_path, 'Weights', 'LM&LI_vs_RM&RI_B1-B8.h5')\n",
    "model.km.load_weights(weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(208, 204, 200)\n",
      "(208, 1, 200, 204)\n"
     ]
    }
   ],
   "source": [
    "X = combiner.X.copy()\n",
    "print(X.shape)\n",
    "X = np.transpose(np.expand_dims(X, axis = 1), (0, 1, 3, 2))\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(208, 2), dtype=float32, numpy=\n",
       "array([[-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.km(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built: dmx input: (None, 1, 200, 204)\n",
      "Built: tconv input: (None, 1, 200, 32)\n",
      "Built: fc input: (None, 1, 20, 32)\n"
     ]
    }
   ],
   "source": [
    "models_path = '/home/user/Projects/FingerMovementDecoder/Source/Subjects/Ga_Fed_06/Models'\n",
    "model = tf.keras.models.load_model(\n",
    "    os.path.join(models_path, 'LM&LI_vs_RM&RI_B1-B8.h5'),\n",
    "    custom_objects={\n",
    "        'DeMixing': mf.layers.DeMixing,\n",
    "        'LFTConv': mf.layers.LFTConv,\n",
    "        'TempPooling': mf.layers.TempPooling,\n",
    "        'Dense': mf.layers.Dense,\n",
    "        'identity': tf.identity,\n",
    "        'softmax_cross_entropy_with_logits_v2': tf.compat.v1.nn.softmax_cross_entropy_with_logits_v2,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(208, 2), dtype=float32, numpy=\n",
       "array([[-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297],\n",
       "       [-0.00817292,  0.07730297]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-20 21:02:07.521458: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-02-20 21:02:07.521505: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-02-20 21:02:07.521531: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (arcolinux-machine): /proc/driver/nvidia/version does not exist\n",
      "2022-02-20 21:02:07.521929: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<TFRecordDatasetV2 element_spec=TensorSpec(shape=(), dtype=tf.string, name=None)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfr_path = os.path.join(subject_path, 'TFR', 'LM&LI_vs_RM&RI_B1-B8', 'fingers_movement_epochs_test_0.tfrecord')\n",
    "\n",
    "raw_dataset = tf.data.TFRecordDataset([tfr_path])\n",
    "raw_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in raw_dataset:\n",
    "      print(element)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "25b6c1d617e3cb25e4067864bcd46322e1b7da41afdae0cf7c23b941b0b9b767"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
