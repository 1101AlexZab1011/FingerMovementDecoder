{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "import os\n",
    "current_dir = os.path.dirname(os.path.abspath('./'))\n",
    "if not current_dir in sys.path:\n",
    "    sys.path.append(current_dir)\n",
    "from combiners import EpochsCombiner\n",
    "from typing import *\n",
    "import mne\n",
    "import tensorflow as tf\n",
    "import mneflow as mf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn.metrics as sm\n",
    "from utils.machine_learning import one_hot_decoder\n",
    "from utils.machine_learning.confusion import ConfusionEstimator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne.set_log_level('CRITICAL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_root = '../'\n",
    "subjects_folder_path = os.path.join(content_root, 'Source/Subjects')\n",
    "subject_path = os.path.join(subjects_folder_path, 'Ga_Fed_06')\n",
    "info_path = os.path.join(subject_path, 'Info',\n",
    "                        'ML_Subject05_P1_tsss_mc_trans_info.pkl')\n",
    "resp_lock_lm_B1_epochs_path = os.path.join(\n",
    "    subject_path, 'Epochs', 'RespCor_LM_B1_epochs.fif')\n",
    "resp_lock_rm_B1_epochs_path = os.path.join(\n",
    "    subject_path, 'Epochs', 'RespCor_RM_B1_epochs.fif')\n",
    "resp_lock_li_B1_epochs_path = os.path.join(\n",
    "    subject_path, 'Epochs', 'RespCor_LI_B1_epochs.fif')\n",
    "resp_lock_ri_B1_epochs_path = os.path.join(\n",
    "    subject_path, 'Epochs', 'RespCor_RI_B1_epochs.fif')\n",
    "\n",
    "resp_lock_lm_B1_epochs = mne.read_epochs(resp_lock_lm_B1_epochs_path)\n",
    "resp_lock_li_B1_epochs = mne.read_epochs(resp_lock_li_B1_epochs_path)\n",
    "resp_lock_rm_B1_epochs = mne.read_epochs(resp_lock_rm_B1_epochs_path)\n",
    "resp_lock_ri_B1_epochs = mne.read_epochs(resp_lock_ri_B1_epochs_path)\n",
    "\n",
    "resp_lock_li_B1_epochs.resample(200)\n",
    "resp_lock_lm_B1_epochs.resample(200)\n",
    "resp_lock_ri_B1_epochs.resample(200)\n",
    "resp_lock_rm_B1_epochs.resample(200)\n",
    "\n",
    "combiner = EpochsCombiner(\n",
    "    resp_lock_lm_B1_epochs.copy(),\n",
    "    resp_lock_li_B1_epochs.copy(),\n",
    "    resp_lock_rm_B1_epochs.copy(),\n",
    "    resp_lock_ri_B1_epochs.copy()\n",
    ")\n",
    "first_class_indices = (0, 1)\n",
    "second_class_indices = (2, 3)\n",
    "combiner.combine(first_class_indices, second_class_indices, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing from tuple\n",
      "input shapes: X- (208, 204, 200) targets- (208, 1)\n",
      "Preprocessing:\n",
      "Scaling to interval 0.0 - 60.0\n",
      "Splitting sets\n",
      "Preprocessed: (208, 1, 200, 204) (208, 2) folds: 6 x 34\n",
      "Prepocessed sample shape: (1, 200, 204)\n",
      "Target shape actual/metadata:  (2,) (2,)\n",
      "Saving TFRecord# 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-21 17:38:28.277725: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-02-21 17:38:28.277761: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-02-21 17:38:28.277777: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (arcolinux-machine): /proc/driver/nvidia/version does not exist\n",
      "2022-02-21 17:38:28.278108: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting reg for dmx, to l2\n",
      "Built: dmx input: (None, 1, 200, 204)\n",
      "Setting reg for tconv, to l2\n",
      "Built: tconv input: (None, 1, 200, 32)\n",
      "Setting reg for fc, to l1\n",
      "Built: fc input: (None, 1, 20, 32)\n",
      "Input shape: (1, 200, 204)\n",
      "y_pred: (None, 2)\n",
      "Initialization complete!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "savepath = '../Source/Subjects/Az_Mar_05/TFR/left_vs_right/'\n",
    "project_name = 'fake_name'\n",
    "\n",
    "import_opt = dict(\n",
    "        savepath=savepath+'/',\n",
    "        out_name=project_name,\n",
    "        fs=200,\n",
    "        input_type='trials',\n",
    "        target_type='int',\n",
    "        picks={'meg': 'grad'},\n",
    "        scale=True,\n",
    "        crop_baseline=True,\n",
    "        decimate=None,\n",
    "        scale_interval=(0, 60),\n",
    "        n_folds=5,\n",
    "        overwrite=True,\n",
    "        segment=False,\n",
    "        test_set='holdout'\n",
    "    )\n",
    "meta = mf.produce_tfrecords((combiner.X, combiner.Y), **import_opt)\n",
    "dataset = mf.Dataset(meta, train_batch=100)\n",
    "lf_params = dict(\n",
    "        n_latent=32,\n",
    "        filter_length=50,\n",
    "        nonlin=tf.keras.activations.elu,\n",
    "        padding='SAME',\n",
    "        pooling=10,\n",
    "        stride=10,\n",
    "        pool_type='max',\n",
    "        model_path=import_opt['savepath'],\n",
    "        dropout=.4,\n",
    "        l2_scope=[\"weights\"],\n",
    "        l2=1e-6\n",
    ")\n",
    "\n",
    "model = mf.models.LFCNN(dataset, lf_params)\n",
    "model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path = os.path.join(subject_path, 'Weights', 'LM&LI_vs_RM&RI_B1-B8.h5')\n",
    "model.km.load_weights(weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 388ms/step - loss: 0.7108 - cat_ACC: 0.6897\n",
      "0.6896551847457886\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(model.dataset.val)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val acc 0.41379310344827586\n",
      "\tT\tF\n",
      "P\t9\t13\n",
      "N\t3\t4\n",
      "Accuracy: 0.41379310344827586\n",
      "Specificity: 0.1875\n",
      "Sensitivity: 0.6923076923076923\n",
      "train acc 0.52\n",
      "\tT\tF\n",
      "P\t42\t32\n",
      "N\t10\t16\n",
      "Accuracy: 0.52\n",
      "Specificity: 0.23809523809523808\n",
      "Sensitivity: 0.7241379310344828\n",
      "total acc 0.49612403100775193\n",
      "\tT\tF\n",
      "P\t51\t45\n",
      "N\t13\t20\n",
      "Accuracy: 0.49612403100775193\n",
      "Specificity: 0.22413793103448276\n",
      "Sensitivity: 0.7183098591549296\n"
     ]
    }
   ],
   "source": [
    "y_t_val, y_p_val = model.predict(model.dataset.val)\n",
    "\n",
    "print(\n",
    "    'val acc',\n",
    "    sm.accuracy_score(\n",
    "        one_hot_decoder(y_t_val),\n",
    "        one_hot_decoder(y_p_val),\n",
    "    )\n",
    ")\n",
    "\n",
    "tn, fp, fn, tp = sm.confusion_matrix(one_hot_decoder(y_t_val), one_hot_decoder(y_p_val)).ravel()\n",
    "ce = ConfusionEstimator(tp, tn, fp, fn)\n",
    "\n",
    "print(\n",
    "    f'\\tT\\tF\\n'\\\n",
    "    f'P\\t{tp}\\t{fp}\\n'\\\n",
    "    f'N\\t{tn}\\t{fn}\\n'\n",
    "    f'Accuracy: {ce.acc}\\n'\\\n",
    "    f'Specificity: {ce.spec}\\n'\\\n",
    "    f'Sensitivity: {ce.sens}'\n",
    ")\n",
    "y_t_train, y_p_train = model.predict(model.dataset.train)\n",
    "\n",
    "print(\n",
    "    'train acc',\n",
    "    sm.accuracy_score(\n",
    "        one_hot_decoder(y_t_train),\n",
    "        one_hot_decoder(y_p_train),\n",
    "    )\n",
    ")\n",
    "\n",
    "tn, fp, fn, tp = sm.confusion_matrix(one_hot_decoder(y_t_train), one_hot_decoder(y_p_train)).ravel()\n",
    "ce = ConfusionEstimator(tp, tn, fp, fn)\n",
    "\n",
    "print(\n",
    "    f'\\tT\\tF\\n'\\\n",
    "    f'P\\t{tp}\\t{fp}\\n'\\\n",
    "    f'N\\t{tn}\\t{fn}\\n'\n",
    "    f'Accuracy: {ce.acc}\\n'\\\n",
    "    f'Specificity: {ce.spec}\\n'\\\n",
    "    f'Sensitivity: {ce.sens}'\n",
    ")\n",
    "\n",
    "y_t = np.concatenate([y_t_val, y_t_train], axis=0)\n",
    "y_p = np.concatenate([y_p_val, y_p_train], axis=0)\n",
    "\n",
    "\n",
    "print(\n",
    "    'total acc',\n",
    "    sm.accuracy_score(\n",
    "        one_hot_decoder(y_t),\n",
    "        one_hot_decoder(y_p),\n",
    "    )\n",
    ")\n",
    "tn, fp, fn, tp = sm.confusion_matrix(one_hot_decoder(y_t), one_hot_decoder(y_p)).ravel()\n",
    "ce = ConfusionEstimator(tp, tn, fp, fn)\n",
    "\n",
    "print(\n",
    "    f'\\tT\\tF\\n'\\\n",
    "    f'P\\t{tp}\\t{fp}\\n'\\\n",
    "    f'N\\t{tn}\\t{fn}\\n'\n",
    "    f'Accuracy: {ce.acc}\\n'\\\n",
    "    f'Specificity: {ce.spec}\\n'\\\n",
    "    f'Sensitivity: {ce.sens}'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(208, 204, 200)\n",
      "(208, 1, 200, 204)\n"
     ]
    }
   ],
   "source": [
    "X = combiner.X.copy()\n",
    "print(X.shape)\n",
    "X = np.transpose(np.expand_dims(X, axis = 1), (0, 1, 3, 2))\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-21 14:02:45.894793: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 407347200 exceeds 10% of free system memory.\n",
      "2022-02-21 14:02:46.123099: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 135782400 exceeds 10% of free system memory.\n",
      "2022-02-21 14:02:46.855018: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 135782400 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Can't convert non-rectangular Python sequence to Tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/user/Projects/FingerMovementDecoder/dirty_field/LFCNN_load_weights.ipynb Cell 9'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/user/Projects/FingerMovementDecoder/dirty_field/LFCNN_load_weights.ipynb#ch0000008?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49mpredict((combiner\u001b[39m.\u001b[39;49mX, combiner\u001b[39m.\u001b[39;49mY))\n",
      "File \u001b[0;32m~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/mneflow/models.py:427\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/mneflow/models.py?line=424'>425</a>\u001b[0m     dataset \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39mval\n\u001b[1;32m    <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/mneflow/models.py?line=425'>426</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(dataset, \u001b[39mstr\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(dataset, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)):\n\u001b[0;32m--> <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/mneflow/models.py?line=426'>427</a>\u001b[0m     dataset \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset\u001b[39m.\u001b[39;49m_build_dataset(dataset, \n\u001b[1;32m    <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/mneflow/models.py?line=427'>428</a>\u001b[0m                                      split\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, \n\u001b[1;32m    <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/mneflow/models.py?line=428'>429</a>\u001b[0m                                      test_batch\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, \n\u001b[1;32m    <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/mneflow/models.py?line=429'>430</a>\u001b[0m                                      repeat\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/mneflow/models.py?line=430'>431</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(dataset, tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataset):\n\u001b[1;32m    <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/mneflow/models.py?line=431'>432</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mSpecify dataset\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/mneflow/data.py:79\u001b[0m, in \u001b[0;36mDataset._build_dataset\u001b[0;34m(self, path, split, train_batch, test_batch, repeat, val_fold_ind, holdout)\u001b[0m\n\u001b[1;32m     <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/mneflow/data.py?line=74'>75</a>\u001b[0m \u001b[39m\"\"\"Produce a tf.Dataset object and apply preprocessing\u001b[39;00m\n\u001b[1;32m     <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/mneflow/data.py?line=75'>76</a>\u001b[0m \u001b[39mfunctions if specified.\u001b[39;00m\n\u001b[1;32m     <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/mneflow/data.py?line=76'>77</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/mneflow/data.py?line=77'>78</a>\u001b[0m \u001b[39m# import and process parent dataset\u001b[39;00m\n\u001b[0;32m---> <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/mneflow/data.py?line=78'>79</a>\u001b[0m dataset \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mTFRecordDataset(path)\n\u001b[1;32m     <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/mneflow/data.py?line=80'>81</a>\u001b[0m dataset \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mmap(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parse_function)\n\u001b[1;32m     <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/mneflow/data.py?line=82'>83</a>\u001b[0m \u001b[39m# if self.channel_subset is not None:\u001b[39;00m\n\u001b[1;32m     <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/mneflow/data.py?line=83'>84</a>\u001b[0m \u001b[39m#     dataset = dataset.map(self._select_channels)\u001b[39;00m\n\u001b[1;32m     <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/mneflow/data.py?line=84'>85</a>\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/mneflow/data.py?line=96'>97</a>\u001b[0m     \n\u001b[1;32m     <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/mneflow/data.py?line=97'>98</a>\u001b[0m \u001b[39m#TODO: test set case\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/data/ops/readers.py:465\u001b[0m, in \u001b[0;36mTFRecordDatasetV2.__init__\u001b[0;34m(self, filenames, compression_type, buffer_size, num_parallel_reads, name)\u001b[0m\n\u001b[1;32m    <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/data/ops/readers.py?line=433'>434</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[1;32m    <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/data/ops/readers.py?line=434'>435</a>\u001b[0m              filenames,\n\u001b[1;32m    <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/data/ops/readers.py?line=435'>436</a>\u001b[0m              compression_type\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/data/ops/readers.py?line=436'>437</a>\u001b[0m              buffer_size\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/data/ops/readers.py?line=437'>438</a>\u001b[0m              num_parallel_reads\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/data/ops/readers.py?line=438'>439</a>\u001b[0m              name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/data/ops/readers.py?line=439'>440</a>\u001b[0m   \u001b[39m\"\"\"Creates a `TFRecordDataset` to read one or more TFRecord files.\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/data/ops/readers.py?line=440'>441</a>\u001b[0m \n\u001b[1;32m    <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/data/ops/readers.py?line=441'>442</a>\u001b[0m \u001b[39m  Each element of the dataset will contain a single TFRecord.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/data/ops/readers.py?line=462'>463</a>\u001b[0m \u001b[39m    ValueError: If any argument does not have the expected shape.\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/data/ops/readers.py?line=463'>464</a>\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/data/ops/readers.py?line=464'>465</a>\u001b[0m   filenames \u001b[39m=\u001b[39m _create_or_validate_filenames_dataset(filenames, name\u001b[39m=\u001b[39;49mname)\n\u001b[1;32m    <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/data/ops/readers.py?line=466'>467</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_filenames \u001b[39m=\u001b[39m filenames\n\u001b[1;32m    <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/data/ops/readers.py?line=467'>468</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compression_type \u001b[39m=\u001b[39m compression_type\n",
      "File \u001b[0;32m~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/data/ops/readers.py:67\u001b[0m, in \u001b[0;36m_create_or_validate_filenames_dataset\u001b[0;34m(filenames, name)\u001b[0m\n\u001b[1;32m     <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/data/ops/readers.py?line=64'>65</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/data/ops/readers.py?line=65'>66</a>\u001b[0m   filenames \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mmap_structure(_normalise_fspath, filenames)\n\u001b[0;32m---> <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/data/ops/readers.py?line=66'>67</a>\u001b[0m   filenames \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39;49mconvert_to_tensor(filenames, dtype_hint\u001b[39m=\u001b[39;49mdtypes\u001b[39m.\u001b[39;49mstring)\n\u001b[1;32m     <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/data/ops/readers.py?line=67'>68</a>\u001b[0m   \u001b[39mif\u001b[39;00m filenames\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m dtypes\u001b[39m.\u001b[39mstring:\n\u001b[1;32m     <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/data/ops/readers.py?line=68'>69</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m     <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/data/ops/readers.py?line=69'>70</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe `filenames` argument must contain `tf.string` elements. Got \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/data/ops/readers.py?line=70'>71</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`\u001b[39m\u001b[39m{\u001b[39;00mfilenames\u001b[39m.\u001b[39mdtype\u001b[39m!r}\u001b[39;00m\u001b[39m` elements.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py?line=180'>181</a>\u001b[0m   \u001b[39mwith\u001b[39;00m Trace(trace_name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrace_kwargs):\n\u001b[1;32m    <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py?line=181'>182</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py?line=182'>183</a>\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1695\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py?line=1689'>1690</a>\u001b[0m       \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mconvert_to_tensor did not convert to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py?line=1690'>1691</a>\u001b[0m                       \u001b[39m\"\u001b[39m\u001b[39mthe preferred dtype: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m vs \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py?line=1691'>1692</a>\u001b[0m                       (ret\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mbase_dtype, preferred_dtype\u001b[39m.\u001b[39mbase_dtype))\n\u001b[1;32m   <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py?line=1693'>1694</a>\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py?line=1694'>1695</a>\u001b[0m   ret \u001b[39m=\u001b[39m conversion_func(value, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname, as_ref\u001b[39m=\u001b[39;49mas_ref)\n\u001b[1;32m   <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py?line=1696'>1697</a>\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNotImplemented\u001b[39m:\n\u001b[1;32m   <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py?line=1697'>1698</a>\u001b[0m   \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:343\u001b[0m, in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=339'>340</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_constant_tensor_conversion_function\u001b[39m(v, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=340'>341</a>\u001b[0m                                          as_ref\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=341'>342</a>\u001b[0m   _ \u001b[39m=\u001b[39m as_ref\n\u001b[0;32m--> <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=342'>343</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m constant(v, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[0;32m~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:267\u001b[0m, in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=169'>170</a>\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mconstant\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[])\n\u001b[1;32m    <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=170'>171</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconstant\u001b[39m(value, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, shape\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConst\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=171'>172</a>\u001b[0m   \u001b[39m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=172'>173</a>\u001b[0m \n\u001b[1;32m    <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=173'>174</a>\u001b[0m \u001b[39m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=264'>265</a>\u001b[0m \u001b[39m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=265'>266</a>\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=266'>267</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m _constant_impl(value, dtype, shape, name, verify_shape\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=267'>268</a>\u001b[0m                         allow_broadcast\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:279\u001b[0m, in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=276'>277</a>\u001b[0m     \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\u001b[39m\"\u001b[39m\u001b[39mtf.constant\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=277'>278</a>\u001b[0m       \u001b[39mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m--> <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=278'>279</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[1;32m    <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=280'>281</a>\u001b[0m g \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mget_default_graph()\n\u001b[1;32m    <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=281'>282</a>\u001b[0m tensor_value \u001b[39m=\u001b[39m attr_value_pb2\u001b[39m.\u001b[39mAttrValue()\n",
      "File \u001b[0;32m~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:304\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=301'>302</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_constant_eager_impl\u001b[39m(ctx, value, dtype, shape, verify_shape):\n\u001b[1;32m    <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=302'>303</a>\u001b[0m   \u001b[39m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=303'>304</a>\u001b[0m   t \u001b[39m=\u001b[39m convert_to_eager_tensor(value, ctx, dtype)\n\u001b[1;32m    <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=304'>305</a>\u001b[0m   \u001b[39mif\u001b[39;00m shape \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=305'>306</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m t\n",
      "File \u001b[0;32m~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=99'>100</a>\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[1;32m    <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=100'>101</a>\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m--> <a href='file:///~/Projects/FingerMovementDecoder/venv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=101'>102</a>\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n",
      "\u001b[0;31mValueError\u001b[0m: Can't convert non-rectangular Python sequence to Tensor."
     ]
    }
   ],
   "source": [
    "model.predict((combiner.X, combiner.Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built: dmx input: (None, 1, 200, 204)\n",
      "Built: tconv input: (None, 1, 200, 32)\n",
      "Built: fc input: (None, 1, 20, 32)\n"
     ]
    }
   ],
   "source": [
    "models_path = '/home/user/Projects/FingerMovementDecoder/Source/Subjects/Ga_Fed_06/Models'\n",
    "model = tf.keras.models.load_model(\n",
    "    os.path.join(models_path, 'LM&LI_vs_RM&RI_B1-B8.h5'),\n",
    "    custom_objects={\n",
    "        'DeMixing': mf.layers.DeMixing,\n",
    "        'LFTConv': mf.layers.LFTConv,\n",
    "        'TempPooling': mf.layers.TempPooling,\n",
    "        'Dense': mf.layers.Dense,\n",
    "        'identity': tf.identity,\n",
    "        'softmax_cross_entropy_with_logits_v2': tf.compat.v1.nn.softmax_cross_entropy_with_logits_v2,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-21 20:40:56.771275: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 67891200 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(208, 2), dtype=float32, numpy=\n",
       "array([[-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114],\n",
       "       [-0.0070357, -0.0509114]], dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "25b6c1d617e3cb25e4067864bcd46322e1b7da41afdae0cf7c23b941b0b9b767"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
