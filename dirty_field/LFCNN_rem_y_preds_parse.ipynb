{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "current_dir = os.path.dirname(os.path.abspath('./'))\n",
    "if not current_dir in sys.path:\n",
    "    sys.path.append(current_dir)\n",
    "from combiners import EpochsCombiner\n",
    "from typing import *\n",
    "import mne\n",
    "import tensorflow as tf\n",
    "import mneflow as mf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from utils.data_management import dict2str\n",
    "from lfcnn_vis import plot_patterns\n",
    "from LFCNN_decoder import SpatialParameters, TemporalParameters, ComponentsOrder, Predictions\n",
    "import pickle\n",
    "from utils.machine_learning import one_hot_decoder\n",
    "import sklearn.metrics as sm\n",
    "from utils.machine_learning.confusion import ConfusionEstimator\n",
    "import scipy as sp\n",
    "\n",
    "def read_pkl(path: str) -> Any:\n",
    "    with open(\n",
    "            path,\n",
    "            'rb'\n",
    "        ) as file:\n",
    "        content = pickle.load(\n",
    "            file\n",
    "        )\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6960897477187333\n",
      "0.7250858165372503\n",
      "0.69343843076526\n",
      "0.847382132383333\n",
      "0.7089745948538733\n",
      "0.7634265758358783\n",
      "0.8270903123585336\n",
      "0.6895991021324355\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.661231856953922"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root = '../Source/Subjects'\n",
    "scores = 0\n",
    "case = 'lm_vs_li'\n",
    "i = 0\n",
    "for subj_name in os.listdir(root):\n",
    "    i += 1\n",
    "    \n",
    "    if subj_name == 'Pse_Udo':\n",
    "        continue\n",
    "    \n",
    "    tf_path = os.path.join(root, subj_name, 'TF_planes', 'BB1-BB8', 'RespCor')\n",
    "    tf_file = os.path.join(tf_path, f'{case}.pkl')\n",
    "    scorer = read_pkl(tf_file)\n",
    "    print(scorer.tf_scores.mean(0).max())\n",
    "    scores += scorer.tf_scores.mean(0).max()\n",
    "scores/i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils.console.colored import warn\n",
    "\n",
    "class PredictionsParser(object):\n",
    "    def __init__(\n",
    "        self,\n",
    "        y_true: Union[list[int], np.ndarray],\n",
    "        y_pred: Union[list[int], np.ndarray],\n",
    "        class_names: Optional[Union[str, list[str]]] = None\n",
    "    ):\n",
    "        \n",
    "        y_true = self.__check_numpy(y_true)\n",
    "        y_pred = self.__check_numpy(y_pred)\n",
    "        \n",
    "        if y_true.shape != y_pred.shape:\n",
    "            raise ValueError('Predictions and actual values are inconsistent. Actual values shape: {y_true.shape}, predictions shape: {y_pred.shape}')\n",
    "        \n",
    "        if len(y_true.shape) != 1:\n",
    "            y_true = one_hot_decoder(y_true)\n",
    "            y_pred = one_hot_decoder(y_pred)\n",
    "        \n",
    "        self._y_true = y_true\n",
    "        self._y_pred = y_pred\n",
    "        \n",
    "        self._accuracy = sm.accuracy_score(y_true, y_pred)\n",
    "        \n",
    "        classes_true = np.unique(self._y_true)\n",
    "        classes_pred = np.unique(self._y_pred)\n",
    "        \n",
    "        if np.any(classes_true != classes_pred):\n",
    "            warn(f'Warning: Classes are inconsistent.\\n\\tActual classes: {classes_true}\\n\\tPredicted classes: {classes_pred}.\\nTake actual classes')\n",
    "            \n",
    "        del classes_pred\n",
    "        \n",
    "        self._classes = classes_true\n",
    "        self._n_classes = len(classes_true)\n",
    "        \n",
    "        if class_names is not None:\n",
    "            \n",
    "            if isinstance(class_names, str):\n",
    "                class_names = class_names.split(' ')\n",
    "            \n",
    "            if len(class_names) != self.n_classes:\n",
    "                raise ValueError(f'Class names and classes are inconsistent: number of classes is {self.n_classes}, but {len(class_names)} names of classes were given')\n",
    "        else:\n",
    "            class_names = [f'Class {i}' for i in range(self.n_classes)]\n",
    "        \n",
    "        self._class_names = class_names\n",
    "        \n",
    "        self._confusion = pd.DataFrame(\n",
    "            sm.confusion_matrix(self.y_true, self.y_pred),\n",
    "            index = [f'Actual {class_name}' for class_name in self.class_names],\n",
    "            columns = [f'Predicted {class_name}' for class_name in self.class_names]\n",
    "        )\n",
    "    \n",
    "    @staticmethod\n",
    "    def __check_numpy(arr: Union[list, tuple, np.ndarray]):\n",
    "        if isinstance(arr, np.ndarray):\n",
    "            return arr\n",
    "        elif not isinstance(arr, np.ndarray) and isinstance(arr, (list, tuple)):\n",
    "            return np.array(arr)\n",
    "        else:\n",
    "            raise ValueError(f'The given argument must be either a np.ndarray or a list, but {type(arr)} was given')\n",
    "        \n",
    "    @property\n",
    "    def y_true(self):\n",
    "        return self._y_true\n",
    "    @y_true.setter\n",
    "    def y_true(self, value):\n",
    "        raise AttributeError('Impossible to set y_true directly')\n",
    "    \n",
    "    @property\n",
    "    def y_pred(self):\n",
    "        return self._y_pred\n",
    "    @y_pred.setter\n",
    "    def y_pred(self, value):\n",
    "        raise AttributeError('Impossible to set y_pred directly')\n",
    "    \n",
    "    @property\n",
    "    def accuracy(self):\n",
    "        return self._accuracy\n",
    "    @accuracy.setter\n",
    "    def accuracy(self, value):\n",
    "        raise AttributeError('Impossible to set accuracy directly')\n",
    "    \n",
    "    @property\n",
    "    def classes(self):\n",
    "        return self._classes\n",
    "    @classes.setter\n",
    "    def classes(self, value):\n",
    "        raise AttributeError('Impossible to set classes directly')\n",
    "    \n",
    "    @property\n",
    "    def n_classes(self):\n",
    "        return self._n_classes\n",
    "    @n_classes.setter\n",
    "    def n_classes(self, value):\n",
    "        raise AttributeError('Impossible to set number of classes directly')\n",
    "    \n",
    "    @property\n",
    "    def class_names(self):\n",
    "        return self._class_names\n",
    "    @class_names.setter\n",
    "    def class_names(self, value):\n",
    "        raise AttributeError('Impossible to set names for classes directly')\n",
    "    \n",
    "    @property\n",
    "    def confusion(self):\n",
    "        return self._confusion\n",
    "    @confusion.setter\n",
    "    def confusion(self, value):\n",
    "        raise AttributeError('Impossible to set confusion matrix directly')\n",
    "    \n",
    "    def summary(self, *args: str):\n",
    "        df = self.confusion.copy()\n",
    "        summary = pd.DataFrame(columns = self.class_names)\n",
    "        summary.loc['Total'] = [df[column].sum() for column in df.columns]\n",
    "        summary.loc['Accuracy'] = [None for _ in range(self.n_classes)]\n",
    "        summary.loc['Specificity'] = [None for _ in range(self.n_classes)]\n",
    "        summary.loc['Sensitivity'] = [None for _ in range(self.n_classes)]\n",
    "        \n",
    "        ec = self.estimate_confusion()\n",
    "        \n",
    "        args = list(args)\n",
    "        for i, arg in enumerate(args):\n",
    "            if not isinstance(arg, tuple):\n",
    "                args[i] = arg, arg\n",
    "        \n",
    "        for arg_value, arg_name in args:\n",
    "            if hasattr(ec[self.class_names[0]], arg_value):\n",
    "                summary.loc[arg_name] = [None for _ in range(self.n_classes)]\n",
    "            else:\n",
    "                warn(f'WARNING: the {arg_value} property was not found in the confusion evaluator, so it was ignored')\n",
    "                args.remove((arg_value, arg_name))\n",
    "            \n",
    "        \n",
    "        for i, class_name in enumerate(self.class_names):\n",
    "            summary[class_name].loc['Accuracy'] = ec[class_name].acc\n",
    "            summary[class_name].loc['Specificity'] = ec[class_name].spec\n",
    "            summary[class_name].loc['Sensitivity'] = ec[class_name].sens\n",
    "            \n",
    "            for arg_value, arg_name in args:\n",
    "                summary[class_name].loc[arg_name] = getattr(ec[class_name], arg_value)\n",
    "            \n",
    "        return summary\n",
    "    \n",
    "    def estimate_confusion(self):\n",
    "        \n",
    "        return {\n",
    "            class_name: ConfusionEstimator(\n",
    "                # tp, tn, fp, fn\n",
    "                self.confusion[self.confusion.columns[i]][self.confusion.index[i]],\n",
    "                self.confusion[\n",
    "                    list(self.confusion.columns[:i]) + list(self.confusion.columns[i+1:])\n",
    "                    ].loc[\n",
    "                        list(self.confusion.index[:i]) + list(self.confusion.index[i+1:])\n",
    "                ].sum().sum(),\n",
    "                self.confusion[self.confusion.columns[i]].loc[\n",
    "                    list(self.confusion.index[:i]) + list(self.confusion.index[i+1:])\n",
    "                ].sum(),\n",
    "                self.confusion[\n",
    "                    list(self.confusion.columns[:i]) + list(self.confusion.columns[i+1:])\n",
    "                ].loc[self.confusion.index[i]].sum()\n",
    "            )\n",
    "            for i, class_name in enumerate(self.class_names)\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/Projects/FingerMovementDecoder/utils/machine_learning/confusion.py:300: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self._lr_plus = self.tpr / self.fpr\n",
      "/home/user/Projects/FingerMovementDecoder/utils/machine_learning/confusion.py:300: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self._lr_plus = self.tpr / self.fpr\n",
      "/home/user/Projects/FingerMovementDecoder/utils/machine_learning/confusion.py:300: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self._lr_plus = self.tpr / self.fpr\n",
      "/home/user/Projects/FingerMovementDecoder/utils/machine_learning/confusion.py:300: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self._lr_plus = self.tpr / self.fpr\n",
      "/home/user/Projects/FingerMovementDecoder/utils/machine_learning/confusion.py:300: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self._lr_plus = self.tpr / self.fpr\n",
      "/home/user/Projects/FingerMovementDecoder/utils/machine_learning/confusion.py:300: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self._lr_plus = self.tpr / self.fpr\n",
      "/tmp/ipykernel_3260006/3332066588.py:51: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  sumdf.to_excel(os.path.join(classification_tables_path, f'{subject_name}_{classification}_summary.xls'))\n",
      "/tmp/ipykernel_3260006/3332066588.py:52: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  confdf.to_excel(os.path.join(classification_tables_path, f'{subject_name}_{classification}_confusion.xls'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Source/perf_tables/Ga_Fed_06/B1-B8_LFRNN/Ga_Fed_06_RM&RI_vs_LM&LI_summary.xls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3260006/3332066588.py:51: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  sumdf.to_excel(os.path.join(classification_tables_path, f'{subject_name}_{classification}_summary.xls'))\n",
      "/tmp/ipykernel_3260006/3332066588.py:52: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  confdf.to_excel(os.path.join(classification_tables_path, f'{subject_name}_{classification}_confusion.xls'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Source/perf_tables/Fe_To_08/B1-B8_LFRNN/Fe_To_08_RM&RI_vs_LM&LI_summary.xls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3260006/3332066588.py:51: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  sumdf.to_excel(os.path.join(classification_tables_path, f'{subject_name}_{classification}_summary.xls'))\n",
      "/tmp/ipykernel_3260006/3332066588.py:52: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  confdf.to_excel(os.path.join(classification_tables_path, f'{subject_name}_{classification}_confusion.xls'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Source/perf_tables/Az_Mar_05/B1-B8_LFRNN/Az_Mar_05_RM&RI_vs_LM&LI_summary.xls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/Projects/FingerMovementDecoder/utils/machine_learning/confusion.py:300: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self._lr_plus = self.tpr / self.fpr\n",
      "/home/user/Projects/FingerMovementDecoder/utils/machine_learning/confusion.py:300: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self._lr_plus = self.tpr / self.fpr\n",
      "/home/user/Projects/FingerMovementDecoder/utils/machine_learning/confusion.py:300: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self._lr_plus = self.tpr / self.fpr\n",
      "/home/user/Projects/FingerMovementDecoder/utils/machine_learning/confusion.py:300: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self._lr_plus = self.tpr / self.fpr\n",
      "/home/user/Projects/FingerMovementDecoder/utils/machine_learning/confusion.py:300: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self._lr_plus = self.tpr / self.fpr\n",
      "/home/user/Projects/FingerMovementDecoder/utils/machine_learning/confusion.py:300: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self._lr_plus = self.tpr / self.fpr\n",
      "/tmp/ipykernel_3260006/3332066588.py:51: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  sumdf.to_excel(os.path.join(classification_tables_path, f'{subject_name}_{classification}_summary.xls'))\n",
      "/tmp/ipykernel_3260006/3332066588.py:52: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  confdf.to_excel(os.path.join(classification_tables_path, f'{subject_name}_{classification}_confusion.xls'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Source/perf_tables/Ku_EL_09/B1-B8_LFRNN/Ku_EL_09_RM&RI_vs_LM&LI_summary.xls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/Projects/FingerMovementDecoder/utils/machine_learning/confusion.py:300: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self._lr_plus = self.tpr / self.fpr\n",
      "/home/user/Projects/FingerMovementDecoder/utils/machine_learning/confusion.py:302: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self._dor = self.lr_plus / self.lr_minus\n",
      "/home/user/Projects/FingerMovementDecoder/utils/machine_learning/confusion.py:300: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self._lr_plus = self.tpr / self.fpr\n",
      "/home/user/Projects/FingerMovementDecoder/utils/machine_learning/confusion.py:302: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self._dor = self.lr_plus / self.lr_minus\n",
      "/home/user/Projects/FingerMovementDecoder/utils/machine_learning/confusion.py:300: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self._lr_plus = self.tpr / self.fpr\n",
      "/home/user/Projects/FingerMovementDecoder/utils/machine_learning/confusion.py:302: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self._dor = self.lr_plus / self.lr_minus\n",
      "/tmp/ipykernel_3260006/3332066588.py:51: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  sumdf.to_excel(os.path.join(classification_tables_path, f'{subject_name}_{classification}_summary.xls'))\n",
      "/tmp/ipykernel_3260006/3332066588.py:52: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  confdf.to_excel(os.path.join(classification_tables_path, f'{subject_name}_{classification}_confusion.xls'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Source/perf_tables/Pr_An_04/B1-B8_LFRNN/Pr_An_04_RM&RI_vs_LM&LI_summary.xls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3260006/3332066588.py:51: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  sumdf.to_excel(os.path.join(classification_tables_path, f'{subject_name}_{classification}_summary.xls'))\n",
      "/tmp/ipykernel_3260006/3332066588.py:52: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  confdf.to_excel(os.path.join(classification_tables_path, f'{subject_name}_{classification}_confusion.xls'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Source/perf_tables/Ru_Ek_07/B1-B8_LFRNN/Ru_Ek_07_RM&RI_vs_LM&LI_summary.xls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3260006/3332066588.py:51: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  sumdf.to_excel(os.path.join(classification_tables_path, f'{subject_name}_{classification}_summary.xls'))\n",
      "/tmp/ipykernel_3260006/3332066588.py:52: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  confdf.to_excel(os.path.join(classification_tables_path, f'{subject_name}_{classification}_confusion.xls'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Source/perf_tables/Se_Tu_03/B1-B8_LFRNN/Se_Tu_03_RM&RI_vs_LM&LI_summary.xls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3260006/3332066588.py:51: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  sumdf.to_excel(os.path.join(classification_tables_path, f'{subject_name}_{classification}_summary.xls'))\n",
      "/tmp/ipykernel_3260006/3332066588.py:52: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  confdf.to_excel(os.path.join(classification_tables_path, f'{subject_name}_{classification}_confusion.xls'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Source/perf_tables/Te_Ali_11/B1-B8_LFRNN/Te_Ali_11_RM&RI_vs_LM&LI_summary.xls\n",
      "../Source/perf_tables/Pse_Udo/B1-B8_LFRNN/Pse_Udo_RM&RI_vs_LM&LI_summary.xls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3260006/3332066588.py:51: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  sumdf.to_excel(os.path.join(classification_tables_path, f'{subject_name}_{classification}_summary.xls'))\n",
      "/tmp/ipykernel_3260006/3332066588.py:52: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  confdf.to_excel(os.path.join(classification_tables_path, f'{subject_name}_{classification}_confusion.xls'))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "perf_tables_path = '../Source/perf_tables/'\n",
    "from utils.storage_management import check_path\n",
    "postfix = 'B1-B8_LFRNN'\n",
    "check_path(perf_tables_path)\n",
    "\n",
    "for subject_name in os.listdir(f'../Source/Subjects/'):\n",
    "    \n",
    "    subject_perf_tables_path = os.path.join(perf_tables_path, subject_name)\n",
    "    check_path(subject_perf_tables_path)\n",
    "\n",
    "    path = f'../Source/Subjects/{subject_name}/LFRNN'\n",
    "\n",
    "    classification_tables_path = os.path.join(subject_perf_tables_path, f'{postfix}')\n",
    "    check_path(classification_tables_path)\n",
    "    \n",
    "    sumdf = pd.DataFrame()\n",
    "    confdf = pd.DataFrame()\n",
    "    for classification in [\n",
    "        'RM_vs_RI_vs_LM_vs_LI',\n",
    "        'RM_vs_RI',\n",
    "        'LM_vs_LI',\n",
    "        'RM&RI_vs_LM&LI'\n",
    "    ]:\n",
    "        file_name = f'{classification}_{postfix}_pred.pkl'\n",
    "        class_names = classification.split('_vs_')\n",
    "\n",
    "        try:\n",
    "            predictions = read_pkl(\n",
    "                os.path.join(path, 'Predictions', file_name)\n",
    "            )\n",
    "        except FileNotFoundError:\n",
    "            warn(f'File does not exist: {os.path.join(path, \"Predictions\", file_name)}')\n",
    "            continue\n",
    "        pp = PredictionsParser(predictions.y_true, predictions.y_p, class_names)\n",
    "        \n",
    "        sumdf = pd.concat([\n",
    "                sumdf,\n",
    "                pp.summary(),\n",
    "                pd.DataFrame([None for _ in range(pp.summary().shape[0])], index=pp.summary().index),\n",
    "            ],\n",
    "            axis=1\n",
    "        )\n",
    "        confdf = pd.concat([\n",
    "                confdf,\n",
    "                pp.confusion,\n",
    "                # pd.DataFrame([None for _ in range(pp.confusion.shape[0])], index=pp.confusion.index),\n",
    "                pd.DataFrame(list(confdf.index), index=confdf.index),\n",
    "            ],\n",
    "            axis=1\n",
    "        )\n",
    "    sumdf.to_excel(os.path.join(classification_tables_path, f'{subject_name}_{classification}_summary.xls'))\n",
    "    confdf.to_excel(os.path.join(classification_tables_path, f'{subject_name}_{classification}_confusion.xls'))\n",
    "    print(os.path.join(classification_tables_path, f'{subject_name}_{classification}_summary.xls'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/Projects/FingerMovementDecoder/utils/machine_learning/confusion.py:300: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self._lr_plus = self.tpr / self.fpr\n",
      "/home/user/Projects/FingerMovementDecoder/utils/machine_learning/confusion.py:300: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self._lr_plus = self.tpr / self.fpr\n",
      "/home/user/Projects/FingerMovementDecoder/utils/machine_learning/confusion.py:300: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self._lr_plus = self.tpr / self.fpr\n",
      "/home/user/Projects/FingerMovementDecoder/utils/machine_learning/confusion.py:300: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self._lr_plus = self.tpr / self.fpr\n",
      "/home/user/Projects/FingerMovementDecoder/utils/machine_learning/confusion.py:300: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self._lr_plus = self.tpr / self.fpr\n",
      "/home/user/Projects/FingerMovementDecoder/utils/machine_learning/confusion.py:302: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self._dor = self.lr_plus / self.lr_minus\n",
      "/tmp/ipykernel_3260006/913632873.py:57: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  sumdf.to_excel(\n",
      "/tmp/ipykernel_3260006/913632873.py:60: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  confdf.to_excel(os.path.join(classification_tables_path, f'group_{classification}_confusion.xls'))\n"
     ]
    }
   ],
   "source": [
    "from utils.storage_management import check_path\n",
    "perf_tables_path = '../Source/perf_tables/LFRNN'\n",
    "check_path(perf_tables_path)\n",
    "from utils.storage_management import check_path\n",
    "postfix = 'B1-B8_LFRNN'\n",
    "group_tables_path = os.path.join(perf_tables_path, 'Group')\n",
    "check_path(group_tables_path)\n",
    "classification_tables_path = os.path.join(group_tables_path, postfix)\n",
    "check_path(perf_tables_path, group_tables_path, classification_tables_path)\n",
    "\n",
    "sumdf = pd.DataFrame()\n",
    "confdf = pd.DataFrame()\n",
    "for classification in [\n",
    "        'RM_vs_RI_vs_LM_vs_LI',\n",
    "        'RM_vs_RI',\n",
    "        'LM_vs_LI',\n",
    "        'RM&RI_vs_LM&LI'\n",
    "    ]:\n",
    "    conf = list()\n",
    "    summary = list()\n",
    "    for subject_name in os.listdir(f'../Source/Subjects/'):\n",
    "        path = f'../Source/Subjects/{subject_name}/LFRNN'\n",
    "        check_path(path)\n",
    "        \n",
    "        file_name = f'{classification}_{postfix}_pred.pkl'\n",
    "        class_names = classification.split('_vs_')\n",
    "\n",
    "        try:\n",
    "            predictions = read_pkl(\n",
    "                os.path.join(path, 'Predictions', file_name)\n",
    "            )\n",
    "        except FileNotFoundError:\n",
    "            warn(f'File does not exist: {os.path.join(path, \"Predictions\", file_name)}')\n",
    "            continue\n",
    "        pp = PredictionsParser(predictions.y_true, predictions.y_p, class_names)\n",
    "        conf.append(pp.confusion)\n",
    "        summary.append(pp.summary())\n",
    "    \n",
    "    index, columns = summary[0].index, summary[0].columns\n",
    "    data = np.array([c.to_numpy() for c in summary]).mean(0)\n",
    "    local_summary = pd.DataFrame(data, index=index, columns=columns)\n",
    "    sumdf = pd.concat([\n",
    "        sumdf,\n",
    "        local_summary,\n",
    "        pd.DataFrame([None for _ in range(local_summary.shape[0])], index=local_summary.index),\n",
    "    ], axis=1)\n",
    "    \n",
    "    index, columns = conf[0].index, conf[0].columns\n",
    "    data = np.array([s.to_numpy() for s in conf]).mean(0)\n",
    "    local_conf = pd.DataFrame(data, index=index, columns=columns)\n",
    "    confdf = pd.concat([\n",
    "        confdf,\n",
    "        local_conf,\n",
    "        pd.DataFrame(list(local_conf.index), index=local_conf.index),\n",
    "    ], axis=1)\n",
    "\n",
    "sumdf.to_excel(\n",
    "    os.path.join(classification_tables_path, f'group_{classification}_summary.xls')\n",
    ")\n",
    "confdf.to_excel(os.path.join(classification_tables_path, f'group_{classification}_confusion.xls'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ga_Fed_06\n",
      "Total accuracy:  0.55\n",
      "                LM     LI     RM    RI\n",
      "Total        16.00  12.00  16.00  9.00\n",
      "Accuracy      0.77   0.77   0.77  0.77\n",
      "Specificity   0.84   0.89   0.80  0.86\n",
      "Sensitivity   0.62   0.50   0.67  0.33\n",
      "           Predicted LM  Predicted LI  Predicted RM  Predicted RI\n",
      "Actual LM            10             4             1             1\n",
      "Actual LI             6             8             1             1\n",
      "Actual RM             0             0             8             4\n",
      "Actual RI             0             0             6             3\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Fe_To_08\n",
      "Total accuracy:  0.57\n",
      "                LM     LI     RM    RI\n",
      "Total        12.00  18.00  16.00  8.00\n",
      "Accuracy      0.78   0.76   0.80  0.81\n",
      "Specificity   0.92   0.78   0.81  0.93\n",
      "Sensitivity   0.50   0.69   0.73  0.42\n",
      "           Predicted LM  Predicted LI  Predicted RM  Predicted RI\n",
      "Actual LM             9             7             2             0\n",
      "Actual LI             2             9             1             1\n",
      "Actual RM             1             0             8             2\n",
      "Actual RI             0             2             5             5\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Az_Mar_05\n",
      "Total accuracy:  0.29\n",
      "                LM     LI     RM     RI\n",
      "Total        11.00  14.00  16.00  11.00\n",
      "Accuracy      0.60   0.60   0.71   0.67\n",
      "Specificity   0.76   0.70   0.78   0.82\n",
      "Sensitivity   0.14   0.11   0.53   0.29\n",
      "           Predicted LM  Predicted LI  Predicted RM  Predicted RI\n",
      "Actual LM             2             9             1             2\n",
      "Actual LI             2             1             3             3\n",
      "Actual RM             2             3             8             2\n",
      "Actual RI             5             1             4             4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ku_EL_09\n",
      "Total accuracy:  0.62\n",
      "                LM     LI    RM     RI\n",
      "Total        17.00  13.00  9.00  14.00\n",
      "Accuracy      0.89   0.79  0.74   0.83\n",
      "Specificity   0.89   0.84  0.94   0.84\n",
      "Sensitivity   0.87   0.60  0.37   0.78\n",
      "           Predicted LM  Predicted LI  Predicted RM  Predicted RI\n",
      "Actual LM            13             2             0             0\n",
      "Actual LI             3             6             0             1\n",
      "Actual RM             1             5             7             6\n",
      "Actual RI             0             0             2             7\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001b[93mWarning: Classes are inconsistent.\n",
      "\tActual classes: [0 1 2 3]\n",
      "\tPredicted classes: [0 1 2].\n",
      "Take actual classes\u001b[0m\n",
      "Pr_An_04\n",
      "Total accuracy:  0.49\n",
      "                LM     LI     RM    RI\n",
      "Total        13.00  17.00  23.00  0.00\n",
      "Accuracy      0.72   0.75   0.66  0.85\n",
      "Specificity   0.84   0.78   0.67  1.00\n",
      "Sensitivity   0.44   0.67   0.65  0.00\n",
      "           Predicted LM  Predicted LI  Predicted RM  Predicted RI\n",
      "Actual LM             7             5             4             0\n",
      "Actual LI             2             8             2             0\n",
      "Actual RM             3             3            11             0\n",
      "Actual RI             1             1             6             0\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ru_Ek_07\n",
      "Total accuracy:  0.62\n",
      "               LM     LI     RM     RI\n",
      "Total        9.00  10.00  20.00  13.00\n",
      "Accuracy     0.92   0.81   0.77   0.73\n",
      "Specificity  0.93   0.90   0.81   0.82\n",
      "Sensitivity  0.86   0.50   0.70   0.46\n",
      "           Predicted LM  Predicted LI  Predicted RM  Predicted RI\n",
      "Actual LM             6             1             0             0\n",
      "Actual LI             3             6             1             2\n",
      "Actual RM             0             1            14             5\n",
      "Actual RI             0             2             5             6\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Se_Tu_03\n",
      "Total accuracy:  0.50\n",
      "               LM     LI     RM    RI\n",
      "Total        5.00  21.00  22.00  8.00\n",
      "Accuracy     0.84   0.77   0.70  0.70\n",
      "Specificity  0.94   0.78   0.72  0.88\n",
      "Sensitivity  0.25   0.75   0.65  0.20\n",
      "           Predicted LM  Predicted LI  Predicted RM  Predicted RI\n",
      "Actual LM             2             6             0             0\n",
      "Actual LI             2            12             1             1\n",
      "Actual RM             1             1            11             4\n",
      "Actual RI             0             2            10             3\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Te_Ali_11\n",
      "Total accuracy:  0.45\n",
      "                LM    LI     RM     RI\n",
      "Total        12.00  8.00  22.00  11.00\n",
      "Accuracy      0.74  0.74   0.72   0.72\n",
      "Specificity   0.85  0.86   0.70   0.86\n",
      "Sensitivity   0.43  0.20   0.77   0.38\n",
      "           Predicted LM  Predicted LI  Predicted RM  Predicted RI\n",
      "Actual LM             6             4             3             1\n",
      "Actual LI             3             2             2             3\n",
      "Actual RM             0             2            10             1\n",
      "Actual RI             3             0             7             6\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19962/2523103007.py:30: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  if np.any(classes_true != classes_pred):\n",
      "/home/user/Projects/FingerMovementDecoder/utils/machine_learning/confusion.py:255: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  self._ppv = self.tp / (self.tp + self.fp)\n",
      "/home/user/Projects/FingerMovementDecoder/utils/machine_learning/confusion.py:263: RuntimeWarning: invalid value encountered in true_divide\n",
      "  self._mcc = (self.tp * self.tn - self.fp * self.fn) / \\\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "subjects_path = '../Source/Subjects/'\n",
    "file_name = 'LM_vs_LI_vs_RM_vs_RI_B1-B8_pred.pkl'\n",
    "# file_name = 'LM&LI_vs_RM&RI_B1-B8_pred.pkl'\n",
    "class_names = file_name[:-15].split('_vs_')\n",
    "\n",
    "for subject_name in os.listdir(subjects_path):\n",
    "    \n",
    "    if subject_name == 'Pse_Udo':\n",
    "        continue\n",
    "    \n",
    "    subject_path = os.path.join(subjects_path, subject_name)\n",
    "\n",
    "    predictions = read_pkl(\n",
    "        os.path.join(subject_path, 'Predictions', file_name)\n",
    "    )\n",
    "\n",
    "    pp = PredictionsParser(predictions.y_true, predictions.y_p, class_names)\n",
    "    print(subject_name)\n",
    "    print(f'Total accuracy: {pp.accuracy : .2f}')\n",
    "    summary = pp.summary()\n",
    "    summary = summary.astype(float).round(2)\n",
    "    print(summary)\n",
    "    print(pp.confusion)\n",
    "    print('-'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ga_Fed_06\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [196]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m y_p \u001b[39m=\u001b[39m one_hot_decoder(predictions\u001b[39m.\u001b[39my_p)\n\u001b[1;32m     22\u001b[0m \u001b[39mprint\u001b[39m(subject_name)\n\u001b[0;32m---> 23\u001b[0m tn, fp, fn, tp \u001b[39m=\u001b[39m sm\u001b[39m.\u001b[39mconfusion_matrix(y_t, y_p)\u001b[39m.\u001b[39mravel()\n\u001b[1;32m     24\u001b[0m ce \u001b[39m=\u001b[39m ConfusionEstimator(tp, tn, fp, fn)\n\u001b[1;32m     26\u001b[0m \u001b[39mprint\u001b[39m(\n\u001b[1;32m     27\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39mT\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39mF\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\\\n\u001b[1;32m     28\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mP\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m{\u001b[39;00mtp\u001b[39m}\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{\u001b[39;00mfp\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\\\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mSensitivity: \u001b[39m\u001b[39m{\u001b[39;00mce\u001b[39m.\u001b[39msens\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m     33\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 1)"
     ]
    }
   ],
   "source": [
    "subjects_path = '../Source/Subjects/'\n",
    "# file_name = 'LM_vs_LI_vs_RM_vs_RI_B1-B8_pred.pkl'\n",
    "# file_name = 'LM&LI_vs_RM&RI_B1-B8_pred.pkl'\n",
    "file_name = 'LM_vs_LI_B1-B8_pred.pkl'\n",
    "class_names = file_name[:-15].split('_vs_')\n",
    "\n",
    "for subject_name in os.listdir(subjects_path):\n",
    "    \n",
    "    if subject_name == 'Pse_Udo':\n",
    "        continue\n",
    "    \n",
    "    subject_path = os.path.join(subjects_path, subject_name)\n",
    "\n",
    "    predictions = read_pkl(\n",
    "        os.path.join(subject_path, 'Predictions', file_name),\n",
    "    )\n",
    "\n",
    "    y_t = one_hot_decoder(predictions.y_true)\n",
    "\n",
    "    y_p = one_hot_decoder(predictions.y_p)\n",
    "\n",
    "    print(subject_name)\n",
    "    tn, fp, fn, tp = sm.confusion_matrix(y_t, y_p).ravel()\n",
    "    ce = ConfusionEstimator(tp, tn, fp, fn)\n",
    "\n",
    "    print(\n",
    "        f'\\tT\\tF\\n'\\\n",
    "        f'P\\t{tp}\\t{fp}\\n'\\\n",
    "        f'N\\t{tn}\\t{fn}\\n'\n",
    "        f'Accuracy: {ce.acc}\\n'\\\n",
    "        f'Specificity: {ce.spec}\\n'\\\n",
    "        f'Sensitivity: {ce.sens}\\n'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_sp(iy, waveforms, temporal_parameters, spatial_parameters, info, *, logscale=False, suptitle=None):\n",
    "    data = spatial_parameters.patterns.copy()\n",
    "    # fig2, axs = plt.subplots(3)\n",
    "    # ax21, ax22, ax23 = axs\n",
    "    fig2 = plt.figure(constrained_layout=False)\n",
    "    gs2 = fig2.add_gridspec(\n",
    "        nrows=9,\n",
    "        ncols=2,#3,\n",
    "        bottom=.1,\n",
    "        wspace=.05,\n",
    "        hspace=.1\n",
    "    )\n",
    "    ax21 = fig2.add_subplot(gs2[:3, :])\n",
    "    ax22 = fig2.add_subplot(gs2[3:6, :])#1:2])\n",
    "    ax23 = fig2.add_subplot(gs2[6:, :])#1:2])\n",
    "    plot_patterns(data, info, iy, ax21, name_format='', title='')\n",
    "    ax22_t = ax22.twinx()\n",
    "    ax22_t.plot(sp.stats.zscore(waveforms.evoked[iy]), '#454545')\n",
    "    pos = ax22.imshow(np.flip(waveforms.induced[iy, :, :], axis=0), cmap='RdBu_r')\n",
    "    cb = fig2.colorbar(pos, ax=ax22, pad=0.2, orientation='horizontal', aspect=75, fraction=.12)\n",
    "    ax22.set_aspect('auto')\n",
    "    ax22_t.set_aspect('auto')\n",
    "    # ax22_t.set_ylim(top=1, bottom=-1)\n",
    "    ax23.plot(\n",
    "        temporal_parameters.franges,\n",
    "        sp.stats.zscore(temporal_parameters.finputs[iy]),\n",
    "        temporal_parameters.franges,\n",
    "        sp.stats.zscore(temporal_parameters.foutputs[iy]),\n",
    "        temporal_parameters.franges,\n",
    "        sp.stats.zscore(temporal_parameters.fresponces[iy]),\n",
    "    )\n",
    "    ax22_t.set_ylabel('Amplitude (Î¼V)', labelpad=30, rotation=270)\n",
    "    ax22_t.spines['top'].set_alpha(.2)\n",
    "    ax22_t.spines['right'].set_alpha(.2)\n",
    "    ax22_t.spines['left'].set_alpha(.2)\n",
    "    ax22_t.spines['bottom'].set_alpha(.2)\n",
    "    ax22_t.tick_params(axis='both', which='both',length=5, color='#00000050')\n",
    "    ax22.spines['top'].set_alpha(.2)\n",
    "    ax22.spines['right'].set_alpha(.2)\n",
    "    ax22.spines['left'].set_alpha(.2)\n",
    "    ax22.spines['bottom'].set_alpha(.2)\n",
    "    ax22.tick_params(axis='both', which='both',length=5, color='#00000050')\n",
    "    cb.outline.set_color('#00000020')\n",
    "    cb.ax.tick_params(axis='both', which='both',length=5, color='#00000050')\n",
    "    times = np.unique(np.round(waveforms.times, 1))\n",
    "    ranges = np.linspace(0, len(waveforms.times), len(times)).astype(int)\n",
    "    ax22.set_xticks(ranges)\n",
    "    ax22.set_xticklabels(times)\n",
    "    freqs = [0] + [(i+1) for i in range(waveforms.induced.shape[-2]) if (i+1)%10==0]\n",
    "    ax22.set_yticks(freqs)\n",
    "    ax22.set_yticklabels(sorted(freqs, reverse=True))\n",
    "    ax22.set_xlabel('Time (s)')\n",
    "    ax22.set_ylabel('Frequency (Hz)', labelpad=30)\n",
    "    ax23.legend(['Filter input', 'Filter output', 'Filter responce'], loc='upper right')\n",
    "    ax23.spines['top'].set_alpha(.2)\n",
    "    ax23.spines['right'].set_alpha(.2)\n",
    "    ax23.spines['left'].set_alpha(.2)\n",
    "    ax23.spines['bottom'].set_alpha(.2)\n",
    "    ax23.tick_params(axis='both', which='both',length=5, color='#00000050')\n",
    "    ax23.set_xlabel('Frequency (Hz)')\n",
    "    ax23.set_ylabel('Amplitude (Î¼V)')\n",
    "\n",
    "    if logscale:\n",
    "        ax23.set_yscale('log')\n",
    "    if suptitle is None:\n",
    "        fig2.suptitle(f'Latent source {iy + 1}')\n",
    "    else:\n",
    "        fig2.suptitle(suptitle)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ComponentsOrder(l2=None, compwise_loss=None, weight=None, output_corr=None, weight_corr=None)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "subject_name = 'Az_Mar_05'\n",
    "from lfcnn_vis import *\n",
    "from collections import Counter\n",
    "cases_to_combine = ['RM', 'RI', 'LM', 'LI']\n",
    "option = 2\n",
    "option = {1: 'B1-B3', 2: 'B10-B12'}[option]\n",
    "\n",
    "classification_name,\\\n",
    "    classification_postfix,\\\n",
    "    classification_prefix = None, '', ''\n",
    "cases_to_combine = [case.split(' ') for case in cases_to_combine]\n",
    "\n",
    "cases_to_combine = sorted(cases_to_combine, reverse=True)\n",
    "class_names = ['&'.join(sorted(cases_combination, reverse=True)) for cases_combination in cases_to_combine]\n",
    "\n",
    "if classification_name is None:\n",
    "    classification_name = '_vs_'.join(class_names)\n",
    "\n",
    "model = f'LFCNN_train_{option}'\n",
    "subjects_dir = os.path.join('../', 'Source', 'Subjects')\n",
    "classification_name_formatted = \"_\".join(list(filter(lambda s: s not in (None, \"\"), [classification_prefix, classification_name, classification_postfix])))\n",
    "subject_info_path = os.path.join(subjects_dir, subject_name, 'Info')\n",
    "subject_parameters_path = os.path.join(subjects_dir, subject_name, model, 'Parameters')\n",
    "spatial_parameters = read_pkl(os.path.join(subject_parameters_path, f'{classification_name_formatted}_spatial.pkl'))\n",
    "temporal_parameters = read_pkl(os.path.join(subject_parameters_path, f'{classification_name_formatted}_temporal.pkl'))\n",
    "waveforms = read_pkl(os.path.join(subject_parameters_path, f'{classification_name_formatted}_waveforms.pkl'))\n",
    "orders = read_pkl(os.path.join(subject_parameters_path, f'{classification_name_formatted}_sorting.pkl'))\n",
    "# all_orders = dict(sorted(Counter(np.matrix.flatten(np.squeeze([orders[order_name] for order_name in range(len(orders))]))).items(), key=lambda x: x[1], reverse=True))\n",
    "# all_orders\n",
    "orders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log\n",
    "#### Components indices are written in brackets\n",
    "\n",
    "* Az_Mar_05, B7-B8, The most frequent components (29, 17) has small sum of weights and noisy patterns, so components with the highest sum pf weights (30, 12) have been chosen.\n",
    "* Fe_To_08, B7-B8, The most frequent component is (7), but (13, 17) has been chosen, as they have bigger sum of weights.\n",
    "* Ku_EL_09, B1-B2, One of the most frequent components (27) has very low sum of weights\n",
    "* Ku_EL_09, B7-B8, One of the most frequent components (19) has very low sum of weights, as well as one less frequent component (15)\n",
    "* Pr_An_04, B1-B2, The most frequent components (25, 28, 0, 9) have low sum of weights\n",
    "* Ru_Ek_07, B7-B8, The most frequent component (7) has low sum of weights\n",
    "* Se_Tu_03, B1-B2, The most frequent component (25) has low sum of weights\n",
    "* Se_Tu_03, B7-B8, The most frequent component (25) has low sum of weights\n",
    "* Te_Ali_11, B1-B2, The most frequent components (24, 22) have low sum of weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = read_pkl(os.path.join(subject_info_path, os.listdir(subject_info_path)[0]))\n",
    "info.pick_channels(\n",
    "    list(\n",
    "        filter(\n",
    "            lambda ch_name: (ch_name[-1] == '2' or ch_name[-1] == '3') and 'meg' in ch_name.lower(),\n",
    "            info['ch_names']\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "draw_sp(16, waveforms, temporal_parameters, spatial_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylustrator\n",
    "\n",
    "def compare(x1 :np.array, x2: np.array) -> float:\n",
    "    return (x1@x2)/(np.linalg.norm(x1)*np.linalg.norm(x2))\n",
    "\n",
    "subject_info_path = '../Source/Subjects/Az_Mar_05/Info'\n",
    "info = read_pkl(os.path.join(subject_info_path, os.listdir(subject_info_path)[0]))\n",
    "info.pick_channels(\n",
    "    list(\n",
    "        filter(\n",
    "            lambda ch_name: (ch_name[-1] == '2' or ch_name[-1] == '3') and 'meg' in ch_name.lower(),\n",
    "            info['ch_names']\n",
    "        )\n",
    "    )\n",
    ")\n",
    "path1 = '../Source/Subjects/Az_Mar_05/LFCNN_train_B1-B3/Parameters'\n",
    "path2 = '../Source/Subjects/Az_Mar_05/LFCNN_train_B10-B12/Parameters'\n",
    "temporal_parameters1 = read_pkl(os.path.join(path1, 'RM&RI_vs_LM&LI_temporal.pkl'))\n",
    "temporal_parameters2 = read_pkl(os.path.join(path2, 'RM&RI_vs_LM&LI_temporal.pkl'))\n",
    "spatial_parameters1 = read_pkl(os.path.join(path1, 'RM&RI_vs_LM&LI_spatial.pkl'))\n",
    "spatial_parameters2 = read_pkl(os.path.join(path2, 'RM&RI_vs_LM&LI_spatial.pkl'))\n",
    "waveforms1 = read_pkl(os.path.join(path1, f'RM&RI_vs_LM&LI_waveforms.pkl'))\n",
    "waveforms2 = read_pkl(os.path.join(path1, f'RM&RI_vs_LM&LI_waveforms.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = spatial_parameters1.patterns\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "\n",
    "indices1 = list(\n",
    "    map(\n",
    "        lambda item: item[0],\n",
    "        sorted(\n",
    "            enumerate(spatial_parameters1.patterns.T),\n",
    "            key=lambda item: np.abs(item[1]).sum(0),\n",
    "            reverse=True\n",
    "        )\n",
    "    )\n",
    ")\n",
    "best_pattern_index = indices1[0]\n",
    "best_pattern = patterns[:, best_pattern_index]\n",
    "\n",
    "indices2 = list(\n",
    "    map(\n",
    "        lambda item: item[0],\n",
    "        sorted(\n",
    "            enumerate(spatial_parameters2.patterns.T),\n",
    "            key=lambda item: compare(best_pattern, item[1]),\n",
    "            reverse=True\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "path1 = '/home/user/Downloads/Pics/pictemp1.png'\n",
    "path2 = '/home/user/Downloads/Pics/pictemp2.png'\n",
    "path3 = '/home/user/Downloads/Pics/pictempcon.png'\n",
    "%matplotlib qt\n",
    "draw_sp(indices1[0], waveforms1, temporal_parameters1, spatial_parameters1, info, suptitle='B1-B3')\n",
    "\n",
    "w, h = 12, 15\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(w, h)\n",
    "plt.savefig(path1)\n",
    "plt.close()\n",
    "\n",
    "draw_sp(indices2[0], waveforms2, temporal_parameters2, spatial_parameters2, info, suptitle='B10-B12')\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(w, h)\n",
    "plt.savefig(path2)\n",
    "plt.close()\n",
    "\n",
    "pylustrator.load(path1)\n",
    "pylustrator.load(path2, offset=[.75, 0])\n",
    "plt.savefig(path3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as it\n",
    "import matplotlib.patches as mpatches\n",
    "import pandas as pd\n",
    "span = 1\n",
    "%matplotlib inline\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "\n",
    "def adjust_fig(fig):\n",
    "    fig['cmeans'].set_color('red')\n",
    "    fig['cbars'].set_edgecolor('gray')\n",
    "    fig['cbars'].set_alpha(.5)\n",
    "    fig['cbars'].set_linewidth(.8)\n",
    "    fig['cmaxes'].set_color('#042164')\n",
    "    fig['cmins'].set_color('#042164')\n",
    "    fig['cquantiles'].set_color('#EE550E')\n",
    "\n",
    "for classification, title in zip(\n",
    "    [\n",
    "        'RM_vs_RI_vs_LM_vs_LI',\n",
    "        'RM&RI_vs_LM&LI',\n",
    "        'LM_vs_LI',\n",
    "        'RM_vs_RI'\n",
    "    ], [\n",
    "        '4 classes',\n",
    "        'Left vs Right',\n",
    "        'Within Left',\n",
    "        'Within Right'\n",
    "    ]\n",
    "):\n",
    "    plt.ylim((0.4, 1.25))\n",
    "    plt.yticks(\n",
    "        [.5, .6, .7, .8, .9, 1.],\n",
    "    )\n",
    "    plt.grid(True, axis='x', linewidth=100, alpha=.1)\n",
    "\n",
    "    order = list(it.product(['B1-B3', 'B10-B12'], repeat=2))\n",
    "    order[-1], order[-2] = order[-2], order[-1]\n",
    "    for i, ((seq1, seq2), color) in enumerate(zip(order, ['blue', 'red', 'orange', 'green'])):\n",
    "        path = f'/home/user/Downloads/perf_tables_fullrange/{classification}_train_{seq1}_test_{seq2}_sep.csv'\n",
    "        df = pd.read_csv(path, index_col = 0)\n",
    "        subjects = set(df.index)\n",
    "        data = np.array([df.test_acc[f'{subject}'].to_numpy() for subject in subjects])\n",
    "        data = np.append(data, [data.mean(0)], axis = 0)\n",
    "        subjects = list(subjects) + ['Average']\n",
    "        plane = np.array([i for i in range(len(subjects)*4) if not (i)%4])\n",
    "        fig = plt.violinplot(\n",
    "            data.T, plane + i + np.array(range(len(plane)))*span,\n",
    "            showmeans=True,\n",
    "            quantiles = [[0.25, 0.75] for _ in subjects]\n",
    "        )\n",
    "        for i in range(len(subjects)):\n",
    "            fig['bodies'][i].set_facecolor(color)\n",
    "        adjust_fig(fig)\n",
    "\n",
    "    _ = plt.xticks(\n",
    "        plane + 1.5 + np.array(range(len(plane)))*span,\n",
    "        subjects,\n",
    "        rotation=30\n",
    "    )\n",
    "\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(18.5, 10.5)\n",
    "    b = mpatches.Patch(color='blue', label='B1-B3 | B1-B3', alpha=.4)\n",
    "    r = mpatches.Patch(color='red', label='B1-B3 | B10-B12', alpha=.4)\n",
    "    o = mpatches.Patch(color='orange', label='B10-B12 | B10-B12', alpha=.4)\n",
    "    g = mpatches.Patch(color='green', label='B10-B12 | B1-B3', alpha=.4)\n",
    "    plt.legend(handles=[b, r, o, g])\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    # plt.savefig(f'/home/user/Downloads/Pics/{classification}.png')\n",
    "    # plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "25b6c1d617e3cb25e4067864bcd46322e1b7da41afdae0cf7c23b941b0b9b767"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
