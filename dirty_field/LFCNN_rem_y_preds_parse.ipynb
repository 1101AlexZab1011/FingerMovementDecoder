{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "current_dir = os.path.dirname(os.path.abspath('./'))\n",
    "if not current_dir in sys.path:\n",
    "    sys.path.append(current_dir)\n",
    "from combiners import EpochsCombiner\n",
    "from typing import *\n",
    "import mne\n",
    "import tensorflow as tf\n",
    "import mneflow as mf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from utils.data_management import dict2str\n",
    "from lfcnn_vis import plot_patterns\n",
    "from LFCNN_decoder import SpatialParameters, TemporalParameters, ComponentsOrder, Predictions\n",
    "import pickle\n",
    "from utils.machine_learning import one_hot_decoder\n",
    "import sklearn.metrics as sm\n",
    "from utils.machine_learning.confusion import ConfusionEstimator\n",
    "import scipy as sp\n",
    "import itertools as it\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.lines as mlines\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from collections import namedtuple\n",
    "import matplotlib.colors as mc\n",
    "\n",
    "def read_pkl(path: str) -> Any:\n",
    "    with open(\n",
    "            path,\n",
    "            'rb'\n",
    "        ) as file:\n",
    "        content = pickle.load(\n",
    "            file\n",
    "        )\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6960897477187333\n",
      "0.7250858165372503\n",
      "0.69343843076526\n",
      "0.847382132383333\n",
      "0.7089745948538733\n",
      "0.7634265758358783\n",
      "0.8270903123585336\n",
      "0.6895991021324355\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.661231856953922"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root = '../Source/Subjects'\n",
    "scores = 0\n",
    "case = 'lm_vs_li'\n",
    "i = 0\n",
    "for subj_name in os.listdir(root):\n",
    "    i += 1\n",
    "    \n",
    "    if subj_name == 'Pse_Udo':\n",
    "        continue\n",
    "    \n",
    "    tf_path = os.path.join(root, subj_name, 'TF_planes', 'BB1-BB8', 'RespCor')\n",
    "    tf_file = os.path.join(tf_path, f'{case}.pkl')\n",
    "    scorer = read_pkl(tf_file)\n",
    "    print(scorer.tf_scores.mean(0).max())\n",
    "    scores += scorer.tf_scores.mean(0).max()\n",
    "scores/i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils.console.colored import warn\n",
    "\n",
    "class PredictionsParser(object):\n",
    "    def __init__(\n",
    "        self,\n",
    "        y_true: Union[list[int], np.ndarray],\n",
    "        y_pred: Union[list[int], np.ndarray],\n",
    "        class_names: Optional[Union[str, list[str]]] = None\n",
    "    ):\n",
    "        \n",
    "        y_true = self.__check_numpy(y_true)\n",
    "        y_pred = self.__check_numpy(y_pred)\n",
    "        \n",
    "        if y_true.shape != y_pred.shape:\n",
    "            raise ValueError('Predictions and actual values are inconsistent. Actual values shape: {y_true.shape}, predictions shape: {y_pred.shape}')\n",
    "        \n",
    "        if len(y_true.shape) != 1:\n",
    "            y_true = one_hot_decoder(y_true)\n",
    "            y_pred = one_hot_decoder(y_pred)\n",
    "        \n",
    "        self._y_true = y_true\n",
    "        self._y_pred = y_pred\n",
    "        \n",
    "        self._accuracy = sm.accuracy_score(y_true, y_pred)\n",
    "        \n",
    "        classes_true = np.unique(self._y_true)\n",
    "        classes_pred = np.unique(self._y_pred)\n",
    "        \n",
    "        if np.any(classes_true != classes_pred):\n",
    "            warn(f'Warning: Classes are inconsistent.\\n\\tActual classes: {classes_true}\\n\\tPredicted classes: {classes_pred}.\\nTake actual classes')\n",
    "            \n",
    "        del classes_pred\n",
    "        \n",
    "        self._classes = classes_true\n",
    "        self._n_classes = len(classes_true)\n",
    "        \n",
    "        if class_names is not None:\n",
    "            \n",
    "            if isinstance(class_names, str):\n",
    "                class_names = class_names.split(' ')\n",
    "            \n",
    "            if len(class_names) != self.n_classes:\n",
    "                raise ValueError(f'Class names and classes are inconsistent: number of classes is {self.n_classes}, but {len(class_names)} names of classes were given')\n",
    "        else:\n",
    "            class_names = [f'Class {i}' for i in range(self.n_classes)]\n",
    "        \n",
    "        self._class_names = class_names\n",
    "        \n",
    "        self._confusion = pd.DataFrame(\n",
    "            sm.confusion_matrix(self.y_true, self.y_pred),\n",
    "            index = [f'Actual {class_name}' for class_name in self.class_names],\n",
    "            columns = [f'Predicted {class_name}' for class_name in self.class_names]\n",
    "        )\n",
    "    \n",
    "    @staticmethod\n",
    "    def __check_numpy(arr: Union[list, tuple, np.ndarray]):\n",
    "        if isinstance(arr, np.ndarray):\n",
    "            return arr\n",
    "        elif not isinstance(arr, np.ndarray) and isinstance(arr, (list, tuple)):\n",
    "            return np.array(arr)\n",
    "        else:\n",
    "            raise ValueError(f'The given argument must be either a np.ndarray or a list, but {type(arr)} was given')\n",
    "        \n",
    "    @property\n",
    "    def y_true(self):\n",
    "        return self._y_true\n",
    "    @y_true.setter\n",
    "    def y_true(self, value):\n",
    "        raise AttributeError('Impossible to set y_true directly')\n",
    "    \n",
    "    @property\n",
    "    def y_pred(self):\n",
    "        return self._y_pred\n",
    "    @y_pred.setter\n",
    "    def y_pred(self, value):\n",
    "        raise AttributeError('Impossible to set y_pred directly')\n",
    "    \n",
    "    @property\n",
    "    def accuracy(self):\n",
    "        return self._accuracy\n",
    "    @accuracy.setter\n",
    "    def accuracy(self, value):\n",
    "        raise AttributeError('Impossible to set accuracy directly')\n",
    "    \n",
    "    @property\n",
    "    def classes(self):\n",
    "        return self._classes\n",
    "    @classes.setter\n",
    "    def classes(self, value):\n",
    "        raise AttributeError('Impossible to set classes directly')\n",
    "    \n",
    "    @property\n",
    "    def n_classes(self):\n",
    "        return self._n_classes\n",
    "    @n_classes.setter\n",
    "    def n_classes(self, value):\n",
    "        raise AttributeError('Impossible to set number of classes directly')\n",
    "    \n",
    "    @property\n",
    "    def class_names(self):\n",
    "        return self._class_names\n",
    "    @class_names.setter\n",
    "    def class_names(self, value):\n",
    "        raise AttributeError('Impossible to set names for classes directly')\n",
    "    \n",
    "    @property\n",
    "    def confusion(self):\n",
    "        return self._confusion\n",
    "    @confusion.setter\n",
    "    def confusion(self, value):\n",
    "        raise AttributeError('Impossible to set confusion matrix directly')\n",
    "    \n",
    "    def summary(self, *args: str):\n",
    "        df = self.confusion.copy()\n",
    "        summary = pd.DataFrame(columns = self.class_names)\n",
    "        summary.loc['Total'] = [df[column].sum() for column in df.columns]\n",
    "        summary.loc['Accuracy'] = [None for _ in range(self.n_classes)]\n",
    "        summary.loc['Specificity'] = [None for _ in range(self.n_classes)]\n",
    "        summary.loc['Sensitivity'] = [None for _ in range(self.n_classes)]\n",
    "        \n",
    "        ec = self.estimate_confusion()\n",
    "        \n",
    "        args = list(args)\n",
    "        for i, arg in enumerate(args):\n",
    "            if not isinstance(arg, tuple):\n",
    "                args[i] = arg, arg\n",
    "        \n",
    "        for arg_value, arg_name in args:\n",
    "            if hasattr(ec[self.class_names[0]], arg_value):\n",
    "                summary.loc[arg_name] = [None for _ in range(self.n_classes)]\n",
    "            else:\n",
    "                warn(f'WARNING: the {arg_value} property was not found in the confusion evaluator, so it was ignored')\n",
    "                args.remove((arg_value, arg_name))\n",
    "            \n",
    "        \n",
    "        for i, class_name in enumerate(self.class_names):\n",
    "            summary[class_name].loc['Accuracy'] = ec[class_name].acc\n",
    "            summary[class_name].loc['Specificity'] = ec[class_name].spec\n",
    "            summary[class_name].loc['Sensitivity'] = ec[class_name].sens\n",
    "            \n",
    "            for arg_value, arg_name in args:\n",
    "                summary[class_name].loc[arg_name] = getattr(ec[class_name], arg_value)\n",
    "            \n",
    "        return summary\n",
    "    \n",
    "    def estimate_confusion(self):\n",
    "        \n",
    "        return {\n",
    "            class_name: ConfusionEstimator(\n",
    "                # tp, tn, fp, fn\n",
    "                self.confusion[self.confusion.columns[i]][self.confusion.index[i]],\n",
    "                self.confusion[\n",
    "                    list(self.confusion.columns[:i]) + list(self.confusion.columns[i+1:])\n",
    "                    ].loc[\n",
    "                        list(self.confusion.index[:i]) + list(self.confusion.index[i+1:])\n",
    "                ].sum().sum(),\n",
    "                self.confusion[self.confusion.columns[i]].loc[\n",
    "                    list(self.confusion.index[:i]) + list(self.confusion.index[i+1:])\n",
    "                ].sum(),\n",
    "                self.confusion[\n",
    "                    list(self.confusion.columns[:i]) + list(self.confusion.columns[i+1:])\n",
    "                ].loc[self.confusion.index[i]].sum()\n",
    "            )\n",
    "            for i, class_name in enumerate(self.class_names)\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28617/3937441739.py:50: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  sumdf.to_excel(os.path.join(classification_tables_path, f'{subject_name}_{classification}_summary.xls'))\n",
      "/tmp/ipykernel_28617/3937441739.py:51: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  confdf.to_excel(os.path.join(classification_tables_path, f'{subject_name}_{classification}_confusion.xls'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Source/perf_tables/Pse_Udo/Pse_Udo_RM&RI_vs_LM&LI_summary.xls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28617/3937441739.py:50: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  sumdf.to_excel(os.path.join(classification_tables_path, f'{subject_name}_{classification}_summary.xls'))\n",
      "/tmp/ipykernel_28617/3937441739.py:51: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  confdf.to_excel(os.path.join(classification_tables_path, f'{subject_name}_{classification}_confusion.xls'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Source/perf_tables/Az_Mar/Az_Mar_RM&RI_vs_LM&LI_summary.xls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28617/3937441739.py:50: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  sumdf.to_excel(os.path.join(classification_tables_path, f'{subject_name}_{classification}_summary.xls'))\n",
      "/tmp/ipykernel_28617/3937441739.py:51: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  confdf.to_excel(os.path.join(classification_tables_path, f'{subject_name}_{classification}_confusion.xls'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Source/perf_tables/Fe_To/Fe_To_RM&RI_vs_LM&LI_summary.xls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/Projects/FingerMovementDecoder/utils/machine_learning/confusion.py:406: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self._lr_plus = self.tpr / self.fpr\n",
      "/home/user/Projects/FingerMovementDecoder/utils/machine_learning/confusion.py:408: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self._dor = self.lr_plus / self.lr_minus\n",
      "/home/user/Projects/FingerMovementDecoder/utils/machine_learning/confusion.py:406: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self._lr_plus = self.tpr / self.fpr\n",
      "/home/user/Projects/FingerMovementDecoder/utils/machine_learning/confusion.py:408: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self._dor = self.lr_plus / self.lr_minus\n",
      "/home/user/Projects/FingerMovementDecoder/utils/machine_learning/confusion.py:406: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self._lr_plus = self.tpr / self.fpr\n",
      "/home/user/Projects/FingerMovementDecoder/utils/machine_learning/confusion.py:408: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self._dor = self.lr_plus / self.lr_minus\n",
      "/tmp/ipykernel_28617/3937441739.py:50: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  sumdf.to_excel(os.path.join(classification_tables_path, f'{subject_name}_{classification}_summary.xls'))\n",
      "/tmp/ipykernel_28617/3937441739.py:51: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  confdf.to_excel(os.path.join(classification_tables_path, f'{subject_name}_{classification}_confusion.xls'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Source/perf_tables/Ga_Fed/Ga_Fed_RM&RI_vs_LM&LI_summary.xls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28617/3937441739.py:50: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  sumdf.to_excel(os.path.join(classification_tables_path, f'{subject_name}_{classification}_summary.xls'))\n",
      "/tmp/ipykernel_28617/3937441739.py:51: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  confdf.to_excel(os.path.join(classification_tables_path, f'{subject_name}_{classification}_confusion.xls'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Source/perf_tables/Ku_EL/Ku_EL_RM&RI_vs_LM&LI_summary.xls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28617/3937441739.py:50: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  sumdf.to_excel(os.path.join(classification_tables_path, f'{subject_name}_{classification}_summary.xls'))\n",
      "/tmp/ipykernel_28617/3937441739.py:51: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  confdf.to_excel(os.path.join(classification_tables_path, f'{subject_name}_{classification}_confusion.xls'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Source/perf_tables/Pr_An/Pr_An_RM&RI_vs_LM&LI_summary.xls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28617/3937441739.py:50: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  sumdf.to_excel(os.path.join(classification_tables_path, f'{subject_name}_{classification}_summary.xls'))\n",
      "/tmp/ipykernel_28617/3937441739.py:51: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  confdf.to_excel(os.path.join(classification_tables_path, f'{subject_name}_{classification}_confusion.xls'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Source/perf_tables/Ru_Ek/Ru_Ek_RM&RI_vs_LM&LI_summary.xls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/Projects/FingerMovementDecoder/utils/machine_learning/confusion.py:406: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self._lr_plus = self.tpr / self.fpr\n",
      "/home/user/Projects/FingerMovementDecoder/utils/machine_learning/confusion.py:408: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self._dor = self.lr_plus / self.lr_minus\n",
      "/home/user/Projects/FingerMovementDecoder/utils/machine_learning/confusion.py:406: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self._lr_plus = self.tpr / self.fpr\n",
      "/home/user/Projects/FingerMovementDecoder/utils/machine_learning/confusion.py:408: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self._dor = self.lr_plus / self.lr_minus\n",
      "/home/user/Projects/FingerMovementDecoder/utils/machine_learning/confusion.py:406: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self._lr_plus = self.tpr / self.fpr\n",
      "/home/user/Projects/FingerMovementDecoder/utils/machine_learning/confusion.py:408: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self._dor = self.lr_plus / self.lr_minus\n",
      "/tmp/ipykernel_28617/3937441739.py:50: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  sumdf.to_excel(os.path.join(classification_tables_path, f'{subject_name}_{classification}_summary.xls'))\n",
      "/tmp/ipykernel_28617/3937441739.py:51: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  confdf.to_excel(os.path.join(classification_tables_path, f'{subject_name}_{classification}_confusion.xls'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Source/perf_tables/Se_Tu/Se_Tu_RM&RI_vs_LM&LI_summary.xls\n",
      "../Source/perf_tables/Te_Ali/Te_Ali_RM&RI_vs_LM&LI_summary.xls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28617/3937441739.py:50: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  sumdf.to_excel(os.path.join(classification_tables_path, f'{subject_name}_{classification}_summary.xls'))\n",
      "/tmp/ipykernel_28617/3937441739.py:51: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  confdf.to_excel(os.path.join(classification_tables_path, f'{subject_name}_{classification}_confusion.xls'))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "perf_tables_path = '../Source/perf_tables/'\n",
    "from utils.storage_management import check_path\n",
    "check_path(perf_tables_path)\n",
    "\n",
    "for subject_name in os.listdir(f'../Source/Subjects/'):\n",
    "    \n",
    "    subject_perf_tables_path = os.path.join(perf_tables_path, subject_name)\n",
    "    check_path(subject_perf_tables_path)\n",
    "\n",
    "    path = f'../Source/Subjects/{subject_name}/LFCNN'\n",
    "\n",
    "    classification_tables_path = os.path.join(subject_perf_tables_path)\n",
    "    check_path(classification_tables_path)\n",
    "    \n",
    "    sumdf = pd.DataFrame()\n",
    "    confdf = pd.DataFrame()\n",
    "    for classification in [\n",
    "        'RM_vs_RI_vs_LM_vs_LI',\n",
    "        'RM_vs_RI',\n",
    "        'LM_vs_LI',\n",
    "        'RM&RI_vs_LM&LI'\n",
    "    ]:\n",
    "        file_name = f'{classification}_pred.pkl'\n",
    "        class_names = classification.split('_vs_')\n",
    "\n",
    "        try:\n",
    "            predictions = read_pkl(\n",
    "                os.path.join(path, 'Predictions', file_name)\n",
    "            )\n",
    "        except FileNotFoundError:\n",
    "            warn(f'File does not exist: {os.path.join(path, \"Predictions\", file_name)}')\n",
    "            continue\n",
    "        pp = PredictionsParser(predictions.y_true, predictions.y_p, class_names)\n",
    "        \n",
    "        sumdf = pd.concat([\n",
    "                sumdf,\n",
    "                pp.summary(),\n",
    "                pd.DataFrame([None for _ in range(pp.summary().shape[0])], index=pp.summary().index),\n",
    "            ],\n",
    "            axis=1\n",
    "        )\n",
    "        confdf = pd.concat([\n",
    "                confdf,\n",
    "                pp.confusion,\n",
    "                # pd.DataFrame([None for _ in range(pp.confusion.shape[0])], index=pp.confusion.index),\n",
    "                pd.DataFrame(list(confdf.index), index=confdf.index),\n",
    "            ],\n",
    "            axis=1\n",
    "        )\n",
    "    sumdf.to_excel(os.path.join(classification_tables_path, f'{subject_name}_{classification}_summary.xls'))\n",
    "    confdf.to_excel(os.path.join(classification_tables_path, f'{subject_name}_{classification}_confusion.xls'))\n",
    "    print(os.path.join(classification_tables_path, f'{subject_name}_{classification}_summary.xls'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'warn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/user/Projects/FingerMovementDecoder/dirty_field/LFCNN_rem_y_preds_parse.ipynb Cell 5'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/user/Projects/FingerMovementDecoder/dirty_field/LFCNN_rem_y_preds_parse.ipynb#ch0000004?line=27'>28</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/user/Projects/FingerMovementDecoder/dirty_field/LFCNN_rem_y_preds_parse.ipynb#ch0000004?line=28'>29</a>\u001b[0m     predictions \u001b[39m=\u001b[39m read_pkl(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/user/Projects/FingerMovementDecoder/dirty_field/LFCNN_rem_y_preds_parse.ipynb#ch0000004?line=29'>30</a>\u001b[0m         os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(path, \u001b[39m'\u001b[39;49m\u001b[39mPredictions\u001b[39;49m\u001b[39m'\u001b[39;49m, file_name)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/user/Projects/FingerMovementDecoder/dirty_field/LFCNN_rem_y_preds_parse.ipynb#ch0000004?line=30'>31</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/user/Projects/FingerMovementDecoder/dirty_field/LFCNN_rem_y_preds_parse.ipynb#ch0000004?line=31'>32</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m:\n",
      "\u001b[1;32m/home/user/Projects/FingerMovementDecoder/dirty_field/LFCNN_rem_y_preds_parse.ipynb Cell 1'\u001b[0m in \u001b[0;36mread_pkl\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/user/Projects/FingerMovementDecoder/dirty_field/LFCNN_rem_y_preds_parse.ipynb#ch0000000?line=28'>29</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread_pkl\u001b[39m(path: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/user/Projects/FingerMovementDecoder/dirty_field/LFCNN_rem_y_preds_parse.ipynb#ch0000000?line=29'>30</a>\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/user/Projects/FingerMovementDecoder/dirty_field/LFCNN_rem_y_preds_parse.ipynb#ch0000000?line=30'>31</a>\u001b[0m             path,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/user/Projects/FingerMovementDecoder/dirty_field/LFCNN_rem_y_preds_parse.ipynb#ch0000000?line=31'>32</a>\u001b[0m             \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/user/Projects/FingerMovementDecoder/dirty_field/LFCNN_rem_y_preds_parse.ipynb#ch0000000?line=32'>33</a>\u001b[0m         ) \u001b[39mas\u001b[39;00m file:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/user/Projects/FingerMovementDecoder/dirty_field/LFCNN_rem_y_preds_parse.ipynb#ch0000000?line=33'>34</a>\u001b[0m         content \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/user/Projects/FingerMovementDecoder/dirty_field/LFCNN_rem_y_preds_parse.ipynb#ch0000000?line=34'>35</a>\u001b[0m             file\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/user/Projects/FingerMovementDecoder/dirty_field/LFCNN_rem_y_preds_parse.ipynb#ch0000000?line=35'>36</a>\u001b[0m         )\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../Source/Subjects/Pse_Udo/LFRNN/Predictions/RM_vs_RI_vs_LM_vs_LI_LFCNN_pred.pkl'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/user/Projects/FingerMovementDecoder/dirty_field/LFCNN_rem_y_preds_parse.ipynb Cell 5'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/user/Projects/FingerMovementDecoder/dirty_field/LFCNN_rem_y_preds_parse.ipynb#ch0000004?line=28'>29</a>\u001b[0m     predictions \u001b[39m=\u001b[39m read_pkl(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/user/Projects/FingerMovementDecoder/dirty_field/LFCNN_rem_y_preds_parse.ipynb#ch0000004?line=29'>30</a>\u001b[0m         os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(path, \u001b[39m'\u001b[39m\u001b[39mPredictions\u001b[39m\u001b[39m'\u001b[39m, file_name)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/user/Projects/FingerMovementDecoder/dirty_field/LFCNN_rem_y_preds_parse.ipynb#ch0000004?line=30'>31</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/user/Projects/FingerMovementDecoder/dirty_field/LFCNN_rem_y_preds_parse.ipynb#ch0000004?line=31'>32</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/user/Projects/FingerMovementDecoder/dirty_field/LFCNN_rem_y_preds_parse.ipynb#ch0000004?line=32'>33</a>\u001b[0m     warn(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mFile does not exist: \u001b[39m\u001b[39m{\u001b[39;00mos\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(path, \u001b[39m\"\u001b[39m\u001b[39mPredictions\u001b[39m\u001b[39m\"\u001b[39m, file_name)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/user/Projects/FingerMovementDecoder/dirty_field/LFCNN_rem_y_preds_parse.ipynb#ch0000004?line=33'>34</a>\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/user/Projects/FingerMovementDecoder/dirty_field/LFCNN_rem_y_preds_parse.ipynb#ch0000004?line=34'>35</a>\u001b[0m pp \u001b[39m=\u001b[39m PredictionsParser(predictions\u001b[39m.\u001b[39my_true, predictions\u001b[39m.\u001b[39my_p, class_names)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'warn' is not defined"
     ]
    }
   ],
   "source": [
    "from utils.storage_management import check_path\n",
    "perf_tables_path = '../Source/perf_tables/LFRNN'\n",
    "check_path(perf_tables_path)\n",
    "from utils.storage_management import check_path\n",
    "postfix = 'LFCNN'\n",
    "group_tables_path = os.path.join(perf_tables_path, 'Group')\n",
    "check_path(group_tables_path)\n",
    "classification_tables_path = os.path.join(group_tables_path, postfix)\n",
    "check_path(perf_tables_path, group_tables_path, classification_tables_path)\n",
    "\n",
    "sumdf = pd.DataFrame()\n",
    "confdf = pd.DataFrame()\n",
    "for classification in [\n",
    "        'RM_vs_RI_vs_LM_vs_LI',\n",
    "        'RM_vs_RI',\n",
    "        'LM_vs_LI',\n",
    "        'RM&RI_vs_LM&LI'\n",
    "    ]:\n",
    "    conf = list()\n",
    "    summary = list()\n",
    "    for subject_name in os.listdir(f'../Source/Subjects/'):\n",
    "        path = f'../Source/Subjects/{subject_name}/LFRNN'\n",
    "        check_path(path)\n",
    "        \n",
    "        file_name = f'{classification}_{postfix}_pred.pkl'\n",
    "        class_names = classification.split('_vs_')\n",
    "\n",
    "        try:\n",
    "            predictions = read_pkl(\n",
    "                os.path.join(path, 'Predictions', file_name)\n",
    "            )\n",
    "        except FileNotFoundError:\n",
    "            warn(f'File does not exist: {os.path.join(path, \"Predictions\", file_name)}')\n",
    "            continue\n",
    "        pp = PredictionsParser(predictions.y_true, predictions.y_p, class_names)\n",
    "        conf.append(pp.confusion)\n",
    "        summary.append(pp.summary())\n",
    "    \n",
    "    index, columns = summary[0].index, summary[0].columns\n",
    "    data = np.array([c.to_numpy() for c in summary]).mean(0)\n",
    "    local_summary = pd.DataFrame(data, index=index, columns=columns)\n",
    "    sumdf = pd.concat([\n",
    "        sumdf,\n",
    "        local_summary,\n",
    "        pd.DataFrame([None for _ in range(local_summary.shape[0])], index=local_summary.index),\n",
    "    ], axis=1)\n",
    "    \n",
    "    index, columns = conf[0].index, conf[0].columns\n",
    "    data = np.array([s.to_numpy() for s in conf]).mean(0)\n",
    "    local_conf = pd.DataFrame(data, index=index, columns=columns)\n",
    "    confdf = pd.concat([\n",
    "        confdf,\n",
    "        local_conf,\n",
    "        pd.DataFrame(list(local_conf.index), index=local_conf.index),\n",
    "    ], axis=1)\n",
    "\n",
    "sumdf.to_excel(\n",
    "    os.path.join(classification_tables_path, f'group_{classification}_summary.xls')\n",
    ")\n",
    "confdf.to_excel(os.path.join(classification_tables_path, f'group_{classification}_confusion.xls'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ga_Fed_06\n",
      "Total accuracy:  0.55\n",
      "                LM     LI     RM    RI\n",
      "Total        16.00  12.00  16.00  9.00\n",
      "Accuracy      0.77   0.77   0.77  0.77\n",
      "Specificity   0.84   0.89   0.80  0.86\n",
      "Sensitivity   0.62   0.50   0.67  0.33\n",
      "           Predicted LM  Predicted LI  Predicted RM  Predicted RI\n",
      "Actual LM            10             4             1             1\n",
      "Actual LI             6             8             1             1\n",
      "Actual RM             0             0             8             4\n",
      "Actual RI             0             0             6             3\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Fe_To_08\n",
      "Total accuracy:  0.57\n",
      "                LM     LI     RM    RI\n",
      "Total        12.00  18.00  16.00  8.00\n",
      "Accuracy      0.78   0.76   0.80  0.81\n",
      "Specificity   0.92   0.78   0.81  0.93\n",
      "Sensitivity   0.50   0.69   0.73  0.42\n",
      "           Predicted LM  Predicted LI  Predicted RM  Predicted RI\n",
      "Actual LM             9             7             2             0\n",
      "Actual LI             2             9             1             1\n",
      "Actual RM             1             0             8             2\n",
      "Actual RI             0             2             5             5\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Az_Mar_05\n",
      "Total accuracy:  0.29\n",
      "                LM     LI     RM     RI\n",
      "Total        11.00  14.00  16.00  11.00\n",
      "Accuracy      0.60   0.60   0.71   0.67\n",
      "Specificity   0.76   0.70   0.78   0.82\n",
      "Sensitivity   0.14   0.11   0.53   0.29\n",
      "           Predicted LM  Predicted LI  Predicted RM  Predicted RI\n",
      "Actual LM             2             9             1             2\n",
      "Actual LI             2             1             3             3\n",
      "Actual RM             2             3             8             2\n",
      "Actual RI             5             1             4             4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ku_EL_09\n",
      "Total accuracy:  0.62\n",
      "                LM     LI    RM     RI\n",
      "Total        17.00  13.00  9.00  14.00\n",
      "Accuracy      0.89   0.79  0.74   0.83\n",
      "Specificity   0.89   0.84  0.94   0.84\n",
      "Sensitivity   0.87   0.60  0.37   0.78\n",
      "           Predicted LM  Predicted LI  Predicted RM  Predicted RI\n",
      "Actual LM            13             2             0             0\n",
      "Actual LI             3             6             0             1\n",
      "Actual RM             1             5             7             6\n",
      "Actual RI             0             0             2             7\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001b[93mWarning: Classes are inconsistent.\n",
      "\tActual classes: [0 1 2 3]\n",
      "\tPredicted classes: [0 1 2].\n",
      "Take actual classes\u001b[0m\n",
      "Pr_An_04\n",
      "Total accuracy:  0.49\n",
      "                LM     LI     RM    RI\n",
      "Total        13.00  17.00  23.00  0.00\n",
      "Accuracy      0.72   0.75   0.66  0.85\n",
      "Specificity   0.84   0.78   0.67  1.00\n",
      "Sensitivity   0.44   0.67   0.65  0.00\n",
      "           Predicted LM  Predicted LI  Predicted RM  Predicted RI\n",
      "Actual LM             7             5             4             0\n",
      "Actual LI             2             8             2             0\n",
      "Actual RM             3             3            11             0\n",
      "Actual RI             1             1             6             0\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ru_Ek_07\n",
      "Total accuracy:  0.62\n",
      "               LM     LI     RM     RI\n",
      "Total        9.00  10.00  20.00  13.00\n",
      "Accuracy     0.92   0.81   0.77   0.73\n",
      "Specificity  0.93   0.90   0.81   0.82\n",
      "Sensitivity  0.86   0.50   0.70   0.46\n",
      "           Predicted LM  Predicted LI  Predicted RM  Predicted RI\n",
      "Actual LM             6             1             0             0\n",
      "Actual LI             3             6             1             2\n",
      "Actual RM             0             1            14             5\n",
      "Actual RI             0             2             5             6\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Se_Tu_03\n",
      "Total accuracy:  0.50\n",
      "               LM     LI     RM    RI\n",
      "Total        5.00  21.00  22.00  8.00\n",
      "Accuracy     0.84   0.77   0.70  0.70\n",
      "Specificity  0.94   0.78   0.72  0.88\n",
      "Sensitivity  0.25   0.75   0.65  0.20\n",
      "           Predicted LM  Predicted LI  Predicted RM  Predicted RI\n",
      "Actual LM             2             6             0             0\n",
      "Actual LI             2            12             1             1\n",
      "Actual RM             1             1            11             4\n",
      "Actual RI             0             2            10             3\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Te_Ali_11\n",
      "Total accuracy:  0.45\n",
      "                LM    LI     RM     RI\n",
      "Total        12.00  8.00  22.00  11.00\n",
      "Accuracy      0.74  0.74   0.72   0.72\n",
      "Specificity   0.85  0.86   0.70   0.86\n",
      "Sensitivity   0.43  0.20   0.77   0.38\n",
      "           Predicted LM  Predicted LI  Predicted RM  Predicted RI\n",
      "Actual LM             6             4             3             1\n",
      "Actual LI             3             2             2             3\n",
      "Actual RM             0             2            10             1\n",
      "Actual RI             3             0             7             6\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19962/2523103007.py:30: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  if np.any(classes_true != classes_pred):\n",
      "/home/user/Projects/FingerMovementDecoder/utils/machine_learning/confusion.py:255: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  self._ppv = self.tp / (self.tp + self.fp)\n",
      "/home/user/Projects/FingerMovementDecoder/utils/machine_learning/confusion.py:263: RuntimeWarning: invalid value encountered in true_divide\n",
      "  self._mcc = (self.tp * self.tn - self.fp * self.fn) / \\\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "subjects_path = '../Source/Subjects/'\n",
    "file_name = 'LM_vs_LI_vs_RM_vs_RI_B1-B8_pred.pkl'\n",
    "# file_name = 'LM&LI_vs_RM&RI_B1-B8_pred.pkl'\n",
    "class_names = file_name[:-15].split('_vs_')\n",
    "\n",
    "for subject_name in os.listdir(subjects_path):\n",
    "    \n",
    "    if subject_name == 'Pse_Udo':\n",
    "        continue\n",
    "    \n",
    "    subject_path = os.path.join(subjects_path, subject_name)\n",
    "\n",
    "    predictions = read_pkl(\n",
    "        os.path.join(subject_path, 'Predictions', file_name)\n",
    "    )\n",
    "\n",
    "    pp = PredictionsParser(predictions.y_true, predictions.y_p, class_names)\n",
    "    print(subject_name)\n",
    "    print(f'Total accuracy: {pp.accuracy : .2f}')\n",
    "    summary = pp.summary()\n",
    "    summary = summary.astype(float).round(2)\n",
    "    print(summary)\n",
    "    print(pp.confusion)\n",
    "    print('-'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects_path = '../Source/Subjects/'\n",
    "# file_name = 'LM_vs_LI_vs_RM_vs_RI_B1-B8_pred.pkl'\n",
    "# file_name = 'LM&LI_vs_RM&RI_B1-B8_pred.pkl'\n",
    "file_name = 'LM_vs_LI_B1-B8_pred.pkl'\n",
    "class_names = file_name[:-15].split('_vs_')\n",
    "\n",
    "for subject_name in os.listdir(subjects_path):\n",
    "    \n",
    "    if subject_name == 'Pse_Udo':\n",
    "        continue\n",
    "    \n",
    "    subject_path = os.path.join(subjects_path, subject_name)\n",
    "\n",
    "    predictions = read_pkl(\n",
    "        os.path.join(subject_path, 'Predictions', file_name),\n",
    "    )\n",
    "\n",
    "    y_t = one_hot_decoder(predictions.y_true)\n",
    "\n",
    "    y_p = one_hot_decoder(predictions.y_p)\n",
    "\n",
    "    print(subject_name)\n",
    "    tn, fp, fn, tp = sm.confusion_matrix(y_t, y_p).ravel()\n",
    "    ce = ConfusionEstimator(tp, tn, fp, fn)\n",
    "\n",
    "    print(\n",
    "        f'\\tT\\tF\\n'\\\n",
    "        f'P\\t{tp}\\t{fp}\\n'\\\n",
    "        f'N\\t{tn}\\t{fn}\\n'\n",
    "        f'Accuracy: {ce.acc}\\n'\\\n",
    "        f'Specificity: {ce.spec}\\n'\\\n",
    "        f'Sensitivity: {ce.sens}\\n'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p-values for each subject and averages\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "\n",
    "DataContainer = namedtuple('DataContainer', 'data name title')\n",
    "\n",
    "for kind in ['fullrange', 'before', 'after']:\n",
    "    df_data = list()\n",
    "    for classification, title in zip(\n",
    "        [\n",
    "            'RM_vs_RI_vs_LM_vs_LI',\n",
    "            'RM&RI_vs_LM&LI',\n",
    "            'LM_vs_LI',\n",
    "            'RM_vs_RI'\n",
    "        ], [\n",
    "            '4 classes',\n",
    "            'Left vs Right',\n",
    "            'Within Left',\n",
    "            'Within Right'\n",
    "        ]\n",
    "    ):\n",
    "        order = list(it.product(['B1-B3', 'B10-B12'], repeat=2))\n",
    "        order[-1], order[-2] = order[-2], order[-1]\n",
    "        all_data = list()\n",
    "        for i, ((seq1, seq2), color) in enumerate(zip(order, ['blue', 'red', 'orange', 'green'])):\n",
    "            path = f'/home/user/Downloads/Pics/perf_tables_{kind}/{classification}_train_{seq1}_test_{seq2}_sep.csv'\n",
    "            df = pd.read_csv(path, index_col = 0)\n",
    "            subjects = set(df.index)\n",
    "            data = np.array([df.test_acc[f'{subject}'].to_numpy() for subject in subjects])\n",
    "            all_data.append(DataContainer(data, f'{seq1} : {seq2}', title))\n",
    "\n",
    "        data1, data2 = all_data[:2], all_data[2:]\n",
    "        for data in [data1, data2]:\n",
    "            name = f'{data[0].title} | {data[0].name} | {data[1].name}'\n",
    "            stat, pvals = sp.stats.ttest_rel(data[0].data, data[1].data, axis=1)\n",
    "            sdata = {\n",
    "                subject: p\n",
    "                for subject, p in zip(subjects, pvals)\n",
    "            }\n",
    "            stat, pval = sp.stats.ttest_rel(data[0].data.mean(1), data[1].data.mean(1))\n",
    "            sdata['Average'] = pval\n",
    "            df_data.append(pd.Series(sdata, name=name))\n",
    "    df = pd.DataFrame(df_data).T\n",
    "    df.to_excel(f'/home/user/Downloads/Pics/{kind}_output.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# violinplot for each classification accuracy to subject x sessions\n",
    "\n",
    "span = 1\n",
    "%matplotlib qt\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "\n",
    "def adjust_fig(fig):\n",
    "    fig['cmeans'].set_color('red')\n",
    "    fig['cbars'].set_edgecolor('gray')\n",
    "    fig['cbars'].set_alpha(.5)\n",
    "    fig['cbars'].set_linewidth(.8)\n",
    "    fig['cmaxes'].set_color('#042164')\n",
    "    fig['cmins'].set_color('#042164')\n",
    "    fig['cquantiles'].set_color('#EE550E')\n",
    "\n",
    "def plot_stars(n_subject, n_cap, n_stars, star_symbol='*'):\n",
    "    #? These numbers (9 and 4) are n_subjects & average, n_sessions\n",
    "    indices = [i for i in range(45) if (i+1)%5]\n",
    "    indices = np.reshape(indices, (9, 4))[:, 1:3]\n",
    "    index = indices[n_subject, n_cap]\n",
    "\n",
    "    # The numbers are hand-picked\n",
    "    if (n_cap+1)%2:\n",
    "        height = 1.08\n",
    "    else:\n",
    "        height = 1.19\n",
    "\n",
    "    if n_stars%2:\n",
    "        distances = [np.round((i-n_stars//2)*.4, 2) for i in range(n_stars)]\n",
    "    else:\n",
    "        distances = list(map(\n",
    "            lambda x: x[1] if x[0] >= n_stars//2 else -x[1],\n",
    "            enumerate(map(\n",
    "                lambda x: np.round(x*.4, 2) if x != 0 else .2,\n",
    "                [i for i in range(n_stars//2)][::-1] + list(range(n_stars//2))\n",
    "            ))\n",
    "        ))\n",
    "\n",
    "    for distance in distances:\n",
    "        plt.plot(index+distance, height, star_symbol, c='#1f77b4')\n",
    "\n",
    "# cross = plt.scatter([], [], 120, color='#1f77b4', marker='x', label='p ≥ 0.05')\n",
    "# star = plt.scatter([], [], 120, c='#1f77b4', marker='*', label='p < 0.05')\n",
    "# star2 = mlines.Line2D([], [], color='#1f77b4', marker='*', linestyle='None',\n",
    "#                          markersize=10, label='p < 0.01')\n",
    "\n",
    "for kind in ['before', 'fullrange', 'after']:\n",
    "    excel_file = f'/home/user/Downloads/Pics/{kind}_output.xlsx'\n",
    "    stat = pd.read_excel(excel_file, index_col=0)\n",
    "    # Simplified columns names to original ones\n",
    "    col_info = {\n",
    "        key: val\n",
    "        for key, val\n",
    "        in zip(\n",
    "            [tuple([\n",
    "                word.split(' : ')[0] for word in col.split(' | ')\n",
    "            ][:2]) for col in stat.columns],\n",
    "            stat.columns\n",
    "        )\n",
    "    }\n",
    "\n",
    "    for classification, title in zip(\n",
    "        [\n",
    "            'RM_vs_RI_vs_LM_vs_LI',\n",
    "            'RM&RI_vs_LM&LI',\n",
    "            'LM_vs_LI',\n",
    "            'RM_vs_RI'\n",
    "        ], [\n",
    "            '4 classes',\n",
    "            'Left vs Right',\n",
    "            'Within Left',\n",
    "            'Within Right'\n",
    "        ]\n",
    "    ):\n",
    "        # Limits to make a legend visible\n",
    "        #! When these limits are changed, all hand-picked values are changed\n",
    "        plt.ylim((0., 1.5))\n",
    "        plt.yticks(\n",
    "            [i/10 if i != 0 else 0 for i in range(0, 11, 2)],\n",
    "        )\n",
    "        plt.grid(True, axis='x', linewidth=100, alpha=.1)\n",
    "\n",
    "        # Iterate all sessions\n",
    "        order = list(it.product(['B1-B3', 'B10-B12'], repeat=2))\n",
    "        order[-1], order[-2] = order[-2], order[-1]\n",
    "\n",
    "        for i, ((seq1, seq2), color) in enumerate(zip(order, ['blue', 'red', 'orange', 'green'])):\n",
    "            if i%2:\n",
    "                # As tests are paired, only half of iterations is needed\n",
    "                stat_data = stat[col_info[(title, seq1)]]\n",
    "\n",
    "                for j, subject in enumerate(subjects):\n",
    "                    k = 0 if seq1 == 'B1-B3' else 1\n",
    "                    # print(title, subject, seq1, stat_data[subject], end=' ')\n",
    "\n",
    "                    if stat_data[subject] >= 0.05:\n",
    "                        plot_stars(j, k, 1, 'x')\n",
    "                        # print(f'plotting x at {k}')\n",
    "                    elif .01 <= stat_data[subject] < .05:\n",
    "                        plot_stars(j, k, 1)\n",
    "                        # print(f'plotting * at {k}')\n",
    "                    elif .001 <= stat_data[subject] < .01:\n",
    "                        plot_stars(j, k, 2)\n",
    "                        # print(f'plotting ** at {k}')\n",
    "                    elif stat_data[subject] < .001:\n",
    "                        plot_stars(j, k, 3)\n",
    "                        # print(f'plotting *** at {k}')\n",
    "\n",
    "            path = f'/home/user/Downloads/Pics/perf_tables_{kind}/{classification}_train_{seq1}_test_{seq2}_sep.csv'\n",
    "            df = pd.read_csv(path, index_col = 0)\n",
    "            subjects = set(df.index)\n",
    "            data = np.array([df.test_acc[f'{subject}'].to_numpy() for subject in subjects])\n",
    "            data = np.append(data, [data.mean(0)], axis = 0)\n",
    "            subjects = list(subjects) + ['Average']\n",
    "            # all indices of current session for all subjects\n",
    "            # without spaces between violenplots of different subjects\n",
    "            plane = np.array([i for i in range(len(subjects)*4) if not (i)%4])\n",
    "            fig = plt.violinplot(\n",
    "                data.T, plane + i + np.array(range(len(plane)))*span,\n",
    "                showmeans=True,\n",
    "                quantiles = [[0.25, 0.75] for _ in subjects]\n",
    "            )\n",
    "\n",
    "            # Set color in concordance with session\n",
    "            for i in range(len(subjects)):\n",
    "                fig['bodies'][i].set_facecolor(color)\n",
    "\n",
    "            adjust_fig(fig)\n",
    "\n",
    "        _ = plt.xticks(\n",
    "            plane + 1.5 + np.array(range(len(plane)))*span,\n",
    "            subjects,\n",
    "            rotation=30\n",
    "        )\n",
    "\n",
    "        fig = plt.gcf()\n",
    "        fig.set_size_inches(18.5, 10.5)\n",
    "        b = mpatches.Patch(color='blue', label='B1-B3 | B1-B3', alpha=.4)\n",
    "        r = mpatches.Patch(color='red', label='B1-B3 | B10-B12', alpha=.4)\n",
    "        o = mpatches.Patch(color='orange', label='B10-B12 | B10-B12', alpha=.4)\n",
    "        g = mpatches.Patch(color='green', label='B10-B12 | B1-B3', alpha=.4)\n",
    "        s = mpatches.Patch(color='#1f77b4', label='', alpha=0)\n",
    "        plt.legend(handles=[\n",
    "            b, r, o, g#, cross, star, star2\n",
    "        ], handlelength=1.25, numpoints=2, scatterpoints=1, loc='upper right', ncol=2)\n",
    "        plt.title(title)\n",
    "\n",
    "        # The numbers are hand-picked\n",
    "        start = .051\n",
    "        gap = .0209\n",
    "\n",
    "        for i in range(9):\n",
    "            #! the indexes were selected manually, correspond to the lines that require correction\n",
    "            if i in [1, 3, 5, 7, 8]:\n",
    "                plt.axhline(1.168, start + (5*i+1)*gap, start + (5*i+3)*gap-5e-4, linewidth=.5)\n",
    "                plt.axhline(1.055, start + 5*i*gap, start + (5*i+2)*gap-5e-4, linewidth=.5)\n",
    "            else:\n",
    "                plt.axhline(1.168, start + (5*i+1)*gap, start + (5*i+3)*gap, linewidth=.5)\n",
    "                plt.axhline(1.055, start + 5*i*gap, start + (5*i+2)*gap, linewidth=.5)\n",
    "\n",
    "        pair1, pair2 = True, False\n",
    "        # draw vertical lines\n",
    "        for i in range(5*9):\n",
    "            if (i+1)%5:\n",
    "                if pair1:\n",
    "                    pair1 = False\n",
    "                    pair2 = True\n",
    "                    plt.axvline(i, 0.678, .703, ls='--', linewidth=.75)\n",
    "                    continue\n",
    "                if pair2:\n",
    "                    pair2 = False\n",
    "                    pair1 = True\n",
    "                    plt.axvline(i, 0.753, .778, ls='--', linewidth=.75)\n",
    "\n",
    "        # plt.show()\n",
    "        plt.savefig(f'/home/user/Downloads/Pics/{kind}/{classification}.jpg', dpi=500)\n",
    "        plt.close()\n",
    "\n",
    "    images = [\n",
    "        Image.open(f'/home/user/Downloads/Pics/{kind}/' + f)\n",
    "        for f in os.listdir(f'/home/user/Downloads/Pics/{kind}')\n",
    "    ]\n",
    "    pdf_path = f'/home/user/Downloads/Pics/{kind}_output.pdf'\n",
    "    images[0].save(\n",
    "        pdf_path, \"PDF\", resolution=100.0, save_all=True, append_images=images[1:]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# boxplots classification x sessions to average accuracy\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "DataContainer = namedtuple('DataContainer', 'data name title')\n",
    "\n",
    "\n",
    "def rename_sessions(sessions):\n",
    "    out = list()\n",
    "    for session in sessions:\n",
    "        if session == 'B1-B3':\n",
    "            out.append('beginning')\n",
    "        elif session == 'B10-B12':\n",
    "            out.append('end')\n",
    "        else:\n",
    "            raise ValueError(f'Unknown session: {session}')\n",
    "    return ' : '.join(out)\n",
    "\n",
    "\n",
    "def plot_stars(n_box, n_stars, star_symbol='*', height=1.125):\n",
    "\n",
    "    if n_stars%2:\n",
    "        distances = [np.round((i-n_stars//2)*.4, 2) for i in range(n_stars)]\n",
    "    else:\n",
    "        distances = list(map(\n",
    "            lambda x: x[1] if x[0] >= n_stars//2 else -x[1],\n",
    "            enumerate(map(\n",
    "                lambda x: np.round(.2 + x*.4, 2) if x != 0 else .2,\n",
    "                [i for i in range(n_stars//2)][::-1] + list(range(n_stars//2))\n",
    "            ))\n",
    "        ))\n",
    "\n",
    "    n_box -= .5\n",
    "\n",
    "    for distance in distances:\n",
    "        plt.plot(n_box+distance, height, star_symbol, c='#1f77b4', ms=10)\n",
    "\n",
    "ymin, ymax = .35, 1.35\n",
    "diff=.35\n",
    "\n",
    "for kind in [\n",
    "    'before',\n",
    "    'fullrange',\n",
    "    'after'\n",
    "]:\n",
    "    excel_file = f'/home/user/Downloads/Pics/{kind}_output.xlsx'\n",
    "    stat = pd.read_excel(excel_file, index_col=0)\n",
    "    col_info = {\n",
    "        key: val\n",
    "        for key, val\n",
    "        in zip(\n",
    "            [tuple([\n",
    "                word.split(' : ')[0] for word in col.split(' | ')\n",
    "            ][:2]) for col in stat.columns],\n",
    "            stat.columns\n",
    "        )\n",
    "    }\n",
    "    all_data = list()\n",
    "    all_titles = list()\n",
    "    all_stats = list()\n",
    "    for classification, title in zip(\n",
    "        [\n",
    "            'RM_vs_RI_vs_LM_vs_LI',\n",
    "            'RM&RI_vs_LM&LI',\n",
    "            'LM_vs_LI',\n",
    "            'RM_vs_RI'\n",
    "        ], [\n",
    "            '4 classes',\n",
    "            'Left vs Right',\n",
    "            'Within Left',\n",
    "            'Within Right'\n",
    "        ]\n",
    "    ):\n",
    "        for i, ((seq1, seq2), color) in enumerate(zip(order, ['blue', 'red', 'orange', 'green'])):\n",
    "            if i%2:\n",
    "                all_stats.append(stat[col_info[(title, seq1)]]['Average'])\n",
    "            path = f'/home/user/Downloads/Pics/perf_tables_{kind}/{classification}_train_{seq1}_test_{seq2}_sep.csv'\n",
    "            df = pd.read_csv(path, index_col = 0)\n",
    "            data = [df['test_acc'][subject].mean() for subject in set(df['test_acc'].index)]\n",
    "            all_data.append(data)\n",
    "            all_titles.append(title)\n",
    "\n",
    "    names = list(map(\n",
    "        rename_sessions,\n",
    "        order\n",
    "    ))\n",
    "    indices = [i for i in range(len(all_data) + len(all_data)//5) if (i+1)%5]\n",
    "    for i, data in enumerate(all_data):\n",
    "        q1 = np.percentile(data, 25)\n",
    "        q3 = np.percentile(data, 75)\n",
    "        iqr = q3 - q1\n",
    "        p1 = min(\n",
    "            filter(\n",
    "                lambda datum: q1-1.5*iqr <= datum <= q1,\n",
    "                data\n",
    "            )\n",
    "        )\n",
    "        p2 = max(\n",
    "            filter(\n",
    "                lambda datum: q3 <= datum <= q3+1.5*iqr,\n",
    "                data\n",
    "            )\n",
    "        )\n",
    "        # .4 is min ylim\n",
    "        plt.axvline(indices[i], p2-diff+.05, 1.1-diff, linewidth=1, color='#aaa')\n",
    "\n",
    "        if i%2:\n",
    "            if all_stats[i//2] >= .05:\n",
    "                plot_stars(indices[i], 1, 'x')\n",
    "            if .01 <= all_stats[i//2] < .05:\n",
    "                plot_stars(indices[i], 1, '*')\n",
    "            if .001 <= all_stats[i//2] < .01:\n",
    "                plot_stars(indices[i], 2, '*')\n",
    "            if all_stats[i//2] < .001:\n",
    "                plot_stars(indices[i], 3, '*')\n",
    "\n",
    "            plt.axhline(1.1, indices[i]*0.05, (indices[i]+1)*0.05, linewidth=1, color='#aaa')\n",
    "\n",
    "    boxplot = plt.boxplot(all_data, positions=indices, showfliers=False, patch_artist=True)\n",
    "    color = '#aaa'\n",
    "    width = 1\n",
    "\n",
    "    colorconfig = {\n",
    "        session: color\n",
    "        for session, color in zip(\n",
    "            names,\n",
    "            [mc.to_rgba('blue', .25), mc.to_rgba('red', .25), mc.to_rgba('yellow', .25), mc.to_rgba('green', .25)]\n",
    "        )\n",
    "    }\n",
    "\n",
    "    for i, box in enumerate(boxplot['boxes']):\n",
    "        box.set_facecolor(colorconfig[names[i%len(names)]])\n",
    "        box.set_linewidth(0)\n",
    "    for box in boxplot['caps']:\n",
    "        box.set_color(color)\n",
    "        box.set_linewidth(width*1.5)\n",
    "    for box in boxplot['whiskers']:\n",
    "        box.set_color(color)\n",
    "        box.set_linewidth(width)\n",
    "        box.set_linestyle('--')\n",
    "    for box in boxplot['medians']:\n",
    "        box.set_color('#FF1E0F')\n",
    "        box.set_linewidth(width*1.25)\n",
    "        box.set_alpha(.75)\n",
    "\n",
    "    middles = [index-1.5 for i, index in enumerate(indices) if not (i+1)%4]\n",
    "    _ = plt.xticks(\n",
    "        middles,\n",
    "        [title for i, title in enumerate(all_titles) if not (i+1)%4],\n",
    "        rotation=30\n",
    "    )\n",
    "    _ = plt.yticks([.4, .6, .8, 1.])\n",
    "\n",
    "    for i in middles:\n",
    "        plt.axvline(i, 0, 1, c='gray', alpha=.1, linewidth=200)\n",
    "\n",
    "    plt.xlim(-1, indices[-1]+1)\n",
    "    plt.ylim(ymin, ymax)\n",
    "\n",
    "    b = mpatches.Patch(facecolor=mc.to_rgba('blue', .4), label='B1-B3 | B1-B3', edgecolor=mc.to_rgba('blue', .6))\n",
    "    r = mpatches.Patch(facecolor=mc.to_rgba('red', .4), label='B1-B3 | B10-B12', edgecolor=mc.to_rgba('red', .6))\n",
    "    o = mpatches.Patch(facecolor=mc.to_rgba('yellow', .4), label='B10-B12 | B10-B12', edgecolor=mc.to_rgba('#cccc00', .6))\n",
    "    g = mpatches.Patch(facecolor=mc.to_rgba('green', .4), label='B10-B12 | B1-B3', edgecolor=mc.to_rgba('green', .6))\n",
    "\n",
    "    plt.legend(handles=[b, r, o, g], ncol=2, loc='upper right')\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(18.5, 10.5)\n",
    "    # plt.xlabel('Task')\n",
    "    # plt.ylabel('Accuracy')\n",
    "    # plt.show()\n",
    "    plt.savefig(f'/home/user/Downloads/Pics/{kind}_boxplot.jpg', dpi=500)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "\n",
    "def plot_stars(n_box, n_stars, star_symbol='*', height=1.125):\n",
    "    if n_stars%2:\n",
    "        distances = [np.round((i-n_stars//2)*.4, 2) for i in range(n_stars)]\n",
    "    else:\n",
    "        distances = list(map(\n",
    "            lambda x: x[1] if x[0] >= n_stars//2 else -x[1],\n",
    "            enumerate(map(\n",
    "                lambda x: np.round(.2 + x*.4, 2) if x != 0 else .2,\n",
    "                [i for i in range(n_stars//2)][::-1] + list(range(n_stars//2))\n",
    "            ))\n",
    "        ))\n",
    "\n",
    "    # n_box -= .5\n",
    "\n",
    "    for distance in distances:\n",
    "        plt.plot(n_box+distance, height, star_symbol, c='#1f77b4', ms=10)\n",
    "\n",
    "width = 1\n",
    "path = '/home/user/Downloads/sdata/MEG_SRTT_RT.xlsx'\n",
    "df = pd.read_excel(path, index_col=1)\n",
    "for index in df.columns:\n",
    "    if not isinstance(index, float) or index > 12:\n",
    "        df.drop(index, axis=1, inplace=True)\n",
    "indices = [i for i in range(2*len(df.columns)) if (i+1)%2]\n",
    "boxplot = plt.boxplot(df, patch_artist=True, positions=indices, showfliers=False)\n",
    "color = '#888'\n",
    "\n",
    "for i, box in enumerate(boxplot['boxes']):\n",
    "    box.set_facecolor('#66aadd')\n",
    "    box.set_alpha(.75)\n",
    "    box.set_linewidth(0)\n",
    "for box in boxplot['caps']:\n",
    "    box.set_color(color)\n",
    "    box.set_linewidth(width*1.5)\n",
    "for box in boxplot['whiskers']:\n",
    "    box.set_color(color)\n",
    "    box.set_linewidth(width)\n",
    "    box.set_linestyle('--')\n",
    "for box in boxplot['medians']:\n",
    "    box.set_color('#FF1E0F')\n",
    "    box.set_linewidth(width*1.25)\n",
    "    box.set_alpha(.75)\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "xmin = -1\n",
    "xmax = 2*len(df.columns)-1\n",
    "plt.xlim([xmin, xmax])\n",
    "get_x = lambda x: (x - xmin)/(xmax - xmin)\n",
    "ymin = 150\n",
    "ymax = 550\n",
    "plt.ylim([ymin, ymax])\n",
    "get_y = lambda y: (y - ymin)/(ymax - ymin)\n",
    "\n",
    "for i, drange in zip([1, 12], [range(12), list(range(12))[::-1]]):\n",
    "    if i == 1:\n",
    "        height = 510\n",
    "    if i == 12:\n",
    "        height = 170\n",
    "    for j in drange:\n",
    "        if j+1 == i:\n",
    "            continue\n",
    "        s, p = sp.stats.ttest_ind(df[i], df[j+1])\n",
    "        if p >= .05:\n",
    "            plot_stars(indices[j], 1, star_symbol='x', height=height)\n",
    "        elif .01 <= p < .05:\n",
    "            plot_stars(indices[j], 1, height=height)\n",
    "        elif .001 <= p < .01:\n",
    "            plot_stars(indices[j], 2, height=height)\n",
    "        elif p < .001:\n",
    "            plot_stars(indices[j], 3, height=height)\n",
    "\n",
    "for i, data in enumerate(df.to_numpy().T):\n",
    "    q1 = np.percentile(data, 25)\n",
    "    q3 = np.percentile(data, 75)\n",
    "    iqr = q3 - q1\n",
    "    p1 = min(\n",
    "        filter(\n",
    "            lambda datum: q1-1.5*iqr <= datum <= q1,\n",
    "            data\n",
    "        )\n",
    "    )\n",
    "    p2 = max(\n",
    "        filter(\n",
    "            lambda datum: q3 <= datum <= q3+1.5*iqr,\n",
    "            data\n",
    "        )\n",
    "    )\n",
    "    # .4 is min ylim\n",
    "    plt.axvline(indices[i], get_y(p2+25), get_y(500), linewidth=1, color='#aaa')\n",
    "    plt.axvline(indices[i], get_y(p1-25), get_y(180), linewidth=1, color='#aaa')\n",
    "    plt.axhline(500, get_x(indices[0]), get_x(indices[-1]), linewidth=1, color='#aaa')\n",
    "    plt.axhline(180, get_x(indices[0]), get_x(indices[-1]), linewidth=1, color='#aaa')\n",
    "\n",
    "plt.xlabel('Sessions')\n",
    "# plt.text(2, y=75, s='Stimulus\\nOriented\\nBlocks', ha='center')\n",
    "# plt.text(2+9, y=92.15, s='Learning Blocks')\n",
    "# plt.axhline(150, 0, 1, c=color)\n",
    "plt.ylabel('Mean Reaction Time (ms)')\n",
    "_ = plt.xticks([i-1 for i in range(2*len(df.columns)) if i%2], [f'B{int(i)}' for i in df.columns])\n",
    "_ = plt.yticks([200, 300, 400, 500])\n",
    "# ax2 = plt.axes([0,0,2,2], facecolor=(1,1,1,0))\n",
    "plt.savefig('/home/user/Downloads/Pics/reaction_time.jpg', dpi=500)\n",
    "# plt.close()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/user/Downloads/sdata/MEG_SRTT_ACC.csv'\n",
    "df = pd.read_csv(path, index_col=1)\n",
    "for index in df.columns:\n",
    "    if not str.isdigit(index) or int(index) > 12:\n",
    "        df.drop(index, axis=1, inplace=True)\n",
    "indices = [i for i in range(2*len(df.columns)) if (i+1)%2]\n",
    "df = df.dropna()\n",
    "boxplot = plt.boxplot(df, patch_artist=True, positions=indices, showfliers=False)\n",
    "color = '#888'\n",
    "\n",
    "for i, box in enumerate(boxplot['boxes']):\n",
    "    box.set_facecolor('#66aadd')\n",
    "    box.set_alpha(.75)\n",
    "    box.set_linewidth(0)\n",
    "for box in boxplot['caps']:\n",
    "    box.set_color(color)\n",
    "    box.set_linewidth(width*1.5)\n",
    "for box in boxplot['whiskers']:\n",
    "    box.set_color(color)\n",
    "    box.set_linewidth(width)\n",
    "    box.set_linestyle('--')\n",
    "for box in boxplot['medians']:\n",
    "    box.set_color('#FF1E0F')\n",
    "    box.set_linewidth(width*1.25)\n",
    "    box.set_alpha(.75)\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "xmin = -1\n",
    "xmax = 2*len(df.columns)-1\n",
    "plt.xlim([xmin, xmax])\n",
    "get_x = lambda x: (x - xmin)/(xmax - xmin)\n",
    "ymin = 92\n",
    "ymax = 102\n",
    "plt.ylim([ymin, ymax])\n",
    "get_y = lambda y: (y - ymin)/(ymax - ymin)\n",
    "\n",
    "# for i, drange in zip([1, 12], [range(12), list(range(12))[::-1]]):\n",
    "#     if i == 1:\n",
    "#         height = 105\n",
    "#     if i == 12:\n",
    "#         height = 95\n",
    "#     for j in drange:\n",
    "#         if j+1 == i:\n",
    "#             continue\n",
    "#         s, p = sp.stats.ttest_ind(df[f'{i}'], df[f'{j+1}'])\n",
    "#         if p >= .05:\n",
    "#             plot_stars(indices[j], 1, star_symbol='x', height=height)\n",
    "#         elif .01 <= p < .05:\n",
    "#             plot_stars(indices[j], 1, height=height)\n",
    "#         elif .001 <= p < .01:\n",
    "#             plot_stars(indices[j], 2, height=height)\n",
    "#         elif p < .001:\n",
    "#             plot_stars(indices[j], 3, height=height)\n",
    "\n",
    "# for i, data in enumerate(df.to_numpy().T):\n",
    "#     q1 = np.percentile(data, 25)\n",
    "#     q3 = np.percentile(data, 75)\n",
    "#     iqr = q3 - q1\n",
    "#     print(data, list(\n",
    "#         filter(\n",
    "#             lambda datum: q1-1.5*iqr <= datum <= q1,\n",
    "#             data\n",
    "#         )\n",
    "#     ))\n",
    "#     p1 = min(\n",
    "#         filter(\n",
    "#             lambda datum: q1-1.5*iqr <= datum <= q1,\n",
    "#             data\n",
    "#         )\n",
    "#     )\n",
    "#     p2 = max(\n",
    "#         filter(\n",
    "#             lambda datum: q3 <= datum <= q3+1.5*iqr,\n",
    "#             data\n",
    "#         )\n",
    "#     )\n",
    "#     # .4 is min ylim\n",
    "#     plt.axvline(indices[i], get_y(p2+25), get_y(500), linewidth=1, color='#aaa')\n",
    "#     plt.axvline(indices[i], get_y(p1-25), get_y(180), linewidth=1, color='#aaa')\n",
    "#     plt.axhline(500, get_x(indices[0]), get_x(indices[-1]), linewidth=1, color='#aaa')\n",
    "#     plt.axhline(180, get_x(indices[0]), get_x(indices[-1]), linewidth=1, color='#aaa')\n",
    "\n",
    "plt.xlabel('Sessions')\n",
    "# plt.text(2, y=75, s='Stimulus\\nOriented\\nBlocks', ha='center')\n",
    "# plt.text(2+9, y=92.15, s='Learning Blocks')\n",
    "# # plt.axhline(150, 0, 1, c=color)\n",
    "plt.ylabel('Mean Accuracy')\n",
    "_ = plt.xticks([i-1 for i in range(2*len(df.columns)) if i%2], [f'B{int(i)}' for i in df.columns])\n",
    "_ = plt.yticks([94, 96, 98, 100])\n",
    "# # ax2 = plt.axes([0,0,2,2], facecolor=(1,1,1,0))\n",
    "plt.savefig('/home/user/Downloads/Pics/accuracy.jpg', dpi=500)\n",
    "# # plt.close()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 0.33903536613952545\n",
      "1 3 0.4060763432202964\n",
      "1 4 0.18651108061632113\n",
      "1 5 0.1556955322407384\n",
      "1 6 0.06155219396642376\n",
      "1 7 0.08909665953972162\n",
      "1 8 0.030262094909898833\n",
      "1 9 0.020337738193668905\n",
      "1 10 0.027767225105387924\n",
      "1 11 0.006968595607441927\n",
      "1 12 0.006217239291057131\n",
      "12 11 0.4548363344858678\n",
      "12 10 0.25520975027943116\n",
      "12 9 0.2849417503760919\n",
      "12 8 0.20922029032004968\n",
      "12 7 0.12380851196360351\n",
      "12 6 0.10244634518307633\n",
      "12 5 0.04330865699334563\n",
      "12 4 0.03807444758202549\n",
      "12 3 0.03733970765005651\n",
      "12 2 0.0358599230295767\n",
      "12 1 0.006217239291057131\n"
     ]
    }
   ],
   "source": [
    "for i, drange in zip([1, 12], [range(12), list(range(12))[::-1]]):\n",
    "    for j in drange:\n",
    "        if j+1 == i:\n",
    "            continue\n",
    "        s, p = sp.stats.ttest_ind(df[i], df[j+1])\n",
    "        print(i, j+1, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 18})\n",
    "\n",
    "def adjust_fig(fig):\n",
    "    fig['cmeans'].set_color('red')\n",
    "    fig['cbars'].set_edgecolor('gray')\n",
    "    fig['cbars'].set_alpha(.5)\n",
    "    fig['cbars'].set_linewidth(.8)\n",
    "    fig['cmaxes'].set_color('#042164')\n",
    "    fig['cmins'].set_color('#042164')\n",
    "    fig['cquantiles'].set_color('#EE550E')\n",
    "\n",
    "classifications = [\n",
    "    'RM&RI_vs_LM&LI',\n",
    "    'RM_vs_RI_vs_LM_vs_LI',\n",
    "    'LM_vs_LI',\n",
    "    'RM_vs_RI'\n",
    "]\n",
    "names = [\n",
    "    'Left vs Right',\n",
    "    '4 fingers',\n",
    "    'Within Left',\n",
    "    'Within Right'\n",
    "]\n",
    "\n",
    "n=1\n",
    "\n",
    "df_path = f'/home/user/Downloads/perf_tables/{classifications[n]}.csv'\n",
    "\n",
    "df = pd.read_csv(df_path, index_col=0)\n",
    "data = df.test_acc[[index for index in df.index if index != 'Pse_Udo_']]\n",
    "boxplot = plt.boxplot(data, patch_artist=True, showfliers=False)\n",
    "\n",
    "# fig = plt.violinplot(data, showmeans=True, quantiles=[.25, .75], points=1000, bw_method='silverman')\n",
    "# adjust_fig(fig)\n",
    "\n",
    "# color = '#888'\n",
    "\n",
    "for i, box in enumerate(boxplot['boxes']):\n",
    "    box.set_facecolor('#66aadd')\n",
    "    box.set_alpha(.75)\n",
    "    box.set_linewidth(0)\n",
    "for box in boxplot['caps']:\n",
    "    box.set_color(color)\n",
    "    box.set_linewidth(width*1.5)\n",
    "for box in boxplot['whiskers']:\n",
    "    box.set_color(color)\n",
    "    box.set_linewidth(width)\n",
    "    box.set_linestyle('--')\n",
    "for box in boxplot['medians']:\n",
    "    box.set_color('#FF1E0F')\n",
    "    box.set_linewidth(width*1.25)\n",
    "    box.set_alpha(.75)\n",
    "\n",
    "_ = plt.xticks([1], [names[n]])\n",
    "# plt.show()\n",
    "plt.savefig(f'/home/user/Downloads/Pics/perf_boxplot_{classifications[n]}')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    pd.read_csv(f'/home/user/Downloads/perf_tables/{classification}.csv', index_col=0).test_acc[[index for index in df.index if index != 'Pse_Udo_']]\n",
    "    for classification in ['LM_vs_LI', 'RM_vs_RI']\n",
    "]\n",
    "\n",
    "boxplot = plt.boxplot(data, patch_artist=True, showfliers=False)\n",
    "color = '#888'\n",
    "for i, box in enumerate(boxplot['boxes']):\n",
    "    box.set_facecolor('#66aadd')\n",
    "    box.set_alpha(.75)\n",
    "    box.set_linewidth(0)\n",
    "for box in boxplot['caps']:\n",
    "    box.set_color(color)\n",
    "    box.set_linewidth(width*1.5)\n",
    "for box in boxplot['whiskers']:\n",
    "    box.set_color(color)\n",
    "    box.set_linewidth(width)\n",
    "    box.set_linestyle('--')\n",
    "for box in boxplot['medians']:\n",
    "    box.set_color('#FF1E0F')\n",
    "    box.set_linewidth(width*1.25)\n",
    "    box.set_alpha(.75)\n",
    "\n",
    "_ = plt.xticks([1, 2], ['Within Left', 'Within Right'])\n",
    "\n",
    "plt.savefig(f'/home/user/Downloads/Pics/perf_boxplot_Left_and_Right.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84.25 ± 7.517\n"
     ]
    }
   ],
   "source": [
    "# classification = 'RM&RI_vs_LM&LI'\n",
    "classification = 'RM_vs_RI'\n",
    "data = pd.read_csv(f'/home/user/Downloads/perf_tables/{classification}.csv', index_col=0)\n",
    "data = data.test_acc.drop('Pse_Udo_')\n",
    "\n",
    "data.mean()\n",
    "print(f'{data.mean()*100} ± {np.round(data.std()*100, 3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.        ,  7.76231645, 12.05071132, 18.70828693, 29.04392867,\n",
       "       45.08963303, 70.        ])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "min_freq=5\n",
    "max_freq=70\n",
    "n_freqs=7\n",
    "freqs = np.logspace(np.log10(min_freq), np.log10(max_freq), n_freqs)\n",
    "freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.        ,  1.83478607,  3.36643992,  6.17669708, 11.33291776,\n",
       "       20.79347964, 38.15158679, 70.        ])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_freq=1\n",
    "max_freq=70\n",
    "n_freqs=8\n",
    "freqs = np.logspace(np.log10(min_freq), np.log10(max_freq), n_freqs)\n",
    "freqs"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "25b6c1d617e3cb25e4067864bcd46322e1b7da41afdae0cf7c23b941b0b9b767"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
