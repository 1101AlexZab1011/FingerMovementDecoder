{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-20 00:50:57.394754: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-05-20 00:50:57.394778: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "current_dir = os.path.dirname(os.path.abspath('./'))\n",
    "if not current_dir in sys.path:\n",
    "    sys.path.append(current_dir)\n",
    "from combiners import EpochsCombiner\n",
    "from typing import *\n",
    "import mne\n",
    "import tensorflow as tf\n",
    "import mneflow as mf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from utils.data_management import dict2str\n",
    "from lfcnn_vis import plot_patterns\n",
    "from LFCNN_decoder import SpatialParameters, TemporalParameters, ComponentsOrder, Predictions\n",
    "import pickle\n",
    "from utils.machine_learning import one_hot_decoder\n",
    "import sklearn.metrics as sm\n",
    "from utils.machine_learning.confusion import ConfusionEstimator\n",
    "import scipy as sp\n",
    "\n",
    "def read_pkl(path: str) -> Any:\n",
    "    with open(\n",
    "            path,\n",
    "            'rb'\n",
    "        ) as file:\n",
    "        content = pickle.load(\n",
    "            file\n",
    "        )\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6960897477187333\n",
      "0.7250858165372503\n",
      "0.69343843076526\n",
      "0.847382132383333\n",
      "0.7089745948538733\n",
      "0.7634265758358783\n",
      "0.8270903123585336\n",
      "0.6895991021324355\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.661231856953922"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root = '../Source/Subjects'\n",
    "scores = 0\n",
    "case = 'lm_vs_li'\n",
    "i = 0\n",
    "for subj_name in os.listdir(root):\n",
    "    i += 1\n",
    "    \n",
    "    if subj_name == 'Pse_Udo':\n",
    "        continue\n",
    "    \n",
    "    tf_path = os.path.join(root, subj_name, 'TF_planes', 'BB1-BB8', 'RespCor')\n",
    "    tf_file = os.path.join(tf_path, f'{case}.pkl')\n",
    "    scorer = read_pkl(tf_file)\n",
    "    print(scorer.tf_scores.mean(0).max())\n",
    "    scores += scorer.tf_scores.mean(0).max()\n",
    "scores/i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils.console.colored import warn\n",
    "\n",
    "class PredictionsParser(object):\n",
    "    def __init__(\n",
    "        self,\n",
    "        y_true: Union[list[int], np.ndarray],\n",
    "        y_pred: Union[list[int], np.ndarray],\n",
    "        class_names: Optional[Union[str, list[str]]] = None\n",
    "    ):\n",
    "        \n",
    "        y_true = self.__check_numpy(y_true)\n",
    "        y_pred = self.__check_numpy(y_pred)\n",
    "        \n",
    "        if y_true.shape != y_pred.shape:\n",
    "            raise ValueError('Predictions and actual values are inconsistent. Actual values shape: {y_true.shape}, predictions shape: {y_pred.shape}')\n",
    "        \n",
    "        if len(y_true.shape) != 1:\n",
    "            y_true = one_hot_decoder(y_true)\n",
    "            y_pred = one_hot_decoder(y_pred)\n",
    "        \n",
    "        self._y_true = y_true\n",
    "        self._y_pred = y_pred\n",
    "        \n",
    "        self._accuracy = sm.accuracy_score(y_true, y_pred)\n",
    "        \n",
    "        classes_true = np.unique(self._y_true)\n",
    "        classes_pred = np.unique(self._y_pred)\n",
    "        \n",
    "        if np.any(classes_true != classes_pred):\n",
    "            warn(f'Warning: Classes are inconsistent.\\n\\tActual classes: {classes_true}\\n\\tPredicted classes: {classes_pred}.\\nTake actual classes')\n",
    "            \n",
    "        del classes_pred\n",
    "        \n",
    "        self._classes = classes_true\n",
    "        self._n_classes = len(classes_true)\n",
    "        \n",
    "        if class_names is not None:\n",
    "            \n",
    "            if isinstance(class_names, str):\n",
    "                class_names = class_names.split(' ')\n",
    "            \n",
    "            if len(class_names) != self.n_classes:\n",
    "                raise ValueError(f'Class names and classes are inconsistent: number of classes is {self.n_classes}, but {len(class_names)} names of classes were given')\n",
    "        else:\n",
    "            class_names = [f'Class {i}' for i in range(self.n_classes)]\n",
    "        \n",
    "        self._class_names = class_names\n",
    "        \n",
    "        self._confusion = pd.DataFrame(\n",
    "            sm.confusion_matrix(self.y_true, self.y_pred),\n",
    "            index = [f'Actual {class_name}' for class_name in self.class_names],\n",
    "            columns = [f'Predicted {class_name}' for class_name in self.class_names]\n",
    "        )\n",
    "    \n",
    "    @staticmethod\n",
    "    def __check_numpy(arr: Union[list, tuple, np.ndarray]):\n",
    "        if isinstance(arr, np.ndarray):\n",
    "            return arr\n",
    "        elif not isinstance(arr, np.ndarray) and isinstance(arr, (list, tuple)):\n",
    "            return np.array(arr)\n",
    "        else:\n",
    "            raise ValueError(f'The given argument must be either a np.ndarray or a list, but {type(arr)} was given')\n",
    "        \n",
    "    @property\n",
    "    def y_true(self):\n",
    "        return self._y_true\n",
    "    @y_true.setter\n",
    "    def y_true(self, value):\n",
    "        raise AttributeError('Impossible to set y_true directly')\n",
    "    \n",
    "    @property\n",
    "    def y_pred(self):\n",
    "        return self._y_pred\n",
    "    @y_pred.setter\n",
    "    def y_pred(self, value):\n",
    "        raise AttributeError('Impossible to set y_pred directly')\n",
    "    \n",
    "    @property\n",
    "    def accuracy(self):\n",
    "        return self._accuracy\n",
    "    @accuracy.setter\n",
    "    def accuracy(self, value):\n",
    "        raise AttributeError('Impossible to set accuracy directly')\n",
    "    \n",
    "    @property\n",
    "    def classes(self):\n",
    "        return self._classes\n",
    "    @classes.setter\n",
    "    def classes(self, value):\n",
    "        raise AttributeError('Impossible to set classes directly')\n",
    "    \n",
    "    @property\n",
    "    def n_classes(self):\n",
    "        return self._n_classes\n",
    "    @n_classes.setter\n",
    "    def n_classes(self, value):\n",
    "        raise AttributeError('Impossible to set number of classes directly')\n",
    "    \n",
    "    @property\n",
    "    def class_names(self):\n",
    "        return self._class_names\n",
    "    @class_names.setter\n",
    "    def class_names(self, value):\n",
    "        raise AttributeError('Impossible to set names for classes directly')\n",
    "    \n",
    "    @property\n",
    "    def confusion(self):\n",
    "        return self._confusion\n",
    "    @confusion.setter\n",
    "    def confusion(self, value):\n",
    "        raise AttributeError('Impossible to set confusion matrix directly')\n",
    "    \n",
    "    def summary(self, *args: str):\n",
    "        df = self.confusion.copy()\n",
    "        summary = pd.DataFrame(columns = self.class_names)\n",
    "        summary.loc['Total'] = [df[column].sum() for column in df.columns]\n",
    "        summary.loc['Accuracy'] = [None for _ in range(self.n_classes)]\n",
    "        summary.loc['Specificity'] = [None for _ in range(self.n_classes)]\n",
    "        summary.loc['Sensitivity'] = [None for _ in range(self.n_classes)]\n",
    "        \n",
    "        ec = self.estimate_confusion()\n",
    "        \n",
    "        args = list(args)\n",
    "        for i, arg in enumerate(args):\n",
    "            if not isinstance(arg, tuple):\n",
    "                args[i] = arg, arg\n",
    "        \n",
    "        for arg_value, arg_name in args:\n",
    "            if hasattr(ec[self.class_names[0]], arg_value):\n",
    "                summary.loc[arg_name] = [None for _ in range(self.n_classes)]\n",
    "            else:\n",
    "                warn(f'WARNING: the {arg_value} property was not found in the confusion evaluator, so it was ignored')\n",
    "                args.remove((arg_value, arg_name))\n",
    "            \n",
    "        \n",
    "        for i, class_name in enumerate(self.class_names):\n",
    "            summary[class_name].loc['Accuracy'] = ec[class_name].acc\n",
    "            summary[class_name].loc['Specificity'] = ec[class_name].spec\n",
    "            summary[class_name].loc['Sensitivity'] = ec[class_name].sens\n",
    "            \n",
    "            for arg_value, arg_name in args:\n",
    "                summary[class_name].loc[arg_name] = getattr(ec[class_name], arg_value)\n",
    "            \n",
    "        return summary\n",
    "    \n",
    "    def estimate_confusion(self):\n",
    "        \n",
    "        return {\n",
    "            class_name: ConfusionEstimator(\n",
    "                # tp, tn, fp, fn\n",
    "                self.confusion[self.confusion.columns[i]][self.confusion.index[i]],\n",
    "                self.confusion[\n",
    "                    list(self.confusion.columns[:i]) + list(self.confusion.columns[i+1:])\n",
    "                    ].loc[\n",
    "                        list(self.confusion.index[:i]) + list(self.confusion.index[i+1:])\n",
    "                ].sum().sum(),\n",
    "                self.confusion[self.confusion.columns[i]].loc[\n",
    "                    list(self.confusion.index[:i]) + list(self.confusion.index[i+1:])\n",
    "                ].sum(),\n",
    "                self.confusion[\n",
    "                    list(self.confusion.columns[:i]) + list(self.confusion.columns[i+1:])\n",
    "                ].loc[self.confusion.index[i]].sum()\n",
    "            )\n",
    "            for i, class_name in enumerate(self.class_names)\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/Projects/FingerMovementDecoder/utils/machine_learning/confusion.py:300: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self._lr_plus = self.tpr / self.fpr\n",
      "/home/user/Projects/FingerMovementDecoder/utils/machine_learning/confusion.py:300: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self._lr_plus = self.tpr / self.fpr\n",
      "/home/user/Projects/FingerMovementDecoder/utils/machine_learning/confusion.py:300: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self._lr_plus = self.tpr / self.fpr\n",
      "/home/user/Projects/FingerMovementDecoder/utils/machine_learning/confusion.py:300: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self._lr_plus = self.tpr / self.fpr\n",
      "/home/user/Projects/FingerMovementDecoder/utils/machine_learning/confusion.py:300: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self._lr_plus = self.tpr / self.fpr\n",
      "/home/user/Projects/FingerMovementDecoder/utils/machine_learning/confusion.py:300: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self._lr_plus = self.tpr / self.fpr\n",
      "/tmp/ipykernel_3260006/3332066588.py:51: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  sumdf.to_excel(os.path.join(classification_tables_path, f'{subject_name}_{classification}_summary.xls'))\n",
      "/tmp/ipykernel_3260006/3332066588.py:52: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  confdf.to_excel(os.path.join(classification_tables_path, f'{subject_name}_{classification}_confusion.xls'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Source/perf_tables/Ga_Fed_06/B1-B8_LFRNN/Ga_Fed_06_RM&RI_vs_LM&LI_summary.xls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3260006/3332066588.py:51: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  sumdf.to_excel(os.path.join(classification_tables_path, f'{subject_name}_{classification}_summary.xls'))\n",
      "/tmp/ipykernel_3260006/3332066588.py:52: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  confdf.to_excel(os.path.join(classification_tables_path, f'{subject_name}_{classification}_confusion.xls'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Source/perf_tables/Fe_To_08/B1-B8_LFRNN/Fe_To_08_RM&RI_vs_LM&LI_summary.xls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3260006/3332066588.py:51: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  sumdf.to_excel(os.path.join(classification_tables_path, f'{subject_name}_{classification}_summary.xls'))\n",
      "/tmp/ipykernel_3260006/3332066588.py:52: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  confdf.to_excel(os.path.join(classification_tables_path, f'{subject_name}_{classification}_confusion.xls'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Source/perf_tables/Az_Mar_05/B1-B8_LFRNN/Az_Mar_05_RM&RI_vs_LM&LI_summary.xls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/Projects/FingerMovementDecoder/utils/machine_learning/confusion.py:300: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self._lr_plus = self.tpr / self.fpr\n",
      "/home/user/Projects/FingerMovementDecoder/utils/machine_learning/confusion.py:300: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self._lr_plus = self.tpr / self.fpr\n",
      "/home/user/Projects/FingerMovementDecoder/utils/machine_learning/confusion.py:300: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self._lr_plus = self.tpr / self.fpr\n",
      "/home/user/Projects/FingerMovementDecoder/utils/machine_learning/confusion.py:300: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self._lr_plus = self.tpr / self.fpr\n",
      "/home/user/Projects/FingerMovementDecoder/utils/machine_learning/confusion.py:300: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self._lr_plus = self.tpr / self.fpr\n",
      "/home/user/Projects/FingerMovementDecoder/utils/machine_learning/confusion.py:300: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self._lr_plus = self.tpr / self.fpr\n",
      "/tmp/ipykernel_3260006/3332066588.py:51: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  sumdf.to_excel(os.path.join(classification_tables_path, f'{subject_name}_{classification}_summary.xls'))\n",
      "/tmp/ipykernel_3260006/3332066588.py:52: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  confdf.to_excel(os.path.join(classification_tables_path, f'{subject_name}_{classification}_confusion.xls'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Source/perf_tables/Ku_EL_09/B1-B8_LFRNN/Ku_EL_09_RM&RI_vs_LM&LI_summary.xls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/Projects/FingerMovementDecoder/utils/machine_learning/confusion.py:300: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self._lr_plus = self.tpr / self.fpr\n",
      "/home/user/Projects/FingerMovementDecoder/utils/machine_learning/confusion.py:302: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self._dor = self.lr_plus / self.lr_minus\n",
      "/home/user/Projects/FingerMovementDecoder/utils/machine_learning/confusion.py:300: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self._lr_plus = self.tpr / self.fpr\n",
      "/home/user/Projects/FingerMovementDecoder/utils/machine_learning/confusion.py:302: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self._dor = self.lr_plus / self.lr_minus\n",
      "/home/user/Projects/FingerMovementDecoder/utils/machine_learning/confusion.py:300: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self._lr_plus = self.tpr / self.fpr\n",
      "/home/user/Projects/FingerMovementDecoder/utils/machine_learning/confusion.py:302: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self._dor = self.lr_plus / self.lr_minus\n",
      "/tmp/ipykernel_3260006/3332066588.py:51: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  sumdf.to_excel(os.path.join(classification_tables_path, f'{subject_name}_{classification}_summary.xls'))\n",
      "/tmp/ipykernel_3260006/3332066588.py:52: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  confdf.to_excel(os.path.join(classification_tables_path, f'{subject_name}_{classification}_confusion.xls'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Source/perf_tables/Pr_An_04/B1-B8_LFRNN/Pr_An_04_RM&RI_vs_LM&LI_summary.xls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3260006/3332066588.py:51: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  sumdf.to_excel(os.path.join(classification_tables_path, f'{subject_name}_{classification}_summary.xls'))\n",
      "/tmp/ipykernel_3260006/3332066588.py:52: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  confdf.to_excel(os.path.join(classification_tables_path, f'{subject_name}_{classification}_confusion.xls'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Source/perf_tables/Ru_Ek_07/B1-B8_LFRNN/Ru_Ek_07_RM&RI_vs_LM&LI_summary.xls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3260006/3332066588.py:51: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  sumdf.to_excel(os.path.join(classification_tables_path, f'{subject_name}_{classification}_summary.xls'))\n",
      "/tmp/ipykernel_3260006/3332066588.py:52: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  confdf.to_excel(os.path.join(classification_tables_path, f'{subject_name}_{classification}_confusion.xls'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Source/perf_tables/Se_Tu_03/B1-B8_LFRNN/Se_Tu_03_RM&RI_vs_LM&LI_summary.xls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3260006/3332066588.py:51: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  sumdf.to_excel(os.path.join(classification_tables_path, f'{subject_name}_{classification}_summary.xls'))\n",
      "/tmp/ipykernel_3260006/3332066588.py:52: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  confdf.to_excel(os.path.join(classification_tables_path, f'{subject_name}_{classification}_confusion.xls'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Source/perf_tables/Te_Ali_11/B1-B8_LFRNN/Te_Ali_11_RM&RI_vs_LM&LI_summary.xls\n",
      "../Source/perf_tables/Pse_Udo/B1-B8_LFRNN/Pse_Udo_RM&RI_vs_LM&LI_summary.xls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3260006/3332066588.py:51: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  sumdf.to_excel(os.path.join(classification_tables_path, f'{subject_name}_{classification}_summary.xls'))\n",
      "/tmp/ipykernel_3260006/3332066588.py:52: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  confdf.to_excel(os.path.join(classification_tables_path, f'{subject_name}_{classification}_confusion.xls'))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "perf_tables_path = '../Source/perf_tables/'\n",
    "from utils.storage_management import check_path\n",
    "postfix = 'B1-B8_LFRNN'\n",
    "check_path(perf_tables_path)\n",
    "\n",
    "for subject_name in os.listdir(f'../Source/Subjects/'):\n",
    "    \n",
    "    subject_perf_tables_path = os.path.join(perf_tables_path, subject_name)\n",
    "    check_path(subject_perf_tables_path)\n",
    "\n",
    "    path = f'../Source/Subjects/{subject_name}/LFRNN'\n",
    "\n",
    "    classification_tables_path = os.path.join(subject_perf_tables_path, f'{postfix}')\n",
    "    check_path(classification_tables_path)\n",
    "    \n",
    "    sumdf = pd.DataFrame()\n",
    "    confdf = pd.DataFrame()\n",
    "    for classification in [\n",
    "        'RM_vs_RI_vs_LM_vs_LI',\n",
    "        'RM_vs_RI',\n",
    "        'LM_vs_LI',\n",
    "        'RM&RI_vs_LM&LI'\n",
    "    ]:\n",
    "        file_name = f'{classification}_{postfix}_pred.pkl'\n",
    "        class_names = classification.split('_vs_')\n",
    "\n",
    "        try:\n",
    "            predictions = read_pkl(\n",
    "                os.path.join(path, 'Predictions', file_name)\n",
    "            )\n",
    "        except FileNotFoundError:\n",
    "            warn(f'File does not exist: {os.path.join(path, \"Predictions\", file_name)}')\n",
    "            continue\n",
    "        pp = PredictionsParser(predictions.y_true, predictions.y_p, class_names)\n",
    "        \n",
    "        sumdf = pd.concat([\n",
    "                sumdf,\n",
    "                pp.summary(),\n",
    "                pd.DataFrame([None for _ in range(pp.summary().shape[0])], index=pp.summary().index),\n",
    "            ],\n",
    "            axis=1\n",
    "        )\n",
    "        confdf = pd.concat([\n",
    "                confdf,\n",
    "                pp.confusion,\n",
    "                # pd.DataFrame([None for _ in range(pp.confusion.shape[0])], index=pp.confusion.index),\n",
    "                pd.DataFrame(list(confdf.index), index=confdf.index),\n",
    "            ],\n",
    "            axis=1\n",
    "        )\n",
    "    sumdf.to_excel(os.path.join(classification_tables_path, f'{subject_name}_{classification}_summary.xls'))\n",
    "    confdf.to_excel(os.path.join(classification_tables_path, f'{subject_name}_{classification}_confusion.xls'))\n",
    "    print(os.path.join(classification_tables_path, f'{subject_name}_{classification}_summary.xls'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/Projects/FingerMovementDecoder/utils/machine_learning/confusion.py:300: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self._lr_plus = self.tpr / self.fpr\n",
      "/home/user/Projects/FingerMovementDecoder/utils/machine_learning/confusion.py:300: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self._lr_plus = self.tpr / self.fpr\n",
      "/home/user/Projects/FingerMovementDecoder/utils/machine_learning/confusion.py:300: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self._lr_plus = self.tpr / self.fpr\n",
      "/home/user/Projects/FingerMovementDecoder/utils/machine_learning/confusion.py:300: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self._lr_plus = self.tpr / self.fpr\n",
      "/home/user/Projects/FingerMovementDecoder/utils/machine_learning/confusion.py:300: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self._lr_plus = self.tpr / self.fpr\n",
      "/home/user/Projects/FingerMovementDecoder/utils/machine_learning/confusion.py:302: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self._dor = self.lr_plus / self.lr_minus\n",
      "/tmp/ipykernel_3260006/913632873.py:57: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  sumdf.to_excel(\n",
      "/tmp/ipykernel_3260006/913632873.py:60: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  confdf.to_excel(os.path.join(classification_tables_path, f'group_{classification}_confusion.xls'))\n"
     ]
    }
   ],
   "source": [
    "from utils.storage_management import check_path\n",
    "perf_tables_path = '../Source/perf_tables/LFRNN'\n",
    "check_path(perf_tables_path)\n",
    "from utils.storage_management import check_path\n",
    "postfix = 'B1-B8_LFRNN'\n",
    "group_tables_path = os.path.join(perf_tables_path, 'Group')\n",
    "check_path(group_tables_path)\n",
    "classification_tables_path = os.path.join(group_tables_path, postfix)\n",
    "check_path(perf_tables_path, group_tables_path, classification_tables_path)\n",
    "\n",
    "sumdf = pd.DataFrame()\n",
    "confdf = pd.DataFrame()\n",
    "for classification in [\n",
    "        'RM_vs_RI_vs_LM_vs_LI',\n",
    "        'RM_vs_RI',\n",
    "        'LM_vs_LI',\n",
    "        'RM&RI_vs_LM&LI'\n",
    "    ]:\n",
    "    conf = list()\n",
    "    summary = list()\n",
    "    for subject_name in os.listdir(f'../Source/Subjects/'):\n",
    "        path = f'../Source/Subjects/{subject_name}/LFRNN'\n",
    "        check_path(path)\n",
    "        \n",
    "        file_name = f'{classification}_{postfix}_pred.pkl'\n",
    "        class_names = classification.split('_vs_')\n",
    "\n",
    "        try:\n",
    "            predictions = read_pkl(\n",
    "                os.path.join(path, 'Predictions', file_name)\n",
    "            )\n",
    "        except FileNotFoundError:\n",
    "            warn(f'File does not exist: {os.path.join(path, \"Predictions\", file_name)}')\n",
    "            continue\n",
    "        pp = PredictionsParser(predictions.y_true, predictions.y_p, class_names)\n",
    "        conf.append(pp.confusion)\n",
    "        summary.append(pp.summary())\n",
    "    \n",
    "    index, columns = summary[0].index, summary[0].columns\n",
    "    data = np.array([c.to_numpy() for c in summary]).mean(0)\n",
    "    local_summary = pd.DataFrame(data, index=index, columns=columns)\n",
    "    sumdf = pd.concat([\n",
    "        sumdf,\n",
    "        local_summary,\n",
    "        pd.DataFrame([None for _ in range(local_summary.shape[0])], index=local_summary.index),\n",
    "    ], axis=1)\n",
    "    \n",
    "    index, columns = conf[0].index, conf[0].columns\n",
    "    data = np.array([s.to_numpy() for s in conf]).mean(0)\n",
    "    local_conf = pd.DataFrame(data, index=index, columns=columns)\n",
    "    confdf = pd.concat([\n",
    "        confdf,\n",
    "        local_conf,\n",
    "        pd.DataFrame(list(local_conf.index), index=local_conf.index),\n",
    "    ], axis=1)\n",
    "\n",
    "sumdf.to_excel(\n",
    "    os.path.join(classification_tables_path, f'group_{classification}_summary.xls')\n",
    ")\n",
    "confdf.to_excel(os.path.join(classification_tables_path, f'group_{classification}_confusion.xls'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ga_Fed_06\n",
      "Total accuracy:  0.55\n",
      "                LM     LI     RM    RI\n",
      "Total        16.00  12.00  16.00  9.00\n",
      "Accuracy      0.77   0.77   0.77  0.77\n",
      "Specificity   0.84   0.89   0.80  0.86\n",
      "Sensitivity   0.62   0.50   0.67  0.33\n",
      "           Predicted LM  Predicted LI  Predicted RM  Predicted RI\n",
      "Actual LM            10             4             1             1\n",
      "Actual LI             6             8             1             1\n",
      "Actual RM             0             0             8             4\n",
      "Actual RI             0             0             6             3\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Fe_To_08\n",
      "Total accuracy:  0.57\n",
      "                LM     LI     RM    RI\n",
      "Total        12.00  18.00  16.00  8.00\n",
      "Accuracy      0.78   0.76   0.80  0.81\n",
      "Specificity   0.92   0.78   0.81  0.93\n",
      "Sensitivity   0.50   0.69   0.73  0.42\n",
      "           Predicted LM  Predicted LI  Predicted RM  Predicted RI\n",
      "Actual LM             9             7             2             0\n",
      "Actual LI             2             9             1             1\n",
      "Actual RM             1             0             8             2\n",
      "Actual RI             0             2             5             5\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Az_Mar_05\n",
      "Total accuracy:  0.29\n",
      "                LM     LI     RM     RI\n",
      "Total        11.00  14.00  16.00  11.00\n",
      "Accuracy      0.60   0.60   0.71   0.67\n",
      "Specificity   0.76   0.70   0.78   0.82\n",
      "Sensitivity   0.14   0.11   0.53   0.29\n",
      "           Predicted LM  Predicted LI  Predicted RM  Predicted RI\n",
      "Actual LM             2             9             1             2\n",
      "Actual LI             2             1             3             3\n",
      "Actual RM             2             3             8             2\n",
      "Actual RI             5             1             4             4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ku_EL_09\n",
      "Total accuracy:  0.62\n",
      "                LM     LI    RM     RI\n",
      "Total        17.00  13.00  9.00  14.00\n",
      "Accuracy      0.89   0.79  0.74   0.83\n",
      "Specificity   0.89   0.84  0.94   0.84\n",
      "Sensitivity   0.87   0.60  0.37   0.78\n",
      "           Predicted LM  Predicted LI  Predicted RM  Predicted RI\n",
      "Actual LM            13             2             0             0\n",
      "Actual LI             3             6             0             1\n",
      "Actual RM             1             5             7             6\n",
      "Actual RI             0             0             2             7\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001b[93mWarning: Classes are inconsistent.\n",
      "\tActual classes: [0 1 2 3]\n",
      "\tPredicted classes: [0 1 2].\n",
      "Take actual classes\u001b[0m\n",
      "Pr_An_04\n",
      "Total accuracy:  0.49\n",
      "                LM     LI     RM    RI\n",
      "Total        13.00  17.00  23.00  0.00\n",
      "Accuracy      0.72   0.75   0.66  0.85\n",
      "Specificity   0.84   0.78   0.67  1.00\n",
      "Sensitivity   0.44   0.67   0.65  0.00\n",
      "           Predicted LM  Predicted LI  Predicted RM  Predicted RI\n",
      "Actual LM             7             5             4             0\n",
      "Actual LI             2             8             2             0\n",
      "Actual RM             3             3            11             0\n",
      "Actual RI             1             1             6             0\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ru_Ek_07\n",
      "Total accuracy:  0.62\n",
      "               LM     LI     RM     RI\n",
      "Total        9.00  10.00  20.00  13.00\n",
      "Accuracy     0.92   0.81   0.77   0.73\n",
      "Specificity  0.93   0.90   0.81   0.82\n",
      "Sensitivity  0.86   0.50   0.70   0.46\n",
      "           Predicted LM  Predicted LI  Predicted RM  Predicted RI\n",
      "Actual LM             6             1             0             0\n",
      "Actual LI             3             6             1             2\n",
      "Actual RM             0             1            14             5\n",
      "Actual RI             0             2             5             6\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Se_Tu_03\n",
      "Total accuracy:  0.50\n",
      "               LM     LI     RM    RI\n",
      "Total        5.00  21.00  22.00  8.00\n",
      "Accuracy     0.84   0.77   0.70  0.70\n",
      "Specificity  0.94   0.78   0.72  0.88\n",
      "Sensitivity  0.25   0.75   0.65  0.20\n",
      "           Predicted LM  Predicted LI  Predicted RM  Predicted RI\n",
      "Actual LM             2             6             0             0\n",
      "Actual LI             2            12             1             1\n",
      "Actual RM             1             1            11             4\n",
      "Actual RI             0             2            10             3\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Te_Ali_11\n",
      "Total accuracy:  0.45\n",
      "                LM    LI     RM     RI\n",
      "Total        12.00  8.00  22.00  11.00\n",
      "Accuracy      0.74  0.74   0.72   0.72\n",
      "Specificity   0.85  0.86   0.70   0.86\n",
      "Sensitivity   0.43  0.20   0.77   0.38\n",
      "           Predicted LM  Predicted LI  Predicted RM  Predicted RI\n",
      "Actual LM             6             4             3             1\n",
      "Actual LI             3             2             2             3\n",
      "Actual RM             0             2            10             1\n",
      "Actual RI             3             0             7             6\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19962/2523103007.py:30: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  if np.any(classes_true != classes_pred):\n",
      "/home/user/Projects/FingerMovementDecoder/utils/machine_learning/confusion.py:255: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  self._ppv = self.tp / (self.tp + self.fp)\n",
      "/home/user/Projects/FingerMovementDecoder/utils/machine_learning/confusion.py:263: RuntimeWarning: invalid value encountered in true_divide\n",
      "  self._mcc = (self.tp * self.tn - self.fp * self.fn) / \\\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "subjects_path = '../Source/Subjects/'\n",
    "file_name = 'LM_vs_LI_vs_RM_vs_RI_B1-B8_pred.pkl'\n",
    "# file_name = 'LM&LI_vs_RM&RI_B1-B8_pred.pkl'\n",
    "class_names = file_name[:-15].split('_vs_')\n",
    "\n",
    "for subject_name in os.listdir(subjects_path):\n",
    "    \n",
    "    if subject_name == 'Pse_Udo':\n",
    "        continue\n",
    "    \n",
    "    subject_path = os.path.join(subjects_path, subject_name)\n",
    "\n",
    "    predictions = read_pkl(\n",
    "        os.path.join(subject_path, 'Predictions', file_name)\n",
    "    )\n",
    "\n",
    "    pp = PredictionsParser(predictions.y_true, predictions.y_p, class_names)\n",
    "    print(subject_name)\n",
    "    print(f'Total accuracy: {pp.accuracy : .2f}')\n",
    "    summary = pp.summary()\n",
    "    summary = summary.astype(float).round(2)\n",
    "    print(summary)\n",
    "    print(pp.confusion)\n",
    "    print('-'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects_path = '../Source/Subjects/'\n",
    "# file_name = 'LM_vs_LI_vs_RM_vs_RI_B1-B8_pred.pkl'\n",
    "# file_name = 'LM&LI_vs_RM&RI_B1-B8_pred.pkl'\n",
    "file_name = 'LM_vs_LI_B1-B8_pred.pkl'\n",
    "class_names = file_name[:-15].split('_vs_')\n",
    "\n",
    "for subject_name in os.listdir(subjects_path):\n",
    "    \n",
    "    if subject_name == 'Pse_Udo':\n",
    "        continue\n",
    "    \n",
    "    subject_path = os.path.join(subjects_path, subject_name)\n",
    "\n",
    "    predictions = read_pkl(\n",
    "        os.path.join(subject_path, 'Predictions', file_name),\n",
    "    )\n",
    "\n",
    "    y_t = one_hot_decoder(predictions.y_true)\n",
    "\n",
    "    y_p = one_hot_decoder(predictions.y_p)\n",
    "\n",
    "    print(subject_name)\n",
    "    tn, fp, fn, tp = sm.confusion_matrix(y_t, y_p).ravel()\n",
    "    ce = ConfusionEstimator(tp, tn, fp, fn)\n",
    "\n",
    "    print(\n",
    "        f'\\tT\\tF\\n'\\\n",
    "        f'P\\t{tp}\\t{fp}\\n'\\\n",
    "        f'N\\t{tn}\\t{fn}\\n'\n",
    "        f'Accuracy: {ce.acc}\\n'\\\n",
    "        f'Specificity: {ce.spec}\\n'\\\n",
    "        f'Sensitivity: {ce.sens}\\n'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p-values for each subject and averages\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "\n",
    "DataContainer = namedtuple('DataContainer', 'data name title')\n",
    "\n",
    "for kind in ['fullrange', 'before', 'after']:\n",
    "    df_data = list()\n",
    "    for classification, title in zip(\n",
    "        [\n",
    "            'RM_vs_RI_vs_LM_vs_LI',\n",
    "            'RM&RI_vs_LM&LI',\n",
    "            'LM_vs_LI',\n",
    "            'RM_vs_RI'\n",
    "        ], [\n",
    "            '4 classes',\n",
    "            'Left vs Right',\n",
    "            'Within Left',\n",
    "            'Within Right'\n",
    "        ]\n",
    "    ):\n",
    "        order = list(it.product(['B1-B3', 'B10-B12'], repeat=2))\n",
    "        order[-1], order[-2] = order[-2], order[-1]\n",
    "        all_data = list()\n",
    "        for i, ((seq1, seq2), color) in enumerate(zip(order, ['blue', 'red', 'orange', 'green'])):\n",
    "            path = f'/home/user/Downloads/Pics/perf_tables_{kind}/{classification}_train_{seq1}_test_{seq2}_sep.csv'\n",
    "            df = pd.read_csv(path, index_col = 0)\n",
    "            subjects = set(df.index)\n",
    "            data = np.array([df.test_acc[f'{subject}'].to_numpy() for subject in subjects])\n",
    "            all_data.append(DataContainer(data, f'{seq1} : {seq2}', title))\n",
    "\n",
    "        data1, data2 = all_data[:2], all_data[2:]\n",
    "        for data in [data1, data2]:\n",
    "            name = f'{data[0].title} | {data[0].name} | {data[1].name}'\n",
    "            stat, pvals = sp.stats.ttest_rel(data[0].data, data[1].data, axis=1)\n",
    "            sdata = {\n",
    "                subject: p\n",
    "                for subject, p in zip(subjects, pvals)\n",
    "            }\n",
    "            stat, pval = sp.stats.ttest_rel(data[0].data.mean(1), data[1].data.mean(1))\n",
    "            sdata['Average'] = pval\n",
    "            df_data.append(pd.Series(sdata, name=name))\n",
    "    df = pd.DataFrame(df_data).T\n",
    "    df.to_excel(f'/home/user/Downloads/Pics/{kind}_output.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# violinplot for each classification accuracy to subject x sessions\n",
    "import itertools as it\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.lines as mlines\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "span = 1\n",
    "%matplotlib qt\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "\n",
    "def adjust_fig(fig):\n",
    "    fig['cmeans'].set_color('red')\n",
    "    fig['cbars'].set_edgecolor('gray')\n",
    "    fig['cbars'].set_alpha(.5)\n",
    "    fig['cbars'].set_linewidth(.8)\n",
    "    fig['cmaxes'].set_color('#042164')\n",
    "    fig['cmins'].set_color('#042164')\n",
    "    fig['cquantiles'].set_color('#EE550E')\n",
    "\n",
    "def plot_stars(n_subject, n_cap, n_stars, star_symbol='*'):\n",
    "    #? These numbers (9 and 4) are n_subjects & average, n_sessions\n",
    "    indices = [i for i in range(45) if (i+1)%5]\n",
    "    indices = np.reshape(indices, (9, 4))[:, 1:3]\n",
    "    index = indices[n_subject, n_cap]\n",
    "\n",
    "    # The numbers are hand-picked\n",
    "    if (n_cap+1)%2:\n",
    "        height = 1.08\n",
    "    else:\n",
    "        height = 1.19\n",
    "\n",
    "    if n_stars%2:\n",
    "        distances = [np.round((i-n_stars//2)*.4, 2) for i in range(n_stars)]\n",
    "    else:\n",
    "        distances = list(map(\n",
    "            lambda x: x[1] if x[0] >= n_stars//2 else -x[1],\n",
    "            enumerate(map(\n",
    "                lambda x: np.round(x*.4, 2) if x != 0 else .2,\n",
    "                [i for i in range(n_stars//2)][::-1] + list(range(n_stars//2))\n",
    "            ))\n",
    "        ))\n",
    "\n",
    "    for distance in distances:\n",
    "        plt.plot(index+distance, height, star_symbol, c='#1f77b4')\n",
    "\n",
    "# cross = plt.scatter([], [], 120, color='#1f77b4', marker='x', label='p ≥ 0.05')\n",
    "# star = plt.scatter([], [], 120, c='#1f77b4', marker='*', label='p < 0.05')\n",
    "# star2 = mlines.Line2D([], [], color='#1f77b4', marker='*', linestyle='None',\n",
    "#                          markersize=10, label='p < 0.01')\n",
    "\n",
    "for kind in ['before', 'fullrange', 'after']:\n",
    "    excel_file = f'/home/user/Downloads/Pics/{kind}_output.xlsx'\n",
    "    stat = pd.read_excel(excel_file, index_col=0)\n",
    "    # Simplified columns names to original ones\n",
    "    col_info = {\n",
    "        key: val\n",
    "        for key, val\n",
    "        in zip(\n",
    "            [tuple([\n",
    "                word.split(' : ')[0] for word in col.split(' | ')\n",
    "            ][:2]) for col in stat.columns],\n",
    "            stat.columns\n",
    "        )\n",
    "    }\n",
    "\n",
    "    for classification, title in zip(\n",
    "        [\n",
    "            'RM_vs_RI_vs_LM_vs_LI',\n",
    "            'RM&RI_vs_LM&LI',\n",
    "            'LM_vs_LI',\n",
    "            'RM_vs_RI'\n",
    "        ], [\n",
    "            '4 classes',\n",
    "            'Left vs Right',\n",
    "            'Within Left',\n",
    "            'Within Right'\n",
    "        ]\n",
    "    ):\n",
    "        # Limits to make a legend visible\n",
    "        #! When these limits are changed, all hand-picked values are changed\n",
    "        plt.ylim((0., 1.5))\n",
    "        plt.yticks(\n",
    "            [i/10 if i != 0 else 0 for i in range(0, 11, 2)],\n",
    "        )\n",
    "        plt.grid(True, axis='x', linewidth=100, alpha=.1)\n",
    "\n",
    "        # Iterate all sessions\n",
    "        order = list(it.product(['B1-B3', 'B10-B12'], repeat=2))\n",
    "        order[-1], order[-2] = order[-2], order[-1]\n",
    "\n",
    "        for i, ((seq1, seq2), color) in enumerate(zip(order, ['blue', 'red', 'orange', 'green'])):\n",
    "            if i%2:\n",
    "                # As tests are paired, only half of iterations is needed\n",
    "                stat_data = stat[col_info[(title, seq1)]]\n",
    "\n",
    "                for j, subject in enumerate(subjects):\n",
    "                    k = 0 if seq1 == 'B1-B3' else 1\n",
    "                    # print(title, subject, seq1, stat_data[subject], end=' ')\n",
    "\n",
    "                    if stat_data[subject] >= 0.05:\n",
    "                        plot_stars(j, k, 1, 'x')\n",
    "                        # print(f'plotting x at {k}')\n",
    "                    elif .01 <= stat_data[subject] < .05:\n",
    "                        plot_stars(j, k, 1)\n",
    "                        # print(f'plotting * at {k}')\n",
    "                    elif .001 <= stat_data[subject] < .01:\n",
    "                        plot_stars(j, k, 2)\n",
    "                        # print(f'plotting ** at {k}')\n",
    "                    elif stat_data[subject] < .001:\n",
    "                        plot_stars(j, k, 3)\n",
    "                        # print(f'plotting *** at {k}')\n",
    "\n",
    "            path = f'/home/user/Downloads/Pics/perf_tables_{kind}/{classification}_train_{seq1}_test_{seq2}_sep.csv'\n",
    "            df = pd.read_csv(path, index_col = 0)\n",
    "            subjects = set(df.index)\n",
    "            data = np.array([df.test_acc[f'{subject}'].to_numpy() for subject in subjects])\n",
    "            data = np.append(data, [data.mean(0)], axis = 0)\n",
    "            subjects = list(subjects) + ['Average']\n",
    "            # all indices of current session for all subjects\n",
    "            # without spaces between violenplots of different subjects\n",
    "            plane = np.array([i for i in range(len(subjects)*4) if not (i)%4])\n",
    "            fig = plt.violinplot(\n",
    "                data.T, plane + i + np.array(range(len(plane)))*span,\n",
    "                showmeans=True,\n",
    "                quantiles = [[0.25, 0.75] for _ in subjects]\n",
    "            )\n",
    "\n",
    "            # Set color in concordance with session\n",
    "            for i in range(len(subjects)):\n",
    "                fig['bodies'][i].set_facecolor(color)\n",
    "\n",
    "            adjust_fig(fig)\n",
    "\n",
    "        _ = plt.xticks(\n",
    "            plane + 1.5 + np.array(range(len(plane)))*span,\n",
    "            subjects,\n",
    "            rotation=30\n",
    "        )\n",
    "\n",
    "        fig = plt.gcf()\n",
    "        fig.set_size_inches(18.5, 10.5)\n",
    "        b = mpatches.Patch(color='blue', label='B1-B3 | B1-B3', alpha=.4)\n",
    "        r = mpatches.Patch(color='red', label='B1-B3 | B10-B12', alpha=.4)\n",
    "        o = mpatches.Patch(color='orange', label='B10-B12 | B10-B12', alpha=.4)\n",
    "        g = mpatches.Patch(color='green', label='B10-B12 | B1-B3', alpha=.4)\n",
    "        s = mpatches.Patch(color='#1f77b4', label='', alpha=0)\n",
    "        plt.legend(handles=[\n",
    "            b, r, o, g#, cross, star, star2\n",
    "        ], handlelength=1.25, numpoints=2, scatterpoints=1, loc='upper right', ncol=2)\n",
    "        plt.title(title)\n",
    "\n",
    "        # The numbers are hand-picked\n",
    "        start = .051\n",
    "        gap = .0209\n",
    "\n",
    "        for i in range(9):\n",
    "            #! the indexes were selected manually, correspond to the lines that require correction\n",
    "            if i in [1, 3, 5, 7, 8]:\n",
    "                plt.axhline(1.168, start + (5*i+1)*gap, start + (5*i+3)*gap-5e-4, linewidth=.5)\n",
    "                plt.axhline(1.055, start + 5*i*gap, start + (5*i+2)*gap-5e-4, linewidth=.5)\n",
    "            else:\n",
    "                plt.axhline(1.168, start + (5*i+1)*gap, start + (5*i+3)*gap, linewidth=.5)\n",
    "                plt.axhline(1.055, start + 5*i*gap, start + (5*i+2)*gap, linewidth=.5)\n",
    "\n",
    "        pair1, pair2 = True, False\n",
    "        # draw vertical lines\n",
    "        for i in range(5*9):\n",
    "            if (i+1)%5:\n",
    "                if pair1:\n",
    "                    pair1 = False\n",
    "                    pair2 = True\n",
    "                    plt.axvline(i, 0.678, .703, ls='--', linewidth=.75)\n",
    "                    continue\n",
    "                if pair2:\n",
    "                    pair2 = False\n",
    "                    pair1 = True\n",
    "                    plt.axvline(i, 0.753, .778, ls='--', linewidth=.75)\n",
    "\n",
    "        # plt.show()\n",
    "        plt.savefig(f'/home/user/Downloads/Pics/{kind}/{classification}.jpg', dpi=500)\n",
    "        plt.close()\n",
    "\n",
    "    images = [\n",
    "        Image.open(f'/home/user/Downloads/Pics/{kind}/' + f)\n",
    "        for f in os.listdir(f'/home/user/Downloads/Pics/{kind}')\n",
    "    ]\n",
    "    pdf_path = f'/home/user/Downloads/Pics/{kind}_output.pdf'\n",
    "    images[0].save(\n",
    "        pdf_path, \"PDF\", resolution=100.0, save_all=True, append_images=images[1:]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplots classification x sessions to average accuracy\n",
    "\n",
    "from collections import namedtuple\n",
    "import matplotlib.colors as mc\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "DataContainer = namedtuple('DataContainer', 'data name title')\n",
    "\n",
    "\n",
    "def rename_sessions(sessions):\n",
    "    out = list()\n",
    "    for session in sessions:\n",
    "        if session == 'B1-B3':\n",
    "            out.append('beginning')\n",
    "        elif session == 'B10-B12':\n",
    "            out.append('end')\n",
    "        else:\n",
    "            raise ValueError(f'Unknown session: {session}')\n",
    "    return ' : '.join(out)\n",
    "\n",
    "\n",
    "def plot_stars(n_box, n_stars, star_symbol='*', height=1.125):\n",
    "\n",
    "    if n_stars%2:\n",
    "        distances = [np.round((i-n_stars//2)*.4, 2) for i in range(n_stars)]\n",
    "    else:\n",
    "        distances = list(map(\n",
    "            lambda x: x[1] if x[0] >= n_stars//2 else -x[1],\n",
    "            enumerate(map(\n",
    "                lambda x: np.round(.2 + x*.4, 2) if x != 0 else .2,\n",
    "                [i for i in range(n_stars//2)][::-1] + list(range(n_stars//2))\n",
    "            ))\n",
    "        ))\n",
    "\n",
    "    n_box -= .5\n",
    "\n",
    "    for distance in distances:\n",
    "        plt.plot(n_box+distance, height, star_symbol, c='#1f77b4', ms=10)\n",
    "\n",
    "ymin, ymax = .35, 1.35\n",
    "diff=.35\n",
    "\n",
    "for kind in [\n",
    "    'before',\n",
    "    'fullrange',\n",
    "    'after'\n",
    "]:\n",
    "    excel_file = f'/home/user/Downloads/Pics/{kind}_output.xlsx'\n",
    "    stat = pd.read_excel(excel_file, index_col=0)\n",
    "    col_info = {\n",
    "        key: val\n",
    "        for key, val\n",
    "        in zip(\n",
    "            [tuple([\n",
    "                word.split(' : ')[0] for word in col.split(' | ')\n",
    "            ][:2]) for col in stat.columns],\n",
    "            stat.columns\n",
    "        )\n",
    "    }\n",
    "    all_data = list()\n",
    "    all_titles = list()\n",
    "    all_stats = list()\n",
    "    for classification, title in zip(\n",
    "        [\n",
    "            'RM_vs_RI_vs_LM_vs_LI',\n",
    "            'RM&RI_vs_LM&LI',\n",
    "            'LM_vs_LI',\n",
    "            'RM_vs_RI'\n",
    "        ], [\n",
    "            '4 classes',\n",
    "            'Left vs Right',\n",
    "            'Within Left',\n",
    "            'Within Right'\n",
    "        ]\n",
    "    ):\n",
    "        for i, ((seq1, seq2), color) in enumerate(zip(order, ['blue', 'red', 'orange', 'green'])):\n",
    "            if i%2:\n",
    "                all_stats.append(stat[col_info[(title, seq1)]]['Average'])\n",
    "            path = f'/home/user/Downloads/Pics/perf_tables_{kind}/{classification}_train_{seq1}_test_{seq2}_sep.csv'\n",
    "            df = pd.read_csv(path, index_col = 0)\n",
    "            data = [df['test_acc'][subject].mean() for subject in set(df['test_acc'].index)]\n",
    "            all_data.append(data)\n",
    "            all_titles.append(title)\n",
    "\n",
    "    names = list(map(\n",
    "        rename_sessions,\n",
    "        order\n",
    "    ))\n",
    "    indices = [i for i in range(len(all_data) + len(all_data)//5) if (i+1)%5]\n",
    "    for i, data in enumerate(all_data):\n",
    "        q1 = np.percentile(data, 25)\n",
    "        q3 = np.percentile(data, 75)\n",
    "        iqr = q3 - q1\n",
    "        p1 = min(\n",
    "            filter(\n",
    "                lambda datum: q1-1.5*iqr <= datum <= q1,\n",
    "                data\n",
    "            )\n",
    "        )\n",
    "        p2 = max(\n",
    "            filter(\n",
    "                lambda datum: q3 <= datum <= q3+1.5*iqr,\n",
    "                data\n",
    "            )\n",
    "        )\n",
    "        # .4 is min ylim\n",
    "        plt.axvline(indices[i], p2-diff+.05, 1.1-diff, linewidth=1, color='#aaa')\n",
    "\n",
    "        if i%2:\n",
    "            if all_stats[i//2] >= .05:\n",
    "                plot_stars(indices[i], 1, 'x')\n",
    "            if .01 <= all_stats[i//2] < .05:\n",
    "                plot_stars(indices[i], 1, '*')\n",
    "            if .001 <= all_stats[i//2] < .01:\n",
    "                plot_stars(indices[i], 2, '*')\n",
    "            if all_stats[i//2] < .001:\n",
    "                plot_stars(indices[i], 3, '*')\n",
    "\n",
    "            plt.axhline(1.1, indices[i]*0.05, (indices[i]+1)*0.05, linewidth=1, color='#aaa')\n",
    "\n",
    "    boxplot = plt.boxplot(all_data, positions=indices, showfliers=False, patch_artist=True)\n",
    "    color = '#aaa'\n",
    "    width = 1\n",
    "\n",
    "    colorconfig = {\n",
    "        session: color\n",
    "        for session, color in zip(\n",
    "            names,\n",
    "            [mc.to_rgba('blue', .25), mc.to_rgba('red', .25), mc.to_rgba('yellow', .25), mc.to_rgba('green', .25)]\n",
    "        )\n",
    "    }\n",
    "\n",
    "    for i, box in enumerate(boxplot['boxes']):\n",
    "        box.set_facecolor(colorconfig[names[i%len(names)]])\n",
    "        box.set_linewidth(0)\n",
    "    for box in boxplot['caps']:\n",
    "        box.set_color(color)\n",
    "        box.set_linewidth(width*1.5)\n",
    "    for box in boxplot['whiskers']:\n",
    "        box.set_color(color)\n",
    "        box.set_linewidth(width)\n",
    "        box.set_linestyle('--')\n",
    "    for box in boxplot['medians']:\n",
    "        box.set_color('#FF1E0F')\n",
    "        box.set_linewidth(width*1.25)\n",
    "        box.set_alpha(.75)\n",
    "\n",
    "    middles = [index-1.5 for i, index in enumerate(indices) if not (i+1)%4]\n",
    "    _ = plt.xticks(\n",
    "        middles,\n",
    "        [title for i, title in enumerate(all_titles) if not (i+1)%4],\n",
    "        rotation=30\n",
    "    )\n",
    "    # plt.yticks([.5, .6, .7, .8, .9, 1.])\n",
    "\n",
    "    for i in middles:\n",
    "        plt.axvline(i, 0, 1, c='gray', alpha=.1, linewidth=200)\n",
    "\n",
    "    plt.xlim(-1, indices[-1]+1)\n",
    "    plt.ylim(ymin, ymax)\n",
    "\n",
    "    b = mpatches.Patch(facecolor=mc.to_rgba('blue', .4), label='B1-B3 | B1-B3', edgecolor=mc.to_rgba('blue', .6))\n",
    "    r = mpatches.Patch(facecolor=mc.to_rgba('red', .4), label='B1-B3 | B10-B12', edgecolor=mc.to_rgba('red', .6))\n",
    "    o = mpatches.Patch(facecolor=mc.to_rgba('yellow', .4), label='B10-B12 | B10-B12', edgecolor=mc.to_rgba('#cccc00', .6))\n",
    "    g = mpatches.Patch(facecolor=mc.to_rgba('green', .4), label='B10-B12 | B1-B3', edgecolor=mc.to_rgba('green', .6))\n",
    "\n",
    "    plt.legend(handles=[b, r, o, g], ncol=2, loc='upper right')\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(18.5, 10.5)\n",
    "    # plt.show()\n",
    "    plt.savefig(f'/home/user/Downloads/Pics/{kind}_boxplot.jpg', dpi=500)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>3.0</th>\n",
       "      <th>4.0</th>\n",
       "      <th>5.0</th>\n",
       "      <th>6.0</th>\n",
       "      <th>7.0</th>\n",
       "      <th>8.0</th>\n",
       "      <th>9.0</th>\n",
       "      <th>10.0</th>\n",
       "      <th>11.0</th>\n",
       "      <th>12.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sub_Code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Se_Tu</th>\n",
       "      <td>329.550000</td>\n",
       "      <td>313.125000</td>\n",
       "      <td>316.683333</td>\n",
       "      <td>310.500000</td>\n",
       "      <td>316.883333</td>\n",
       "      <td>306.316667</td>\n",
       "      <td>300.383333</td>\n",
       "      <td>273.633333</td>\n",
       "      <td>245.166667</td>\n",
       "      <td>241.141667</td>\n",
       "      <td>233.858333</td>\n",
       "      <td>209.175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pr_An</th>\n",
       "      <td>453.450000</td>\n",
       "      <td>361.908333</td>\n",
       "      <td>389.025000</td>\n",
       "      <td>375.975000</td>\n",
       "      <td>350.641667</td>\n",
       "      <td>387.283333</td>\n",
       "      <td>350.766667</td>\n",
       "      <td>385.533333</td>\n",
       "      <td>374.391667</td>\n",
       "      <td>365.208333</td>\n",
       "      <td>334.458333</td>\n",
       "      <td>325.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Az_Mar</th>\n",
       "      <td>383.275000</td>\n",
       "      <td>419.875000</td>\n",
       "      <td>429.658333</td>\n",
       "      <td>386.533333</td>\n",
       "      <td>389.433333</td>\n",
       "      <td>373.075000</td>\n",
       "      <td>360.191667</td>\n",
       "      <td>364.983333</td>\n",
       "      <td>346.816667</td>\n",
       "      <td>365.841667</td>\n",
       "      <td>352.008333</td>\n",
       "      <td>360.275000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ga_Fed</th>\n",
       "      <td>347.933333</td>\n",
       "      <td>320.925000</td>\n",
       "      <td>335.358333</td>\n",
       "      <td>301.900000</td>\n",
       "      <td>326.066667</td>\n",
       "      <td>304.866667</td>\n",
       "      <td>285.308333</td>\n",
       "      <td>285.033333</td>\n",
       "      <td>275.358333</td>\n",
       "      <td>299.800000</td>\n",
       "      <td>308.500000</td>\n",
       "      <td>288.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ru_Ek</th>\n",
       "      <td>303.416667</td>\n",
       "      <td>279.158333</td>\n",
       "      <td>282.275000</td>\n",
       "      <td>313.775000</td>\n",
       "      <td>293.916667</td>\n",
       "      <td>281.725000</td>\n",
       "      <td>266.008333</td>\n",
       "      <td>264.316667</td>\n",
       "      <td>281.441667</td>\n",
       "      <td>263.225000</td>\n",
       "      <td>264.733333</td>\n",
       "      <td>265.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fe_To</th>\n",
       "      <td>443.783333</td>\n",
       "      <td>421.358333</td>\n",
       "      <td>415.791667</td>\n",
       "      <td>388.650000</td>\n",
       "      <td>386.975000</td>\n",
       "      <td>326.383333</td>\n",
       "      <td>416.600000</td>\n",
       "      <td>312.108333</td>\n",
       "      <td>337.000000</td>\n",
       "      <td>337.900000</td>\n",
       "      <td>265.375000</td>\n",
       "      <td>157.183333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ku_El</th>\n",
       "      <td>337.150000</td>\n",
       "      <td>300.308333</td>\n",
       "      <td>282.141667</td>\n",
       "      <td>285.700000</td>\n",
       "      <td>277.658333</td>\n",
       "      <td>276.116667</td>\n",
       "      <td>280.841667</td>\n",
       "      <td>285.350000</td>\n",
       "      <td>269.658333</td>\n",
       "      <td>270.616667</td>\n",
       "      <td>276.433333</td>\n",
       "      <td>273.241667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Te_Ali</th>\n",
       "      <td>348.258333</td>\n",
       "      <td>315.658333</td>\n",
       "      <td>300.450000</td>\n",
       "      <td>314.516667</td>\n",
       "      <td>317.300000</td>\n",
       "      <td>301.083333</td>\n",
       "      <td>301.241667</td>\n",
       "      <td>299.758333</td>\n",
       "      <td>297.083333</td>\n",
       "      <td>304.366667</td>\n",
       "      <td>309.908333</td>\n",
       "      <td>302.150000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 1.0         2.0         3.0         4.0         5.0  \\\n",
       "Sub_Code                                                               \n",
       "Se_Tu     329.550000  313.125000  316.683333  310.500000  316.883333   \n",
       "Pr_An     453.450000  361.908333  389.025000  375.975000  350.641667   \n",
       "Az_Mar    383.275000  419.875000  429.658333  386.533333  389.433333   \n",
       "Ga_Fed    347.933333  320.925000  335.358333  301.900000  326.066667   \n",
       "Ru_Ek     303.416667  279.158333  282.275000  313.775000  293.916667   \n",
       "Fe_To     443.783333  421.358333  415.791667  388.650000  386.975000   \n",
       "Ku_El     337.150000  300.308333  282.141667  285.700000  277.658333   \n",
       "Te_Ali    348.258333  315.658333  300.450000  314.516667  317.300000   \n",
       "\n",
       "                 6.0         7.0         8.0         9.0        10.0  \\\n",
       "Sub_Code                                                               \n",
       "Se_Tu     306.316667  300.383333  273.633333  245.166667  241.141667   \n",
       "Pr_An     387.283333  350.766667  385.533333  374.391667  365.208333   \n",
       "Az_Mar    373.075000  360.191667  364.983333  346.816667  365.841667   \n",
       "Ga_Fed    304.866667  285.308333  285.033333  275.358333  299.800000   \n",
       "Ru_Ek     281.725000  266.008333  264.316667  281.441667  263.225000   \n",
       "Fe_To     326.383333  416.600000  312.108333  337.000000  337.900000   \n",
       "Ku_El     276.116667  280.841667  285.350000  269.658333  270.616667   \n",
       "Te_Ali    301.083333  301.241667  299.758333  297.083333  304.366667   \n",
       "\n",
       "                11.0        12.0  \n",
       "Sub_Code                          \n",
       "Se_Tu     233.858333  209.175000  \n",
       "Pr_An     334.458333  325.166667  \n",
       "Az_Mar    352.008333  360.275000  \n",
       "Ga_Fed    308.500000  288.066667  \n",
       "Ru_Ek     264.733333  265.625000  \n",
       "Fe_To     265.375000  157.183333  \n",
       "Ku_El     276.433333  273.241667  \n",
       "Te_Ali    309.908333  302.150000  "
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/home/user/Downloads/sdata/MEG_SRTT_RT.xlsx'\n",
    "df = pd.read_excel(path, index_col=1)\n",
    "# df.drop('No.', axis=1)\n",
    "for index in df.columns:\n",
    "    if not isinstance(index, float) or index > 12:\n",
    "        df.drop(index, axis=1, inplace=True)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "25b6c1d617e3cb25e4067864bcd46322e1b7da41afdae0cf7c23b941b0b9b767"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
