{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-07 15:30:42.784219: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-07 15:30:42.784251: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import sys\n",
    "import os\n",
    "current_dir = os.path.dirname(os.path.abspath('./'))\n",
    "if not current_dir in sys.path:\n",
    "    sys.path.append(current_dir)\n",
    "    \n",
    "from utils.structures import Pipeline, Deploy\n",
    "from utils.data_management import dict2str\n",
    "from utils.machine_learning import one_hot_encoder, one_hot_decoder\n",
    "from typing import *\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import make_classification\n",
    "import mne\n",
    "from combiners import EpochsCombiner\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from utils.machine_learning.designer import ModelDesign, ParallelDesign, LayerDesign\n",
    "from utils.machine_learning.analyzer import ModelAnalyzer, LFCNNAnalyzer\n",
    "from mne.datasets import multimodal\n",
    "import sklearn\n",
    "import mneflow as mf\n",
    "import tensorflow as tf\n",
    "from mneflow.layers import DeMixing, LFTConv, TempPooling, Dense\n",
    "\n",
    "# %matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne.set_log_level(verbose='CRITICAL')\n",
    "fname_raw = os.path.join(multimodal.data_path(), 'multimodal_raw.fif')\n",
    "raw = mne.io.read_raw_fif(fname_raw)\n",
    "cond = raw.acqparser.get_condition(raw, None)\n",
    "condition_names = [k for c in cond for k,v in c['event_id'].items()]\n",
    "epochs_list = [mne.Epochs(raw, **c) for c in cond]\n",
    "epochs = mne.concatenate_epochs(epochs_list)\n",
    "epochs = epochs.pick_types(meg='grad')\n",
    "X = np.array([])\n",
    "Y = list()\n",
    "for i, epochs in enumerate(epochs_list):\n",
    "    data = epochs.get_data()\n",
    "    if i == 0:\n",
    "        X = data.copy()\n",
    "    else:\n",
    "        X = np.append(X, data, axis=0)\n",
    "    Y += [i for _ in range(data.shape[0])]\n",
    "\n",
    "Y = np.array(Y)\n",
    "X = np.array([X[i, epochs._channel_type_idx['grad'], :] for i, _ in enumerate(X)])\n",
    "original_X = X.copy()\n",
    "original_Y = Y.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = original_Y.copy()\n",
    "Y = one_hot_encoder(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(940, 1, 361, 204)\n"
     ]
    }
   ],
   "source": [
    "X = original_X.copy()\n",
    "X = np.transpose(np.expand_dims(X, axis = 1), (0, 1, 3, 2))\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape:  (None, 1, 361, 204)\n",
      "Setting reg for dmx, to l1\n",
      "Built: dmx input: (None, 1, 361, 204)\n",
      "Setting reg for tconv, to l1\n",
      "Built: tconv input: (None, 1, 361, 32)\n",
      "Setting reg for fc, to l1\n",
      "Built: fc input: (None, 1, 37, 32)\n",
      "output shape:  (None, 8)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "specs = dict()\n",
    "specs.setdefault('filter_length', 7)\n",
    "specs.setdefault('n_latent', 32)\n",
    "specs.setdefault('pooling', 2)\n",
    "specs.setdefault('stride', 2)\n",
    "specs.setdefault('padding', 'SAME')\n",
    "specs.setdefault('pool_type', 'max')\n",
    "specs.setdefault('nonlin', tf.nn.relu)\n",
    "specs.setdefault('l1', 3e-4)\n",
    "specs.setdefault('l2', 0)\n",
    "# specs.setdefault('l1_scope', ['fc', 'demix', 'lf_conv'])\n",
    "specs.setdefault('l1_scope', ['fc', 'dmx', 'tconv', 'fc'])\n",
    "specs.setdefault('l2_scope', [])\n",
    "specs.setdefault('maxnorm_scope', [])\n",
    "specs.setdefault('dropout', .5)\n",
    "\n",
    "# n_latent=32,\n",
    "# filter_length=17,\n",
    "# nonlin = tf.nn.relu,\n",
    "# padding = 'SAME',\n",
    "# pooling = 5,\n",
    "# stride = 5,\n",
    "# pool_type='max',\n",
    "# dropout = .5,\n",
    "# l1_scope = [\"weights\"],\n",
    "# l1=3e-3\n",
    "\n",
    "specs['filter_length'] = 17\n",
    "specs['pooling'] = 5\n",
    "specs['stride'] = 5\n",
    "specs['l1'] = 3e-3\n",
    "\n",
    "\n",
    "out_dim = len(np.unique(original_Y))\n",
    "\n",
    "n_samples, _, n_times, n_channels = X.shape\n",
    "\n",
    "inputs = tf.keras.Input(shape=(1, n_times, n_channels))\n",
    "print('input shape: ', inputs.shape)\n",
    "\n",
    "dmx = DeMixing(size=specs['n_latent'], nonlin=tf.identity,\n",
    "                            axis=3, specs=specs)\n",
    "dmx_out = dmx(inputs)\n",
    "\n",
    "tconv = LFTConv(size=specs['n_latent'],\n",
    "                        nonlin=specs['nonlin'],\n",
    "                        filter_length=specs['filter_length'],\n",
    "                        padding=specs['padding'],\n",
    "                        specs=specs\n",
    "                        )\n",
    "tconv_out = tconv(dmx_out)\n",
    "\n",
    "pool = TempPooling(pooling=specs['pooling'],\n",
    "                            pool_type=specs['pool_type'],\n",
    "                            stride=specs['stride'],\n",
    "                            padding=specs['padding'],\n",
    "                            )\n",
    "pooled = pool(tconv_out)\n",
    "\n",
    "dropout = tf.keras.layers.Dropout(specs['dropout'],\n",
    "                    noise_shape=None)(pooled)\n",
    "\n",
    "fin_fc = Dense(size=out_dim, nonlin=tf.identity,\n",
    "                    specs=specs)\n",
    "\n",
    "y_pred = fin_fc(dropout)\n",
    "\n",
    "print('output shape: ', y_pred.shape)\n",
    "\n",
    "km = tf.keras.Model(inputs=inputs, outputs=y_pred)\n",
    "\n",
    "optimizer=\"adam\"\n",
    "learn_rate=3e-4\n",
    "params = {\"optimizer\": tf.optimizers.get(optimizer).from_config({\"learning_rate\":learn_rate})}\n",
    "params.setdefault(\"loss\", tf.nn.softmax_cross_entropy_with_logits)\n",
    "params.setdefault(\"metrics\", tf.keras.metrics.CategoricalAccuracy(name=\"cat_ACC\"))\n",
    "\n",
    "km.compile(optimizer=params[\"optimizer\"],\n",
    "                loss=params[\"loss\"],\n",
    "                metrics=params[\"metrics\"])\n",
    "\n",
    "\n",
    "# Setting reg for dmx, to l1\n",
    "# Built: dmx input: (None, 1, 361, 204)\n",
    "# Setting reg for tconv, to l1\n",
    "# Built: tconv input: (None, 1, 361, 32)\n",
    "# Setting reg for fc, to l1\n",
    "# Built: fc input: (None, 1, 37, 32)\n",
    "# Input shape: (1, 361, 204)\n",
    "# y_pred: (None, 8)\n",
    "# Initialization complete!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting reg for fc, to l1\n",
      "input:  (1, 361, 204)\n",
      "Setting reg for tconv, to l1\n",
      "Built: tconv input: (None, 1, 361, 32)\n",
      "Built: fc input: (None, 1, 37, 32)\n",
      "(None, 8)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "specs = dict()\n",
    "specs.setdefault('filter_length', 7)\n",
    "specs.setdefault('n_latent', 32)\n",
    "specs.setdefault('pooling', 2)\n",
    "specs.setdefault('stride', 2)\n",
    "specs.setdefault('padding', 'SAME')\n",
    "specs.setdefault('pool_type', 'max')\n",
    "specs.setdefault('nonlin', tf.nn.relu)\n",
    "specs.setdefault('l1', 3e-4)\n",
    "specs.setdefault('l2', 0)\n",
    "# specs.setdefault('l1_scope', ['fc', 'demix', 'lf_conv'])\n",
    "specs.setdefault('l1_scope', ['fc', 'dmx', 'tconv', 'fc'])\n",
    "specs.setdefault('l2_scope', [])\n",
    "specs.setdefault('maxnorm_scope', [])\n",
    "specs.setdefault('dropout', .5)\n",
    "\n",
    "# n_latent=32,\n",
    "# filter_length=17,\n",
    "# nonlin = tf.nn.relu,\n",
    "# padding = 'SAME',\n",
    "# pooling = 5,\n",
    "# stride = 5,\n",
    "# pool_type='max',\n",
    "# dropout = .5,\n",
    "# l1_scope = [\"weights\"],\n",
    "# l1=3e-3\n",
    "\n",
    "specs['filter_length'] = 17\n",
    "specs['pooling'] = 5\n",
    "specs['stride'] = 5\n",
    "specs['l1'] = 3e-3\n",
    "\n",
    "\n",
    "out_dim = len(np.unique(original_Y))\n",
    "\n",
    "n_samples, _, n_times, n_channels = X.shape\n",
    "\n",
    "inputs = tf.keras.Input(shape=(1, n_times, n_channels))\n",
    "\n",
    "# kmd = ModelDesign(\n",
    "#     tf.keras.Input(shape=(1, n_times, n_channels)),\n",
    "#     DeMixing(size=specs['n_latent'], nonlin=tf.identity, axis=3, specs=specs),\n",
    "#     LFTConv(\n",
    "#         size=specs['n_latent'],\n",
    "#         nonlin=specs['nonlin'],\n",
    "#         filter_length=specs['filter_length'],\n",
    "#         padding=specs['padding'],\n",
    "#         specs=specs\n",
    "#     ),\n",
    "#     TempPooling(\n",
    "#         pooling=specs['pooling'],\n",
    "#         pool_type=specs['pool_type'],\n",
    "#         stride=specs['stride'],\n",
    "#         padding=specs['padding'],\n",
    "#     ),\n",
    "#     tf.keras.layers.Dropout(specs['dropout'], noise_shape=None),\n",
    "#     Dense(size=out_dim, nonlin=tf.identity, specs=specs)\n",
    "# )\n",
    "\n",
    "kmd = ModelDesign(\n",
    "    tf.keras.Input(shape=(1, n_times, n_channels)),\n",
    "    LayerDesign(tf.squeeze, axis=1),\n",
    "    tf.keras.layers.LSTM(\n",
    "        32,\n",
    "        return_sequences=True,\n",
    "        kernel_regularizer='l2',\n",
    "        recurrent_regularizer=tf.keras.regularizers.L1L2(l1=1e-2, l2=0.0),\n",
    "        bias_regularizer='l1',\n",
    "        # activity_regularizer='l2',\n",
    "        dropout=0.2,\n",
    "        recurrent_dropout=0.4\n",
    "    ),\n",
    "    LayerDesign(tf.expand_dims, axis=1),\n",
    "    # DeMixing(size=specs['n_latent'], nonlin=tf.identity, axis=3, specs=specs),\n",
    "    LFTConv(\n",
    "        size=specs['n_latent'],\n",
    "        nonlin=specs['nonlin'],\n",
    "        filter_length=specs['filter_length'],\n",
    "        padding=specs['padding'],\n",
    "        specs=specs\n",
    "    ),\n",
    "    TempPooling(\n",
    "        pooling=specs['pooling'],\n",
    "        pool_type=specs['pool_type'],\n",
    "        stride=specs['stride'],\n",
    "        padding=specs['padding'],\n",
    "    ),\n",
    "    tf.keras.layers.Dropout(specs['dropout'], noise_shape=None),\n",
    "    Dense(size=out_dim, nonlin=tf.identity, specs=specs)\n",
    "    # tf.keras.layers.DepthwiseConv2D((1, 37), padding='valid', activation='relu', kernel_regularizer='l1'),\n",
    "    # tf.keras.layers.Flatten(),\n",
    "    # tf.keras.layers.Dense(out_dim),\n",
    ")\n",
    "print('input: ', (1, n_times, n_channels))\n",
    "print(kmd().shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing from tuple\n",
      "input shapes: X- (940, 204, 361) targets- (940, 1)\n",
      "Preprocessing:\n",
      "Scaling to interval 0.0 - 60.0\n",
      "Splitting sets\n",
      "Preprocessed: (940, 1, 361, 204) (940, 8) folds: 5 x 188\n",
      "Prepocessed sample shape: (1, 361, 204)\n",
      "Target shape actual/metadata:  (8,) (8,)\n",
      "Saving TFRecord# 0\n",
      "Epoch 1/200\n",
      "10/10 - 5s - loss: 7.9894 - cat_ACC: 0.0893 - val_loss: 7.7607 - val_cat_ACC: 0.1543 - 5s/epoch - 453ms/step\n",
      "Epoch 2/200\n",
      "10/10 - 3s - loss: 7.7134 - cat_ACC: 0.1366 - val_loss: 7.5580 - val_cat_ACC: 0.1702 - 3s/epoch - 254ms/step\n",
      "Epoch 3/200\n",
      "10/10 - 3s - loss: 7.5178 - cat_ACC: 0.1134 - val_loss: 7.3651 - val_cat_ACC: 0.1862 - 3s/epoch - 257ms/step\n",
      "Epoch 4/200\n",
      "10/10 - 3s - loss: 7.3517 - cat_ACC: 0.1228 - val_loss: 7.1777 - val_cat_ACC: 0.1862 - 3s/epoch - 252ms/step\n",
      "Epoch 5/200\n",
      "10/10 - 3s - loss: 7.1514 - cat_ACC: 0.1229 - val_loss: 6.9964 - val_cat_ACC: 0.2128 - 3s/epoch - 279ms/step\n",
      "Epoch 6/200\n",
      "10/10 - 3s - loss: 6.9691 - cat_ACC: 0.1303 - val_loss: 6.8217 - val_cat_ACC: 0.2128 - 3s/epoch - 262ms/step\n",
      "Epoch 7/200\n",
      "10/10 - 3s - loss: 6.8078 - cat_ACC: 0.1418 - val_loss: 6.6542 - val_cat_ACC: 0.2074 - 3s/epoch - 253ms/step\n",
      "Epoch 8/200\n",
      "10/10 - 2s - loss: 6.6177 - cat_ACC: 0.1560 - val_loss: 6.4916 - val_cat_ACC: 0.2074 - 2s/epoch - 249ms/step\n",
      "Epoch 9/200\n",
      "10/10 - 3s - loss: 6.4801 - cat_ACC: 0.1208 - val_loss: 6.3335 - val_cat_ACC: 0.2074 - 3s/epoch - 254ms/step\n",
      "Epoch 10/200\n",
      "10/10 - 3s - loss: 6.3113 - cat_ACC: 0.1628 - val_loss: 6.1804 - val_cat_ACC: 0.2128 - 3s/epoch - 258ms/step\n",
      "Epoch 11/200\n",
      "10/10 - 3s - loss: 6.1550 - cat_ACC: 0.1586 - val_loss: 6.0340 - val_cat_ACC: 0.2181 - 3s/epoch - 270ms/step\n",
      "Epoch 12/200\n",
      "10/10 - 3s - loss: 5.9891 - cat_ACC: 0.1991 - val_loss: 5.8917 - val_cat_ACC: 0.2287 - 3s/epoch - 257ms/step\n",
      "Epoch 13/200\n",
      "10/10 - 3s - loss: 5.8715 - cat_ACC: 0.1639 - val_loss: 5.7534 - val_cat_ACC: 0.2394 - 3s/epoch - 260ms/step\n",
      "Epoch 14/200\n",
      "10/10 - 3s - loss: 5.7242 - cat_ACC: 0.1796 - val_loss: 5.6205 - val_cat_ACC: 0.2553 - 3s/epoch - 262ms/step\n",
      "Epoch 15/200\n",
      "10/10 - 3s - loss: 5.5985 - cat_ACC: 0.1870 - val_loss: 5.4933 - val_cat_ACC: 0.2660 - 3s/epoch - 259ms/step\n",
      "Epoch 16/200\n",
      "10/10 - 3s - loss: 5.4351 - cat_ACC: 0.2423 - val_loss: 5.3701 - val_cat_ACC: 0.2713 - 3s/epoch - 253ms/step\n",
      "Epoch 17/200\n",
      "10/10 - 3s - loss: 5.3545 - cat_ACC: 0.1964 - val_loss: 5.2495 - val_cat_ACC: 0.2713 - 3s/epoch - 262ms/step\n",
      "Epoch 18/200\n",
      "10/10 - 3s - loss: 5.2269 - cat_ACC: 0.2122 - val_loss: 5.1321 - val_cat_ACC: 0.2872 - 3s/epoch - 260ms/step\n",
      "Epoch 19/200\n",
      "10/10 - 3s - loss: 5.1104 - cat_ACC: 0.2206 - val_loss: 5.0198 - val_cat_ACC: 0.2872 - 3s/epoch - 263ms/step\n",
      "Epoch 20/200\n",
      "10/10 - 3s - loss: 4.9712 - cat_ACC: 0.2843 - val_loss: 4.9104 - val_cat_ACC: 0.3032 - 3s/epoch - 252ms/step\n",
      "Epoch 21/200\n",
      "10/10 - 3s - loss: 4.8904 - cat_ACC: 0.2532 - val_loss: 4.8022 - val_cat_ACC: 0.3085 - 3s/epoch - 264ms/step\n",
      "Epoch 22/200\n",
      "10/10 - 3s - loss: 4.7899 - cat_ACC: 0.2542 - val_loss: 4.6969 - val_cat_ACC: 0.3245 - 3s/epoch - 265ms/step\n",
      "Epoch 23/200\n",
      "10/10 - 3s - loss: 4.6791 - cat_ACC: 0.3036 - val_loss: 4.5963 - val_cat_ACC: 0.3351 - 3s/epoch - 263ms/step\n",
      "Epoch 24/200\n",
      "10/10 - 3s - loss: 4.5265 - cat_ACC: 0.3407 - val_loss: 4.4972 - val_cat_ACC: 0.3457 - 3s/epoch - 257ms/step\n",
      "Epoch 25/200\n",
      "10/10 - 3s - loss: 4.4771 - cat_ACC: 0.3141 - val_loss: 4.3987 - val_cat_ACC: 0.3564 - 3s/epoch - 264ms/step\n",
      "Epoch 26/200\n",
      "10/10 - 3s - loss: 4.3973 - cat_ACC: 0.3078 - val_loss: 4.3025 - val_cat_ACC: 0.3670 - 3s/epoch - 262ms/step\n",
      "Epoch 27/200\n",
      "10/10 - 3s - loss: 4.3144 - cat_ACC: 0.3340 - val_loss: 4.2114 - val_cat_ACC: 0.4149 - 3s/epoch - 261ms/step\n",
      "Epoch 28/200\n",
      "10/10 - 3s - loss: 4.1295 - cat_ACC: 0.4204 - val_loss: 4.1219 - val_cat_ACC: 0.4255 - 3s/epoch - 256ms/step\n",
      "Epoch 29/200\n",
      "10/10 - 3s - loss: 4.0901 - cat_ACC: 0.3897 - val_loss: 4.0325 - val_cat_ACC: 0.4309 - 3s/epoch - 266ms/step\n",
      "Epoch 30/200\n",
      "10/10 - 3s - loss: 4.0206 - cat_ACC: 0.3813 - val_loss: 3.9435 - val_cat_ACC: 0.4415 - 3s/epoch - 262ms/step\n",
      "Epoch 31/200\n",
      "10/10 - 3s - loss: 3.9396 - cat_ACC: 0.4223 - val_loss: 3.8599 - val_cat_ACC: 0.4468 - 3s/epoch - 273ms/step\n",
      "Epoch 32/200\n",
      "10/10 - 3s - loss: 3.7630 - cat_ACC: 0.4546 - val_loss: 3.7788 - val_cat_ACC: 0.4734 - 3s/epoch - 256ms/step\n",
      "Epoch 33/200\n",
      "10/10 - 3s - loss: 3.7617 - cat_ACC: 0.4338 - val_loss: 3.6991 - val_cat_ACC: 0.4787 - 3s/epoch - 262ms/step\n",
      "Epoch 34/200\n",
      "10/10 - 3s - loss: 3.6873 - cat_ACC: 0.4706 - val_loss: 3.6215 - val_cat_ACC: 0.4734 - 3s/epoch - 260ms/step\n",
      "Epoch 35/200\n",
      "10/10 - 3s - loss: 3.6053 - cat_ACC: 0.4779 - val_loss: 3.5485 - val_cat_ACC: 0.4894 - 3s/epoch - 263ms/step\n",
      "Epoch 36/200\n",
      "10/10 - 3s - loss: 3.4212 - cat_ACC: 0.5243 - val_loss: 3.4782 - val_cat_ACC: 0.5053 - 3s/epoch - 257ms/step\n",
      "Epoch 37/200\n",
      "10/10 - 3s - loss: 3.4293 - cat_ACC: 0.5158 - val_loss: 3.4083 - val_cat_ACC: 0.5106 - 3s/epoch - 263ms/step\n",
      "Epoch 38/200\n",
      "10/10 - 3s - loss: 3.3622 - cat_ACC: 0.5168 - val_loss: 3.3399 - val_cat_ACC: 0.5160 - 3s/epoch - 262ms/step\n",
      "Epoch 39/200\n",
      "10/10 - 3s - loss: 3.2885 - cat_ACC: 0.5473 - val_loss: 3.2769 - val_cat_ACC: 0.5266 - 3s/epoch - 264ms/step\n",
      "Epoch 40/200\n",
      "10/10 - 3s - loss: 3.1345 - cat_ACC: 0.5985 - val_loss: 3.2166 - val_cat_ACC: 0.5426 - 3s/epoch - 259ms/step\n",
      "Epoch 41/200\n",
      "10/10 - 3s - loss: 3.1756 - cat_ACC: 0.5525 - val_loss: 3.1573 - val_cat_ACC: 0.5426 - 3s/epoch - 264ms/step\n",
      "Epoch 42/200\n",
      "10/10 - 3s - loss: 3.1125 - cat_ACC: 0.5672 - val_loss: 3.0996 - val_cat_ACC: 0.5532 - 3s/epoch - 262ms/step\n",
      "Epoch 43/200\n",
      "10/10 - 3s - loss: 3.0459 - cat_ACC: 0.6061 - val_loss: 3.0471 - val_cat_ACC: 0.5691 - 3s/epoch - 265ms/step\n",
      "Epoch 44/200\n",
      "10/10 - 3s - loss: 2.8962 - cat_ACC: 0.6460 - val_loss: 2.9955 - val_cat_ACC: 0.5745 - 3s/epoch - 255ms/step\n",
      "Epoch 45/200\n",
      "10/10 - 3s - loss: 2.9171 - cat_ACC: 0.6439 - val_loss: 2.9452 - val_cat_ACC: 0.5798 - 3s/epoch - 264ms/step\n",
      "Epoch 46/200\n",
      "10/10 - 3s - loss: 2.8552 - cat_ACC: 0.6786 - val_loss: 2.8969 - val_cat_ACC: 0.5957 - 3s/epoch - 265ms/step\n",
      "Epoch 47/200\n",
      "10/10 - 3s - loss: 2.8001 - cat_ACC: 0.6681 - val_loss: 2.8525 - val_cat_ACC: 0.6170 - 3s/epoch - 269ms/step\n",
      "Epoch 48/200\n",
      "10/10 - 3s - loss: 2.6750 - cat_ACC: 0.6991 - val_loss: 2.8093 - val_cat_ACC: 0.6330 - 3s/epoch - 256ms/step\n",
      "Epoch 49/200\n",
      "10/10 - 3s - loss: 2.7055 - cat_ACC: 0.6985 - val_loss: 2.7657 - val_cat_ACC: 0.6436 - 3s/epoch - 263ms/step\n",
      "Epoch 50/200\n",
      "10/10 - 3s - loss: 2.6614 - cat_ACC: 0.7027 - val_loss: 2.7232 - val_cat_ACC: 0.6489 - 3s/epoch - 266ms/step\n",
      "Epoch 51/200\n",
      "10/10 - 3s - loss: 2.5980 - cat_ACC: 0.7101 - val_loss: 2.6863 - val_cat_ACC: 0.6809 - 3s/epoch - 262ms/step\n",
      "Epoch 52/200\n",
      "10/10 - 3s - loss: 2.4947 - cat_ACC: 0.7246 - val_loss: 2.6539 - val_cat_ACC: 0.6809 - 3s/epoch - 260ms/step\n",
      "Epoch 53/200\n",
      "10/10 - 3s - loss: 2.5319 - cat_ACC: 0.7006 - val_loss: 2.6192 - val_cat_ACC: 0.6809 - 3s/epoch - 266ms/step\n",
      "Epoch 54/200\n",
      "10/10 - 3s - loss: 2.4783 - cat_ACC: 0.7584 - val_loss: 2.5863 - val_cat_ACC: 0.6862 - 3s/epoch - 264ms/step\n",
      "Epoch 55/200\n",
      "10/10 - 3s - loss: 2.4259 - cat_ACC: 0.7637 - val_loss: 2.5554 - val_cat_ACC: 0.6915 - 3s/epoch - 282ms/step\n",
      "Epoch 56/200\n",
      "10/10 - 3s - loss: 2.3353 - cat_ACC: 0.7721 - val_loss: 2.5258 - val_cat_ACC: 0.7181 - 3s/epoch - 267ms/step\n",
      "Epoch 57/200\n",
      "10/10 - 3s - loss: 2.3390 - cat_ACC: 0.7857 - val_loss: 2.4966 - val_cat_ACC: 0.7128 - 3s/epoch - 271ms/step\n",
      "Epoch 58/200\n",
      "10/10 - 3s - loss: 2.3394 - cat_ACC: 0.7668 - val_loss: 2.4630 - val_cat_ACC: 0.7074 - 3s/epoch - 267ms/step\n",
      "Epoch 59/200\n",
      "10/10 - 3s - loss: 2.2757 - cat_ACC: 0.7899 - val_loss: 2.4346 - val_cat_ACC: 0.7128 - 3s/epoch - 271ms/step\n",
      "Epoch 60/200\n",
      "10/10 - 3s - loss: 2.1840 - cat_ACC: 0.8142 - val_loss: 2.4097 - val_cat_ACC: 0.7287 - 3s/epoch - 262ms/step\n",
      "Epoch 61/200\n",
      "10/10 - 3s - loss: 2.2127 - cat_ACC: 0.8120 - val_loss: 2.3873 - val_cat_ACC: 0.7287 - 3s/epoch - 268ms/step\n",
      "Epoch 62/200\n",
      "10/10 - 3s - loss: 2.2243 - cat_ACC: 0.8015 - val_loss: 2.3617 - val_cat_ACC: 0.7234 - 3s/epoch - 269ms/step\n",
      "Epoch 63/200\n",
      "10/10 - 3s - loss: 2.1428 - cat_ACC: 0.8340 - val_loss: 2.3408 - val_cat_ACC: 0.7340 - 3s/epoch - 266ms/step\n",
      "Epoch 64/200\n",
      "10/10 - 3s - loss: 2.0710 - cat_ACC: 0.8595 - val_loss: 2.3191 - val_cat_ACC: 0.7394 - 3s/epoch - 261ms/step\n",
      "Epoch 65/200\n",
      "10/10 - 3s - loss: 2.0987 - cat_ACC: 0.8424 - val_loss: 2.2956 - val_cat_ACC: 0.7340 - 3s/epoch - 270ms/step\n",
      "Epoch 66/200\n",
      "10/10 - 3s - loss: 2.0856 - cat_ACC: 0.8382 - val_loss: 2.2725 - val_cat_ACC: 0.7340 - 3s/epoch - 277ms/step\n",
      "Epoch 67/200\n",
      "10/10 - 3s - loss: 2.0418 - cat_ACC: 0.8561 - val_loss: 2.2527 - val_cat_ACC: 0.7447 - 3s/epoch - 269ms/step\n",
      "Epoch 68/200\n",
      "10/10 - 3s - loss: 2.0000 - cat_ACC: 0.8507 - val_loss: 2.2356 - val_cat_ACC: 0.7500 - 3s/epoch - 263ms/step\n",
      "Epoch 69/200\n",
      "10/10 - 3s - loss: 2.0000 - cat_ACC: 0.8540 - val_loss: 2.2161 - val_cat_ACC: 0.7500 - 3s/epoch - 265ms/step\n",
      "Epoch 70/200\n",
      "10/10 - 3s - loss: 1.9799 - cat_ACC: 0.8687 - val_loss: 2.1940 - val_cat_ACC: 0.7500 - 3s/epoch - 265ms/step\n",
      "Epoch 71/200\n",
      "10/10 - 3s - loss: 1.9523 - cat_ACC: 0.8803 - val_loss: 2.1750 - val_cat_ACC: 0.7447 - 3s/epoch - 267ms/step\n",
      "Epoch 72/200\n",
      "10/10 - 3s - loss: 1.8897 - cat_ACC: 0.8905 - val_loss: 2.1602 - val_cat_ACC: 0.7553 - 3s/epoch - 264ms/step\n",
      "Epoch 73/200\n",
      "10/10 - 3s - loss: 1.9171 - cat_ACC: 0.8803 - val_loss: 2.1468 - val_cat_ACC: 0.7500 - 3s/epoch - 267ms/step\n",
      "Epoch 74/200\n",
      "10/10 - 3s - loss: 1.8917 - cat_ACC: 0.8908 - val_loss: 2.1319 - val_cat_ACC: 0.7500 - 3s/epoch - 272ms/step\n",
      "Epoch 75/200\n",
      "10/10 - 3s - loss: 1.8480 - cat_ACC: 0.8992 - val_loss: 2.1191 - val_cat_ACC: 0.7606 - 3s/epoch - 272ms/step\n",
      "Epoch 76/200\n",
      "10/10 - 3s - loss: 1.8055 - cat_ACC: 0.9038 - val_loss: 2.1032 - val_cat_ACC: 0.7606 - 3s/epoch - 262ms/step\n",
      "Epoch 77/200\n",
      "10/10 - 3s - loss: 1.8328 - cat_ACC: 0.8897 - val_loss: 2.0894 - val_cat_ACC: 0.7606 - 3s/epoch - 265ms/step\n",
      "Epoch 78/200\n",
      "10/10 - 3s - loss: 1.8343 - cat_ACC: 0.8939 - val_loss: 2.0776 - val_cat_ACC: 0.7606 - 3s/epoch - 262ms/step\n",
      "Epoch 79/200\n",
      "10/10 - 3s - loss: 1.7726 - cat_ACC: 0.9191 - val_loss: 2.0619 - val_cat_ACC: 0.7660 - 3s/epoch - 267ms/step\n",
      "Epoch 80/200\n",
      "10/10 - 3s - loss: 1.7560 - cat_ACC: 0.9181 - val_loss: 2.0523 - val_cat_ACC: 0.7660 - 3s/epoch - 265ms/step\n",
      "Epoch 81/200\n",
      "10/10 - 3s - loss: 1.7692 - cat_ACC: 0.9170 - val_loss: 2.0395 - val_cat_ACC: 0.7766 - 3s/epoch - 268ms/step\n",
      "Epoch 82/200\n",
      "10/10 - 3s - loss: 1.7517 - cat_ACC: 0.9202 - val_loss: 2.0236 - val_cat_ACC: 0.7819 - 3s/epoch - 269ms/step\n",
      "Epoch 83/200\n",
      "10/10 - 3s - loss: 1.7272 - cat_ACC: 0.9212 - val_loss: 2.0156 - val_cat_ACC: 0.7766 - 3s/epoch - 269ms/step\n",
      "Epoch 84/200\n",
      "10/10 - 3s - loss: 1.6940 - cat_ACC: 0.9215 - val_loss: 2.0057 - val_cat_ACC: 0.7713 - 3s/epoch - 257ms/step\n",
      "Epoch 85/200\n",
      "10/10 - 3s - loss: 1.7043 - cat_ACC: 0.9149 - val_loss: 1.9908 - val_cat_ACC: 0.7766 - 3s/epoch - 264ms/step\n",
      "Epoch 86/200\n",
      "10/10 - 3s - loss: 1.6829 - cat_ACC: 0.9338 - val_loss: 1.9759 - val_cat_ACC: 0.7766 - 3s/epoch - 266ms/step\n",
      "Epoch 87/200\n",
      "10/10 - 3s - loss: 1.6584 - cat_ACC: 0.9412 - val_loss: 1.9696 - val_cat_ACC: 0.7766 - 3s/epoch - 274ms/step\n",
      "Epoch 88/200\n",
      "10/10 - 3s - loss: 1.6404 - cat_ACC: 0.9381 - val_loss: 1.9606 - val_cat_ACC: 0.7872 - 3s/epoch - 261ms/step\n",
      "Epoch 89/200\n",
      "10/10 - 3s - loss: 1.6397 - cat_ACC: 0.9338 - val_loss: 1.9503 - val_cat_ACC: 0.7926 - 3s/epoch - 271ms/step\n",
      "Epoch 90/200\n",
      "10/10 - 3s - loss: 1.6405 - cat_ACC: 0.9380 - val_loss: 1.9399 - val_cat_ACC: 0.7979 - 3s/epoch - 269ms/step\n",
      "Epoch 91/200\n",
      "10/10 - 3s - loss: 1.6120 - cat_ACC: 0.9422 - val_loss: 1.9322 - val_cat_ACC: 0.7926 - 3s/epoch - 269ms/step\n",
      "Epoch 92/200\n",
      "10/10 - 3s - loss: 1.5925 - cat_ACC: 0.9458 - val_loss: 1.9308 - val_cat_ACC: 0.7979 - 3s/epoch - 269ms/step\n",
      "Epoch 93/200\n",
      "10/10 - 3s - loss: 1.5959 - cat_ACC: 0.9359 - val_loss: 1.9187 - val_cat_ACC: 0.7926 - 3s/epoch - 268ms/step\n",
      "Epoch 94/200\n",
      "10/10 - 3s - loss: 1.6004 - cat_ACC: 0.9391 - val_loss: 1.9101 - val_cat_ACC: 0.7979 - 3s/epoch - 270ms/step\n",
      "Epoch 95/200\n",
      "10/10 - 3s - loss: 1.5849 - cat_ACC: 0.9485 - val_loss: 1.8975 - val_cat_ACC: 0.7979 - 3s/epoch - 272ms/step\n",
      "Epoch 96/200\n",
      "10/10 - 3s - loss: 1.5536 - cat_ACC: 0.9458 - val_loss: 1.8882 - val_cat_ACC: 0.8032 - 3s/epoch - 263ms/step\n",
      "Epoch 97/200\n",
      "10/10 - 3s - loss: 1.5697 - cat_ACC: 0.9433 - val_loss: 1.8805 - val_cat_ACC: 0.7979 - 3s/epoch - 268ms/step\n",
      "Epoch 98/200\n",
      "10/10 - 3s - loss: 1.5501 - cat_ACC: 0.9496 - val_loss: 1.8771 - val_cat_ACC: 0.7979 - 3s/epoch - 272ms/step\n",
      "Epoch 99/200\n",
      "10/10 - 3s - loss: 1.5260 - cat_ACC: 0.9590 - val_loss: 1.8662 - val_cat_ACC: 0.8032 - 3s/epoch - 270ms/step\n",
      "Epoch 100/200\n",
      "10/10 - 3s - loss: 1.5162 - cat_ACC: 0.9425 - val_loss: 1.8561 - val_cat_ACC: 0.8032 - 3s/epoch - 274ms/step\n",
      "Epoch 101/200\n",
      "10/10 - 3s - loss: 1.5180 - cat_ACC: 0.9632 - val_loss: 1.8459 - val_cat_ACC: 0.8032 - 3s/epoch - 269ms/step\n",
      "Epoch 102/200\n",
      "10/10 - 3s - loss: 1.5177 - cat_ACC: 0.9569 - val_loss: 1.8429 - val_cat_ACC: 0.8032 - 3s/epoch - 267ms/step\n",
      "Epoch 103/200\n",
      "10/10 - 3s - loss: 1.4867 - cat_ACC: 0.9643 - val_loss: 1.8359 - val_cat_ACC: 0.8085 - 3s/epoch - 271ms/step\n",
      "Epoch 104/200\n",
      "10/10 - 3s - loss: 1.4809 - cat_ACC: 0.9535 - val_loss: 1.8259 - val_cat_ACC: 0.8085 - 3s/epoch - 269ms/step\n",
      "Epoch 105/200\n",
      "10/10 - 3s - loss: 1.4928 - cat_ACC: 0.9496 - val_loss: 1.8189 - val_cat_ACC: 0.8085 - 3s/epoch - 266ms/step\n",
      "Epoch 106/200\n",
      "10/10 - 3s - loss: 1.4721 - cat_ACC: 0.9695 - val_loss: 1.8156 - val_cat_ACC: 0.8085 - 3s/epoch - 267ms/step\n",
      "Epoch 107/200\n",
      "10/10 - 3s - loss: 1.4571 - cat_ACC: 0.9622 - val_loss: 1.8058 - val_cat_ACC: 0.8085 - 3s/epoch - 271ms/step\n",
      "Epoch 108/200\n",
      "10/10 - 3s - loss: 1.4242 - cat_ACC: 0.9723 - val_loss: 1.7935 - val_cat_ACC: 0.8138 - 3s/epoch - 265ms/step\n",
      "Epoch 109/200\n",
      "10/10 - 3s - loss: 1.4487 - cat_ACC: 0.9695 - val_loss: 1.7920 - val_cat_ACC: 0.8138 - 3s/epoch - 274ms/step\n",
      "Epoch 110/200\n",
      "10/10 - 3s - loss: 1.4540 - cat_ACC: 0.9569 - val_loss: 1.7810 - val_cat_ACC: 0.8085 - 3s/epoch - 279ms/step\n",
      "Epoch 111/200\n",
      "10/10 - 3s - loss: 1.4141 - cat_ACC: 0.9769 - val_loss: 1.7728 - val_cat_ACC: 0.8191 - 3s/epoch - 272ms/step\n",
      "Epoch 112/200\n",
      "10/10 - 3s - loss: 1.4127 - cat_ACC: 0.9668 - val_loss: 1.7701 - val_cat_ACC: 0.8138 - 3s/epoch - 267ms/step\n",
      "Epoch 113/200\n",
      "10/10 - 3s - loss: 1.4196 - cat_ACC: 0.9643 - val_loss: 1.7683 - val_cat_ACC: 0.8138 - 3s/epoch - 301ms/step\n",
      "Epoch 114/200\n",
      "10/10 - 3s - loss: 1.4080 - cat_ACC: 0.9611 - val_loss: 1.7595 - val_cat_ACC: 0.8138 - 3s/epoch - 296ms/step\n",
      "Epoch 115/200\n",
      "10/10 - 3s - loss: 1.3930 - cat_ACC: 0.9695 - val_loss: 1.7511 - val_cat_ACC: 0.8191 - 3s/epoch - 296ms/step\n",
      "Epoch 116/200\n",
      "10/10 - 3s - loss: 1.3779 - cat_ACC: 0.9701 - val_loss: 1.7456 - val_cat_ACC: 0.8191 - 3s/epoch - 300ms/step\n",
      "Epoch 117/200\n",
      "10/10 - 3s - loss: 1.3852 - cat_ACC: 0.9716 - val_loss: 1.7412 - val_cat_ACC: 0.8191 - 3s/epoch - 302ms/step\n",
      "Epoch 118/200\n",
      "10/10 - 3s - loss: 1.3786 - cat_ACC: 0.9779 - val_loss: 1.7340 - val_cat_ACC: 0.8245 - 3s/epoch - 306ms/step\n",
      "Epoch 119/200\n",
      "10/10 - 3s - loss: 1.3722 - cat_ACC: 0.9779 - val_loss: 1.7257 - val_cat_ACC: 0.8191 - 3s/epoch - 293ms/step\n",
      "Epoch 120/200\n",
      "10/10 - 3s - loss: 1.3482 - cat_ACC: 0.9712 - val_loss: 1.7196 - val_cat_ACC: 0.8138 - 3s/epoch - 260ms/step\n",
      "Epoch 121/200\n",
      "10/10 - 3s - loss: 1.3649 - cat_ACC: 0.9695 - val_loss: 1.7131 - val_cat_ACC: 0.8138 - 3s/epoch - 264ms/step\n",
      "Epoch 122/200\n",
      "10/10 - 3s - loss: 1.3611 - cat_ACC: 0.9737 - val_loss: 1.7062 - val_cat_ACC: 0.8191 - 3s/epoch - 261ms/step\n",
      "Epoch 123/200\n",
      "10/10 - 3s - loss: 1.3219 - cat_ACC: 0.9821 - val_loss: 1.7023 - val_cat_ACC: 0.8191 - 3s/epoch - 267ms/step\n",
      "Epoch 124/200\n",
      "10/10 - 3s - loss: 1.3129 - cat_ACC: 0.9834 - val_loss: 1.6966 - val_cat_ACC: 0.8191 - 3s/epoch - 259ms/step\n",
      "Epoch 125/200\n",
      "10/10 - 3s - loss: 1.3304 - cat_ACC: 0.9748 - val_loss: 1.6894 - val_cat_ACC: 0.8191 - 3s/epoch - 269ms/step\n",
      "Epoch 126/200\n",
      "10/10 - 3s - loss: 1.3382 - cat_ACC: 0.9748 - val_loss: 1.6815 - val_cat_ACC: 0.8245 - 3s/epoch - 263ms/step\n",
      "Epoch 127/200\n",
      "10/10 - 3s - loss: 1.3123 - cat_ACC: 0.9748 - val_loss: 1.6742 - val_cat_ACC: 0.8245 - 3s/epoch - 267ms/step\n",
      "Epoch 128/200\n",
      "10/10 - 3s - loss: 1.2971 - cat_ACC: 0.9801 - val_loss: 1.6712 - val_cat_ACC: 0.8245 - 3s/epoch - 258ms/step\n",
      "Epoch 129/200\n",
      "10/10 - 3s - loss: 1.3076 - cat_ACC: 0.9695 - val_loss: 1.6667 - val_cat_ACC: 0.8138 - 3s/epoch - 265ms/step\n",
      "Epoch 130/200\n",
      "10/10 - 3s - loss: 1.2862 - cat_ACC: 0.9842 - val_loss: 1.6597 - val_cat_ACC: 0.8191 - 3s/epoch - 271ms/step\n",
      "Epoch 131/200\n",
      "10/10 - 3s - loss: 1.2843 - cat_ACC: 0.9800 - val_loss: 1.6555 - val_cat_ACC: 0.8138 - 3s/epoch - 279ms/step\n",
      "Epoch 132/200\n",
      "10/10 - 3s - loss: 1.2684 - cat_ACC: 0.9823 - val_loss: 1.6447 - val_cat_ACC: 0.8245 - 3s/epoch - 260ms/step\n",
      "Epoch 133/200\n",
      "10/10 - 3s - loss: 1.2861 - cat_ACC: 0.9758 - val_loss: 1.6426 - val_cat_ACC: 0.8298 - 3s/epoch - 268ms/step\n",
      "Epoch 134/200\n",
      "10/10 - 3s - loss: 1.2828 - cat_ACC: 0.9727 - val_loss: 1.6409 - val_cat_ACC: 0.8245 - 3s/epoch - 269ms/step\n",
      "Epoch 135/200\n",
      "10/10 - 3s - loss: 1.2699 - cat_ACC: 0.9779 - val_loss: 1.6353 - val_cat_ACC: 0.8245 - 3s/epoch - 271ms/step\n",
      "Epoch 136/200\n",
      "10/10 - 3s - loss: 1.2542 - cat_ACC: 0.9845 - val_loss: 1.6229 - val_cat_ACC: 0.8298 - 3s/epoch - 261ms/step\n",
      "Epoch 137/200\n",
      "10/10 - 3s - loss: 1.2615 - cat_ACC: 0.9769 - val_loss: 1.6176 - val_cat_ACC: 0.8298 - 3s/epoch - 267ms/step\n",
      "Epoch 138/200\n",
      "10/10 - 3s - loss: 1.2496 - cat_ACC: 0.9800 - val_loss: 1.6161 - val_cat_ACC: 0.8245 - 3s/epoch - 270ms/step\n",
      "Epoch 139/200\n",
      "10/10 - 3s - loss: 1.2358 - cat_ACC: 0.9895 - val_loss: 1.6113 - val_cat_ACC: 0.8298 - 3s/epoch - 267ms/step\n",
      "Epoch 140/200\n",
      "10/10 - 3s - loss: 1.2257 - cat_ACC: 0.9845 - val_loss: 1.6087 - val_cat_ACC: 0.8298 - 3s/epoch - 260ms/step\n",
      "Epoch 141/200\n",
      "10/10 - 3s - loss: 1.2271 - cat_ACC: 0.9790 - val_loss: 1.6017 - val_cat_ACC: 0.8245 - 3s/epoch - 270ms/step\n",
      "Epoch 142/200\n",
      "10/10 - 3s - loss: 1.2236 - cat_ACC: 0.9853 - val_loss: 1.5939 - val_cat_ACC: 0.8245 - 3s/epoch - 271ms/step\n",
      "Epoch 143/200\n",
      "10/10 - 3s - loss: 1.2221 - cat_ACC: 0.9832 - val_loss: 1.5886 - val_cat_ACC: 0.8298 - 3s/epoch - 268ms/step\n",
      "Epoch 144/200\n",
      "10/10 - 3s - loss: 1.2054 - cat_ACC: 0.9856 - val_loss: 1.5856 - val_cat_ACC: 0.8245 - 3s/epoch - 267ms/step\n",
      "Epoch 145/200\n",
      "10/10 - 3s - loss: 1.2090 - cat_ACC: 0.9779 - val_loss: 1.5806 - val_cat_ACC: 0.8298 - 3s/epoch - 264ms/step\n",
      "Epoch 146/200\n",
      "10/10 - 3s - loss: 1.2125 - cat_ACC: 0.9842 - val_loss: 1.5755 - val_cat_ACC: 0.8298 - 3s/epoch - 269ms/step\n",
      "Epoch 147/200\n",
      "10/10 - 3s - loss: 1.1895 - cat_ACC: 0.9874 - val_loss: 1.5678 - val_cat_ACC: 0.8298 - 3s/epoch - 266ms/step\n",
      "Epoch 148/200\n",
      "10/10 - 3s - loss: 1.1786 - cat_ACC: 0.9867 - val_loss: 1.5666 - val_cat_ACC: 0.8245 - 3s/epoch - 269ms/step\n",
      "Epoch 149/200\n",
      "10/10 - 3s - loss: 1.1755 - cat_ACC: 0.9905 - val_loss: 1.5603 - val_cat_ACC: 0.8245 - 3s/epoch - 266ms/step\n",
      "Epoch 150/200\n",
      "10/10 - 3s - loss: 1.1921 - cat_ACC: 0.9790 - val_loss: 1.5489 - val_cat_ACC: 0.8298 - 3s/epoch - 268ms/step\n",
      "Epoch 151/200\n",
      "10/10 - 3s - loss: 1.1741 - cat_ACC: 0.9853 - val_loss: 1.5438 - val_cat_ACC: 0.8298 - 3s/epoch - 266ms/step\n",
      "Epoch 152/200\n",
      "10/10 - 3s - loss: 1.1479 - cat_ACC: 0.9956 - val_loss: 1.5433 - val_cat_ACC: 0.8351 - 3s/epoch - 262ms/step\n",
      "Epoch 153/200\n",
      "10/10 - 3s - loss: 1.1611 - cat_ACC: 0.9926 - val_loss: 1.5390 - val_cat_ACC: 0.8298 - 3s/epoch - 267ms/step\n",
      "Epoch 154/200\n",
      "10/10 - 3s - loss: 1.1671 - cat_ACC: 0.9863 - val_loss: 1.5362 - val_cat_ACC: 0.8351 - 3s/epoch - 264ms/step\n",
      "Epoch 155/200\n",
      "10/10 - 3s - loss: 1.1475 - cat_ACC: 0.9926 - val_loss: 1.5338 - val_cat_ACC: 0.8351 - 3s/epoch - 265ms/step\n",
      "Epoch 156/200\n",
      "10/10 - 3s - loss: 1.1437 - cat_ACC: 0.9900 - val_loss: 1.5266 - val_cat_ACC: 0.8351 - 3s/epoch - 263ms/step\n",
      "Epoch 157/200\n",
      "10/10 - 3s - loss: 1.1555 - cat_ACC: 0.9769 - val_loss: 1.5190 - val_cat_ACC: 0.8298 - 3s/epoch - 266ms/step\n",
      "Epoch 158/200\n",
      "10/10 - 3s - loss: 1.1569 - cat_ACC: 0.9863 - val_loss: 1.5123 - val_cat_ACC: 0.8457 - 3s/epoch - 266ms/step\n",
      "Epoch 159/200\n",
      "10/10 - 3s - loss: 1.1391 - cat_ACC: 0.9895 - val_loss: 1.5056 - val_cat_ACC: 0.8457 - 3s/epoch - 267ms/step\n",
      "Epoch 160/200\n",
      "10/10 - 3s - loss: 1.1197 - cat_ACC: 0.9856 - val_loss: 1.5030 - val_cat_ACC: 0.8404 - 3s/epoch - 265ms/step\n",
      "Epoch 161/200\n",
      "10/10 - 3s - loss: 1.1283 - cat_ACC: 0.9874 - val_loss: 1.5022 - val_cat_ACC: 0.8351 - 3s/epoch - 267ms/step\n",
      "Epoch 162/200\n",
      "10/10 - 3s - loss: 1.1315 - cat_ACC: 0.9811 - val_loss: 1.4969 - val_cat_ACC: 0.8351 - 3s/epoch - 267ms/step\n",
      "Epoch 163/200\n",
      "10/10 - 3s - loss: 1.1184 - cat_ACC: 0.9863 - val_loss: 1.4903 - val_cat_ACC: 0.8245 - 3s/epoch - 266ms/step\n",
      "Epoch 164/200\n",
      "10/10 - 3s - loss: 1.0940 - cat_ACC: 0.9945 - val_loss: 1.4877 - val_cat_ACC: 0.8298 - 3s/epoch - 264ms/step\n",
      "Epoch 165/200\n",
      "10/10 - 3s - loss: 1.0987 - cat_ACC: 0.9937 - val_loss: 1.4898 - val_cat_ACC: 0.8351 - 3s/epoch - 268ms/step\n",
      "Epoch 166/200\n",
      "10/10 - 3s - loss: 1.0927 - cat_ACC: 0.9905 - val_loss: 1.4825 - val_cat_ACC: 0.8404 - 3s/epoch - 264ms/step\n",
      "Epoch 167/200\n",
      "10/10 - 3s - loss: 1.0890 - cat_ACC: 0.9958 - val_loss: 1.4749 - val_cat_ACC: 0.8404 - 3s/epoch - 263ms/step\n",
      "Epoch 168/200\n",
      "10/10 - 3s - loss: 1.0866 - cat_ACC: 0.9900 - val_loss: 1.4697 - val_cat_ACC: 0.8457 - 3s/epoch - 262ms/step\n",
      "Epoch 169/200\n",
      "10/10 - 3s - loss: 1.0873 - cat_ACC: 0.9905 - val_loss: 1.4650 - val_cat_ACC: 0.8298 - 3s/epoch - 269ms/step\n",
      "Epoch 170/200\n",
      "10/10 - 3s - loss: 1.0737 - cat_ACC: 0.9895 - val_loss: 1.4568 - val_cat_ACC: 0.8298 - 3s/epoch - 268ms/step\n",
      "Epoch 171/200\n",
      "10/10 - 3s - loss: 1.0705 - cat_ACC: 0.9947 - val_loss: 1.4570 - val_cat_ACC: 0.8298 - 3s/epoch - 266ms/step\n",
      "Epoch 172/200\n",
      "10/10 - 3s - loss: 1.0697 - cat_ACC: 0.9889 - val_loss: 1.4479 - val_cat_ACC: 0.8298 - 3s/epoch - 263ms/step\n",
      "Epoch 173/200\n",
      "10/10 - 3s - loss: 1.0724 - cat_ACC: 0.9895 - val_loss: 1.4407 - val_cat_ACC: 0.8404 - 3s/epoch - 269ms/step\n",
      "Epoch 174/200\n",
      "10/10 - 3s - loss: 1.0738 - cat_ACC: 0.9874 - val_loss: 1.4357 - val_cat_ACC: 0.8404 - 3s/epoch - 268ms/step\n",
      "Epoch 175/200\n",
      "10/10 - 3s - loss: 1.0576 - cat_ACC: 0.9916 - val_loss: 1.4332 - val_cat_ACC: 0.8404 - 3s/epoch - 265ms/step\n",
      "Epoch 176/200\n",
      "10/10 - 3s - loss: 1.0441 - cat_ACC: 0.9912 - val_loss: 1.4301 - val_cat_ACC: 0.8404 - 3s/epoch - 268ms/step\n",
      "Epoch 177/200\n",
      "10/10 - 3s - loss: 1.0575 - cat_ACC: 0.9895 - val_loss: 1.4284 - val_cat_ACC: 0.8351 - 3s/epoch - 267ms/step\n",
      "Epoch 178/200\n",
      "10/10 - 3s - loss: 1.0536 - cat_ACC: 0.9884 - val_loss: 1.4237 - val_cat_ACC: 0.8351 - 3s/epoch - 268ms/step\n",
      "Epoch 179/200\n",
      "10/10 - 3s - loss: 1.0395 - cat_ACC: 0.9895 - val_loss: 1.4164 - val_cat_ACC: 0.8351 - 3s/epoch - 269ms/step\n",
      "Epoch 180/200\n",
      "10/10 - 3s - loss: 1.0316 - cat_ACC: 0.9912 - val_loss: 1.4101 - val_cat_ACC: 0.8404 - 3s/epoch - 263ms/step\n",
      "Epoch 181/200\n",
      "10/10 - 3s - loss: 1.0397 - cat_ACC: 0.9853 - val_loss: 1.4078 - val_cat_ACC: 0.8351 - 3s/epoch - 267ms/step\n",
      "Epoch 182/200\n",
      "10/10 - 3s - loss: 1.0351 - cat_ACC: 0.9874 - val_loss: 1.4034 - val_cat_ACC: 0.8351 - 3s/epoch - 271ms/step\n",
      "Epoch 183/200\n",
      "10/10 - 3s - loss: 1.0167 - cat_ACC: 0.9947 - val_loss: 1.3941 - val_cat_ACC: 0.8404 - 3s/epoch - 268ms/step\n",
      "Epoch 184/200\n",
      "10/10 - 3s - loss: 1.0160 - cat_ACC: 0.9934 - val_loss: 1.3889 - val_cat_ACC: 0.8404 - 3s/epoch - 258ms/step\n",
      "Epoch 185/200\n",
      "10/10 - 3s - loss: 1.0301 - cat_ACC: 0.9853 - val_loss: 1.3878 - val_cat_ACC: 0.8404 - 3s/epoch - 266ms/step\n",
      "Epoch 186/200\n",
      "10/10 - 3s - loss: 1.0249 - cat_ACC: 0.9853 - val_loss: 1.3874 - val_cat_ACC: 0.8404 - 3s/epoch - 268ms/step\n",
      "Epoch 187/200\n",
      "10/10 - 3s - loss: 1.0089 - cat_ACC: 0.9874 - val_loss: 1.3827 - val_cat_ACC: 0.8404 - 3s/epoch - 276ms/step\n",
      "Epoch 188/200\n",
      "10/10 - 3s - loss: 0.9991 - cat_ACC: 0.9934 - val_loss: 1.3789 - val_cat_ACC: 0.8404 - 3s/epoch - 268ms/step\n",
      "Epoch 189/200\n",
      "10/10 - 3s - loss: 1.0073 - cat_ACC: 0.9937 - val_loss: 1.3769 - val_cat_ACC: 0.8351 - 3s/epoch - 269ms/step\n",
      "Epoch 190/200\n",
      "10/10 - 3s - loss: 1.0060 - cat_ACC: 0.9884 - val_loss: 1.3721 - val_cat_ACC: 0.8404 - 3s/epoch - 277ms/step\n",
      "Epoch 191/200\n",
      "10/10 - 3s - loss: 0.9919 - cat_ACC: 0.9926 - val_loss: 1.3705 - val_cat_ACC: 0.8351 - 3s/epoch - 279ms/step\n",
      "Epoch 192/200\n",
      "10/10 - 3s - loss: 0.9805 - cat_ACC: 0.9934 - val_loss: 1.3638 - val_cat_ACC: 0.8404 - 3s/epoch - 277ms/step\n",
      "Epoch 193/200\n",
      "10/10 - 3s - loss: 0.9875 - cat_ACC: 0.9916 - val_loss: 1.3591 - val_cat_ACC: 0.8404 - 3s/epoch - 315ms/step\n",
      "Epoch 194/200\n",
      "10/10 - 4s - loss: 0.9913 - cat_ACC: 0.9853 - val_loss: 1.3569 - val_cat_ACC: 0.8404 - 4s/epoch - 351ms/step\n",
      "Epoch 195/200\n",
      "10/10 - 3s - loss: 0.9781 - cat_ACC: 0.9947 - val_loss: 1.3530 - val_cat_ACC: 0.8404 - 3s/epoch - 306ms/step\n",
      "Epoch 196/200\n",
      "10/10 - 3s - loss: 0.9805 - cat_ACC: 0.9900 - val_loss: 1.3490 - val_cat_ACC: 0.8404 - 3s/epoch - 281ms/step\n",
      "Epoch 197/200\n",
      "10/10 - 3s - loss: 0.9894 - cat_ACC: 0.9874 - val_loss: 1.3451 - val_cat_ACC: 0.8457 - 3s/epoch - 323ms/step\n",
      "Epoch 198/200\n",
      "10/10 - 3s - loss: 0.9794 - cat_ACC: 0.9884 - val_loss: 1.3466 - val_cat_ACC: 0.8457 - 3s/epoch - 286ms/step\n",
      "Epoch 199/200\n",
      "10/10 - 3s - loss: 0.9634 - cat_ACC: 0.9905 - val_loss: 1.3429 - val_cat_ACC: 0.8457 - 3s/epoch - 286ms/step\n",
      "Epoch 200/200\n",
      "10/10 - 3s - loss: 0.9531 - cat_ACC: 0.9978 - val_loss: 1.3351 - val_cat_ACC: 0.8404 - 3s/epoch - 320ms/step\n",
      "(204, 128) (32, 128) (128,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 372.103125 248.518125\" width=\"372.103125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2022-03-07T15:59:52.389074</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.4.3, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 248.518125 \nL 372.103125 248.518125 \nL 372.103125 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 30.103125 224.64 \nL 364.903125 224.64 \nL 364.903125 7.2 \nL 30.103125 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m9fb47c1437\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"45.321307\" xlink:href=\"#m9fb47c1437\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(42.140057 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" id=\"DejaVuSans-30\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"83.557945\" xlink:href=\"#m9fb47c1437\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 25 -->\n      <g transform=\"translate(77.195445 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" id=\"DejaVuSans-32\" transform=\"scale(0.015625)\"/>\n        <path d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" id=\"DejaVuSans-35\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"121.794582\" xlink:href=\"#m9fb47c1437\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 50 -->\n      <g transform=\"translate(115.432082 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-35\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"160.03122\" xlink:href=\"#m9fb47c1437\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 75 -->\n      <g transform=\"translate(153.66872 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 525 4666 \nL 3525 4666 \nL 3525 4397 \nL 1831 0 \nL 1172 0 \nL 2766 4134 \nL 525 4134 \nL 525 4666 \nz\n\" id=\"DejaVuSans-37\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-37\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"198.267858\" xlink:href=\"#m9fb47c1437\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 100 -->\n      <g transform=\"translate(188.724108 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" id=\"DejaVuSans-31\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"236.504495\" xlink:href=\"#m9fb47c1437\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 125 -->\n      <g transform=\"translate(226.960745 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-32\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"274.741133\" xlink:href=\"#m9fb47c1437\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 150 -->\n      <g transform=\"translate(265.197383 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"312.977771\" xlink:href=\"#m9fb47c1437\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 175 -->\n      <g transform=\"translate(303.434021 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-37\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_9\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"351.214409\" xlink:href=\"#m9fb47c1437\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 200 -->\n      <g transform=\"translate(341.670659 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_10\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m7fe80382b1\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m7fe80382b1\" y=\"190.667042\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.2 -->\n      <g transform=\"translate(7.2 194.46626)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" id=\"DejaVuSans-2e\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-32\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m7fe80382b1\" y=\"147.150846\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.4 -->\n      <g transform=\"translate(7.2 150.950065)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" id=\"DejaVuSans-34\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-34\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m7fe80382b1\" y=\"103.63465\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0.6 -->\n      <g transform=\"translate(7.2 107.433869)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" id=\"DejaVuSans-36\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-36\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m7fe80382b1\" y=\"60.118455\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 0.8 -->\n      <g transform=\"translate(7.2 63.917673)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" id=\"DejaVuSans-38\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-38\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m7fe80382b1\" y=\"16.602259\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 1.0 -->\n      <g transform=\"translate(7.2 20.401478)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_15\">\n    <path clip-path=\"url(#p99b20d4d66)\" d=\"M 45.321307 214.756364 \nL 46.850772 204.471547 \nL 48.380238 209.499681 \nL 49.909703 207.466989 \nL 51.439169 207.442718 \nL 52.968634 205.842856 \nL 54.4981 203.328792 \nL 56.027565 200.246381 \nL 57.557031 207.899821 \nL 59.086496 198.757763 \nL 60.615962 199.671969 \nL 62.145427 190.859592 \nL 63.674893 198.52921 \nL 65.204358 195.10094 \nL 66.733824 193.501079 \nL 68.263289 181.4728 \nL 69.792755 191.444117 \nL 71.32222 188.015844 \nL 72.851686 186.187433 \nL 74.381151 172.326697 \nL 75.910617 179.102337 \nL 77.440083 178.873787 \nL 78.969548 168.131868 \nL 80.499014 160.051666 \nL 82.028479 165.846357 \nL 83.557945 167.217662 \nL 85.08741 161.503878 \nL 86.616876 142.722207 \nL 88.146341 149.390647 \nL 89.675807 151.219059 \nL 91.205272 142.305557 \nL 92.734738 135.260911 \nL 94.264203 139.79149 \nL 95.793669 131.792188 \nL 97.323134 130.192327 \nL 98.8526 120.097637 \nL 100.382065 121.964475 \nL 101.911531 121.735925 \nL 103.440996 115.107929 \nL 104.970462 103.971614 \nL 106.499927 113.96518 \nL 108.029393 110.765456 \nL 111.088324 93.622081 \nL 112.617789 94.081203 \nL 114.147255 86.539008 \nL 115.67672 88.824519 \nL 117.206186 82.069103 \nL 118.735651 82.196522 \nL 120.265117 81.282323 \nL 121.794582 79.682461 \nL 123.324048 76.533304 \nL 124.853513 81.739423 \nL 126.382979 69.169092 \nL 127.912444 68.02633 \nL 129.44191 66.18377 \nL 130.971375 63.226758 \nL 132.500841 67.340681 \nL 135.559772 57.037666 \nL 137.089237 57.512974 \nL 138.618703 59.798485 \nL 140.148168 52.713389 \nL 141.677634 47.169496 \nL 143.207099 50.884977 \nL 144.736565 51.799177 \nL 146.26603 47.913804 \nL 147.795496 49.094993 \nL 149.324961 48.370916 \nL 150.854427 45.171193 \nL 152.383892 42.657119 \nL 153.913358 40.430266 \nL 155.442823 42.657119 \nL 156.972289 40.371608 \nL 158.501755 38.543197 \nL 160.03122 37.542015 \nL 161.560686 40.600158 \nL 163.090151 39.685959 \nL 164.619617 34.200724 \nL 167.678548 34.657824 \nL 169.208013 33.972175 \nL 170.737479 33.743612 \nL 172.266944 33.691036 \nL 173.79641 35.114924 \nL 175.325875 31.001001 \nL 176.855341 29.401139 \nL 178.384806 30.080732 \nL 179.914272 31.001001 \nL 182.973203 29.17259 \nL 184.502668 28.395912 \nL 186.032134 30.543901 \nL 187.561599 29.858239 \nL 189.091065 27.801278 \nL 192.149996 28.94404 \nL 193.679461 27.572728 \nL 195.208927 25.515767 \nL 196.738392 29.117978 \nL 198.267858 24.601554 \nL 199.797323 25.972866 \nL 201.326789 24.373005 \nL 202.856254 26.711104 \nL 204.38572 27.572728 \nL 205.915185 23.230256 \nL 207.444651 24.830117 \nL 208.974116 22.619436 \nL 210.503582 23.230256 \nL 212.033047 25.972866 \nL 213.562513 21.630394 \nL 215.091978 23.822867 \nL 216.621444 24.373005 \nL 218.150909 25.058667 \nL 219.680375 23.230256 \nL 221.20984 23.100801 \nL 222.739306 22.773143 \nL 224.268771 21.401844 \nL 225.798237 21.401844 \nL 227.327702 22.860125 \nL 228.857168 23.230256 \nL 230.386633 22.316043 \nL 231.916099 20.487632 \nL 233.445564 20.212563 \nL 234.97503 22.087493 \nL 238.033961 22.087493 \nL 239.563427 20.934629 \nL 241.092892 23.230256 \nL 242.622358 20.030532 \nL 244.151823 20.944731 \nL 245.681289 20.453251 \nL 247.210754 21.858944 \nL 248.74022 22.544593 \nL 250.269685 21.401844 \nL 251.799151 19.971874 \nL 253.328616 21.630394 \nL 254.858082 20.944731 \nL 256.387547 18.88777 \nL 259.446478 21.173294 \nL 260.975944 19.801982 \nL 262.505409 20.259082 \nL 264.034875 19.731186 \nL 265.56434 21.401844 \nL 267.093806 20.030532 \nL 268.623271 19.344883 \nL 270.152737 19.490497 \nL 271.682202 18.65922 \nL 273.211668 21.173294 \nL 274.741133 19.801982 \nL 276.270599 17.565001 \nL 277.800064 18.202121 \nL 279.32953 19.573433 \nL 280.858995 18.202121 \nL 282.388461 18.768444 \nL 283.917926 21.630394 \nL 285.447392 19.573433 \nL 286.976857 18.88777 \nL 288.506323 19.731186 \nL 290.035788 19.344883 \nL 291.565254 20.716182 \nL 293.094719 19.573433 \nL 294.624185 17.805689 \nL 296.15365 17.973571 \nL 297.683116 18.65922 \nL 299.212581 17.516471 \nL 300.742047 18.768444 \nL 302.271512 18.65922 \nL 303.800978 18.88777 \nL 305.330443 17.745021 \nL 306.859909 19.009133 \nL 308.389374 18.88777 \nL 309.91884 19.344883 \nL 311.448305 18.430671 \nL 312.977771 18.527755 \nL 314.507236 18.88777 \nL 316.036702 19.11632 \nL 317.566167 18.88777 \nL 319.095633 18.527755 \nL 320.625099 19.801982 \nL 322.154564 19.344883 \nL 323.68403 17.745021 \nL 325.213495 18.046378 \nL 326.742961 19.801982 \nL 328.272426 19.801982 \nL 329.801892 19.344883 \nL 331.331357 18.046378 \nL 332.860823 17.973571 \nL 334.390288 19.11632 \nL 335.919754 18.202121 \nL 337.449219 18.046378 \nL 338.978685 18.430671 \nL 340.50815 19.801982 \nL 342.037616 17.745021 \nL 343.567081 18.768444 \nL 345.096547 19.344883 \nL 346.626012 19.11632 \nL 348.155478 18.65922 \nL 349.684943 17.083636 \nL 349.684943 17.083636 \n\" style=\"fill:none;stroke:#ffed6f;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_16\">\n    <path clip-path=\"url(#p99b20d4d66)\" d=\"M 45.321307 200.620215 \nL 48.380238 193.676142 \nL 49.909703 193.676142 \nL 51.439169 187.889411 \nL 52.968634 187.889411 \nL 54.4981 189.046757 \nL 57.557031 189.046757 \nL 60.615962 186.732066 \nL 63.674893 182.102684 \nL 65.204358 178.630647 \nL 66.733824 176.315956 \nL 68.263289 175.158611 \nL 69.792755 175.158611 \nL 71.32222 171.686574 \nL 72.851686 171.686574 \nL 74.381151 168.214538 \nL 75.910617 167.057192 \nL 77.440083 163.585156 \nL 83.557945 154.326392 \nL 85.08741 143.910276 \nL 86.616876 141.595585 \nL 88.146341 140.438239 \nL 89.675807 138.123548 \nL 91.205272 136.966203 \nL 92.734738 131.179476 \nL 94.264203 130.02213 \nL 95.793669 131.179476 \nL 98.8526 124.235396 \nL 101.911531 121.920705 \nL 103.440996 119.606014 \nL 104.970462 116.133984 \nL 106.499927 116.133984 \nL 108.029393 113.819293 \nL 109.558858 110.34725 \nL 112.617789 108.032559 \nL 114.147255 104.560529 \nL 115.67672 99.931147 \nL 117.206186 96.459104 \nL 118.735651 94.144413 \nL 120.265117 92.987074 \nL 121.794582 86.043001 \nL 124.853513 86.043001 \nL 127.912444 83.72831 \nL 129.44191 77.941577 \nL 132.500841 80.256268 \nL 134.030306 79.098929 \nL 135.559772 75.626886 \nL 137.089237 75.626886 \nL 138.618703 76.784238 \nL 140.148168 74.469547 \nL 141.677634 73.312195 \nL 143.207099 74.469547 \nL 144.736565 74.469547 \nL 146.26603 72.154856 \nL 147.795496 70.997504 \nL 150.854427 70.997504 \nL 152.383892 72.154856 \nL 153.913358 69.840152 \nL 155.442823 70.997504 \nL 156.972289 70.997504 \nL 158.501755 68.682813 \nL 163.090151 68.682813 \nL 164.619617 67.525461 \nL 166.149082 67.525461 \nL 167.678548 65.21077 \nL 169.208013 64.053431 \nL 172.266944 66.368122 \nL 173.79641 65.21077 \nL 176.855341 65.21077 \nL 178.384806 62.896079 \nL 181.443737 60.581388 \nL 182.973203 61.73874 \nL 184.502668 60.581388 \nL 186.032134 61.73874 \nL 187.561599 60.581388 \nL 189.091065 60.581388 \nL 190.62053 59.424049 \nL 192.149996 60.581388 \nL 193.679461 60.581388 \nL 195.208927 59.424049 \nL 199.797323 59.424049 \nL 201.326789 58.266697 \nL 207.444651 58.266697 \nL 208.974116 57.109358 \nL 210.503582 57.109358 \nL 212.033047 58.266697 \nL 213.562513 55.952006 \nL 215.091978 57.109358 \nL 218.150909 57.109358 \nL 219.680375 55.952006 \nL 222.739306 55.952006 \nL 224.268771 54.794667 \nL 227.327702 57.109358 \nL 228.857168 57.109358 \nL 230.386633 55.952006 \nL 234.97503 55.952006 \nL 236.504495 54.794667 \nL 239.563427 54.794667 \nL 241.092892 57.109358 \nL 242.622358 55.952006 \nL 244.151823 57.109358 \nL 245.681289 54.794667 \nL 247.210754 53.637315 \nL 248.74022 54.794667 \nL 250.269685 54.794667 \nL 251.799151 53.637315 \nL 253.328616 53.637315 \nL 254.858082 54.794667 \nL 256.387547 53.637315 \nL 257.917013 53.637315 \nL 259.446478 54.794667 \nL 260.975944 54.794667 \nL 262.505409 53.637315 \nL 264.034875 54.794667 \nL 265.56434 53.637315 \nL 268.623271 53.637315 \nL 270.152737 54.794667 \nL 271.682202 54.794667 \nL 273.211668 53.637315 \nL 274.741133 53.637315 \nL 276.270599 52.479976 \nL 277.800064 53.637315 \nL 279.32953 52.479976 \nL 282.388461 52.479976 \nL 283.917926 53.637315 \nL 285.447392 50.165285 \nL 286.976857 50.165285 \nL 290.035788 52.479976 \nL 291.565254 52.479976 \nL 293.094719 54.794667 \nL 297.683116 51.322624 \nL 299.212581 51.322624 \nL 300.742047 50.165285 \nL 302.271512 53.637315 \nL 306.859909 53.637315 \nL 308.389374 51.322624 \nL 312.977771 51.322624 \nL 314.507236 52.479976 \nL 317.566167 52.479976 \nL 319.095633 51.322624 \nL 320.625099 52.479976 \nL 322.154564 52.479976 \nL 323.68403 51.322624 \nL 331.331357 51.322624 \nL 332.860823 52.479976 \nL 334.390288 51.322624 \nL 335.919754 52.479976 \nL 337.449219 51.322624 \nL 343.567081 51.322624 \nL 345.096547 50.165285 \nL 348.155478 50.165285 \nL 349.684943 51.322624 \nL 349.684943 51.322624 \n\" style=\"fill:none;stroke:#ccebc5;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 30.103125 224.64 \nL 30.103125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 364.903125 224.64 \nL 364.903125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 30.103125 224.64 \nL 364.903125 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 30.103125 7.2 \nL 364.903125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 37.103125 45.1125 \nL 130.10625 45.1125 \nQ 132.10625 45.1125 132.10625 43.1125 \nL 132.10625 14.2 \nQ 132.10625 12.2 130.10625 12.2 \nL 37.103125 12.2 \nQ 35.103125 12.2 35.103125 14.2 \nL 35.103125 43.1125 \nQ 35.103125 45.1125 37.103125 45.1125 \nz\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n    </g>\n    <g id=\"line2d_17\">\n     <path d=\"M 39.103125 20.298437 \nL 59.103125 20.298437 \n\" style=\"fill:none;stroke:#ffed6f;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_18\"/>\n    <g id=\"text_15\">\n     <!-- cat_ACC -->\n     <g transform=\"translate(67.103125 23.798437)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 3122 3366 \nL 3122 2828 \nQ 2878 2963 2633 3030 \nQ 2388 3097 2138 3097 \nQ 1578 3097 1268 2742 \nQ 959 2388 959 1747 \nQ 959 1106 1268 751 \nQ 1578 397 2138 397 \nQ 2388 397 2633 464 \nQ 2878 531 3122 666 \nL 3122 134 \nQ 2881 22 2623 -34 \nQ 2366 -91 2075 -91 \nQ 1284 -91 818 406 \nQ 353 903 353 1747 \nQ 353 2603 823 3093 \nQ 1294 3584 2113 3584 \nQ 2378 3584 2631 3529 \nQ 2884 3475 3122 3366 \nz\n\" id=\"DejaVuSans-63\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" id=\"DejaVuSans-61\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 1172 4494 \nL 1172 3500 \nL 2356 3500 \nL 2356 3053 \nL 1172 3053 \nL 1172 1153 \nQ 1172 725 1289 603 \nQ 1406 481 1766 481 \nL 2356 481 \nL 2356 0 \nL 1766 0 \nQ 1100 0 847 248 \nQ 594 497 594 1153 \nL 594 3053 \nL 172 3053 \nL 172 3500 \nL 594 3500 \nL 594 4494 \nL 1172 4494 \nz\n\" id=\"DejaVuSans-74\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 3263 -1063 \nL 3263 -1509 \nL -63 -1509 \nL -63 -1063 \nL 3263 -1063 \nz\n\" id=\"DejaVuSans-5f\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 2188 4044 \nL 1331 1722 \nL 3047 1722 \nL 2188 4044 \nz\nM 1831 4666 \nL 2547 4666 \nL 4325 0 \nL 3669 0 \nL 3244 1197 \nL 1141 1197 \nL 716 0 \nL 50 0 \nL 1831 4666 \nz\n\" id=\"DejaVuSans-41\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 4122 4306 \nL 4122 3641 \nQ 3803 3938 3442 4084 \nQ 3081 4231 2675 4231 \nQ 1875 4231 1450 3742 \nQ 1025 3253 1025 2328 \nQ 1025 1406 1450 917 \nQ 1875 428 2675 428 \nQ 3081 428 3442 575 \nQ 3803 722 4122 1019 \nL 4122 359 \nQ 3791 134 3420 21 \nQ 3050 -91 2638 -91 \nQ 1578 -91 968 557 \nQ 359 1206 359 2328 \nQ 359 3453 968 4101 \nQ 1578 4750 2638 4750 \nQ 3056 4750 3426 4639 \nQ 3797 4528 4122 4306 \nz\n\" id=\"DejaVuSans-43\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-63\"/>\n      <use x=\"54.980469\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"116.259766\" xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"155.46875\" xlink:href=\"#DejaVuSans-5f\"/>\n      <use x=\"205.46875\" xlink:href=\"#DejaVuSans-41\"/>\n      <use x=\"272.126953\" xlink:href=\"#DejaVuSans-43\"/>\n      <use x=\"341.951172\" xlink:href=\"#DejaVuSans-43\"/>\n     </g>\n    </g>\n    <g id=\"line2d_19\">\n     <path d=\"M 39.103125 35.254687 \nL 59.103125 35.254687 \n\" style=\"fill:none;stroke:#ccebc5;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_20\"/>\n    <g id=\"text_16\">\n     <!-- val_cat_ACC -->\n     <g transform=\"translate(67.103125 38.754687)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 191 3500 \nL 800 3500 \nL 1894 563 \nL 2988 3500 \nL 3597 3500 \nL 2284 0 \nL 1503 0 \nL 191 3500 \nz\n\" id=\"DejaVuSans-76\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 603 4863 \nL 1178 4863 \nL 1178 0 \nL 603 0 \nL 603 4863 \nz\n\" id=\"DejaVuSans-6c\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-76\"/>\n      <use x=\"59.179688\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"120.458984\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"148.242188\" xlink:href=\"#DejaVuSans-5f\"/>\n      <use x=\"198.242188\" xlink:href=\"#DejaVuSans-63\"/>\n      <use x=\"253.222656\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"314.501953\" xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"353.710938\" xlink:href=\"#DejaVuSans-5f\"/>\n      <use x=\"403.710938\" xlink:href=\"#DejaVuSans-41\"/>\n      <use x=\"470.369141\" xlink:href=\"#DejaVuSans-43\"/>\n      <use x=\"540.193359\" xlink:href=\"#DejaVuSans-43\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p99b20d4d66\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"30.103125\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 362.5625 248.518125\" width=\"362.5625pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2022-03-07T15:59:52.669420</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.4.3, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 248.518125 \nL 362.5625 248.518125 \nL 362.5625 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 20.5625 224.64 \nL 355.3625 224.64 \nL 355.3625 7.2 \nL 20.5625 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m4038be44e4\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"35.780682\" xlink:href=\"#m4038be44e4\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(32.599432 239.238438)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" id=\"DejaVuSans-30\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"74.01732\" xlink:href=\"#m4038be44e4\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 25 -->\n      <g transform=\"translate(67.65482 239.238438)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" id=\"DejaVuSans-32\" transform=\"scale(0.015625)\"/>\n        <path d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" id=\"DejaVuSans-35\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"112.253957\" xlink:href=\"#m4038be44e4\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 50 -->\n      <g transform=\"translate(105.891457 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-35\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"150.490595\" xlink:href=\"#m4038be44e4\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 75 -->\n      <g transform=\"translate(144.128095 239.238438)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 525 4666 \nL 3525 4666 \nL 3525 4397 \nL 1831 0 \nL 1172 0 \nL 2766 4134 \nL 525 4134 \nL 525 4666 \nz\n\" id=\"DejaVuSans-37\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-37\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"188.727233\" xlink:href=\"#m4038be44e4\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 100 -->\n      <g transform=\"translate(179.183483 239.238438)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" id=\"DejaVuSans-31\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"226.96387\" xlink:href=\"#m4038be44e4\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 125 -->\n      <g transform=\"translate(217.42012 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-32\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"265.200508\" xlink:href=\"#m4038be44e4\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 150 -->\n      <g transform=\"translate(255.656758 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"303.437146\" xlink:href=\"#m4038be44e4\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 175 -->\n      <g transform=\"translate(293.893396 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-37\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_9\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"341.673784\" xlink:href=\"#m4038be44e4\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 200 -->\n      <g transform=\"translate(332.130034 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_10\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m991895a247\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"20.5625\" xlink:href=\"#m991895a247\" y=\"213.438669\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 1 -->\n      <g transform=\"translate(7.2 217.237888)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"20.5625\" xlink:href=\"#m991895a247\" y=\"185.345602\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 2 -->\n      <g transform=\"translate(7.2 189.144821)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"20.5625\" xlink:href=\"#m991895a247\" y=\"157.252535\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 3 -->\n      <g transform=\"translate(7.2 161.051754)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 2597 2516 \nQ 3050 2419 3304 2112 \nQ 3559 1806 3559 1356 \nQ 3559 666 3084 287 \nQ 2609 -91 1734 -91 \nQ 1441 -91 1130 -33 \nQ 819 25 488 141 \nL 488 750 \nQ 750 597 1062 519 \nQ 1375 441 1716 441 \nQ 2309 441 2620 675 \nQ 2931 909 2931 1356 \nQ 2931 1769 2642 2001 \nQ 2353 2234 1838 2234 \nL 1294 2234 \nL 1294 2753 \nL 1863 2753 \nQ 2328 2753 2575 2939 \nQ 2822 3125 2822 3475 \nQ 2822 3834 2567 4026 \nQ 2313 4219 1838 4219 \nQ 1578 4219 1281 4162 \nQ 984 4106 628 3988 \nL 628 4550 \nQ 988 4650 1302 4700 \nQ 1616 4750 1894 4750 \nQ 2613 4750 3031 4423 \nQ 3450 4097 3450 3541 \nQ 3450 3153 3228 2886 \nQ 3006 2619 2597 2516 \nz\n\" id=\"DejaVuSans-33\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-33\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"20.5625\" xlink:href=\"#m991895a247\" y=\"129.159468\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 4 -->\n      <g transform=\"translate(7.2 132.958687)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" id=\"DejaVuSans-34\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-34\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"20.5625\" xlink:href=\"#m991895a247\" y=\"101.066401\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 5 -->\n      <g transform=\"translate(7.2 104.86562)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_15\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"20.5625\" xlink:href=\"#m991895a247\" y=\"72.973334\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 6 -->\n      <g transform=\"translate(7.2 76.772553)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" id=\"DejaVuSans-36\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-36\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_16\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"20.5625\" xlink:href=\"#m991895a247\" y=\"44.880267\"/>\n      </g>\n     </g>\n     <g id=\"text_16\">\n      <!-- 7 -->\n      <g transform=\"translate(7.2 48.679486)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-37\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_17\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"20.5625\" xlink:href=\"#m991895a247\" y=\"16.7872\"/>\n      </g>\n     </g>\n     <g id=\"text_17\">\n      <!-- 8 -->\n      <g transform=\"translate(7.2 20.586419)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" id=\"DejaVuSans-38\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-38\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_18\">\n    <path clip-path=\"url(#pb6df0567b4)\" d=\"M 35.780682 17.083636 \nL 37.310147 24.837966 \nL 38.839613 30.335021 \nL 40.369078 34.999699 \nL 41.898544 40.625742 \nL 43.428009 45.74904 \nL 44.957475 50.280671 \nL 46.48694 55.621383 \nL 48.016406 59.485902 \nL 51.075337 68.619921 \nL 52.604802 73.279415 \nL 54.134268 76.584164 \nL 55.663733 80.720082 \nL 57.193199 84.25185 \nL 58.722664 88.841846 \nL 60.25213 91.108338 \nL 61.781595 94.691157 \nL 63.311061 97.964318 \nL 64.840526 101.876111 \nL 66.369992 104.14618 \nL 67.899458 106.967701 \nL 69.428923 110.081693 \nL 70.958389 114.367069 \nL 72.487854 115.755813 \nL 75.546785 120.326989 \nL 77.076251 125.521217 \nL 78.605716 126.628556 \nL 80.135182 128.57955 \nL 81.664647 130.85576 \nL 83.194113 135.816446 \nL 84.723578 135.853626 \nL 86.253044 137.945189 \nL 87.782509 140.248587 \nL 89.311975 145.419192 \nL 90.84144 145.19165 \nL 92.370906 147.075879 \nL 93.900371 149.14631 \nL 95.429837 153.474204 \nL 96.959302 152.320777 \nL 100.018233 155.961841 \nL 101.547699 160.169702 \nL 103.077164 159.580212 \nL 104.60663 161.321361 \nL 106.136095 162.868404 \nL 107.665561 166.381464 \nL 109.195026 165.524942 \nL 110.724492 166.766044 \nL 112.253957 168.544875 \nL 113.783423 171.448084 \nL 115.312888 170.403732 \nL 118.371819 173.381127 \nL 119.901285 175.924718 \nL 122.960216 175.809822 \nL 124.489681 177.600917 \nL 126.019147 180.175385 \nL 127.548612 179.371409 \nL 129.078078 179.04374 \nL 130.607543 181.334693 \nL 132.137009 183.3513 \nL 133.666474 182.572346 \nL 135.19594 182.939787 \nL 138.254871 185.344437 \nL 139.784336 185.345947 \nL 141.313802 185.910828 \nL 142.843267 186.686838 \nL 144.372733 188.443428 \nL 145.902198 187.675741 \nL 147.431664 188.387099 \nL 150.490595 190.808691 \nL 152.020061 190.042581 \nL 153.549526 189.999396 \nL 155.078992 191.734051 \nL 156.608457 192.200393 \nL 158.137923 191.830832 \nL 159.667388 192.320798 \nL 161.196854 193.010572 \nL 162.726319 193.943339 \nL 164.255785 193.652714 \nL 168.844181 195.447017 \nL 171.903112 195.444599 \nL 173.432578 196.246931 \nL 174.962043 196.794529 \nL 178.020974 196.571415 \nL 179.55044 197.006672 \nL 181.079905 197.887263 \nL 182.609371 197.432729 \nL 184.138836 197.984496 \nL 185.668302 198.661464 \nL 187.197767 198.935727 \nL 190.256698 198.894625 \nL 191.786164 199.764995 \nL 193.315629 199.928564 \nL 194.845095 199.595427 \nL 196.37456 200.175674 \nL 197.904026 200.597113 \nL 199.433491 201.520811 \nL 200.962957 200.832849 \nL 202.492422 200.684497 \nL 204.021888 201.805362 \nL 205.551353 201.844628 \nL 207.080819 201.649806 \nL 210.13975 202.399383 \nL 211.669215 202.821405 \nL 213.198681 202.618036 \nL 216.257612 202.98184 \nL 217.787077 203.655817 \nL 219.316543 203.186424 \nL 220.846008 203.293982 \nL 222.375474 204.396096 \nL 223.904939 204.648661 \nL 225.434405 204.155508 \nL 226.96387 203.9374 \nL 228.493336 204.665798 \nL 230.022802 205.092692 \nL 231.552267 204.796899 \nL 233.081733 205.397544 \nL 234.611198 205.451707 \nL 236.140664 205.899382 \nL 237.670129 205.401804 \nL 239.199595 205.494276 \nL 242.258526 206.298078 \nL 243.787991 206.091642 \nL 248.376388 207.098559 \nL 249.905853 207.0595 \nL 252.964784 207.20028 \nL 254.49425 207.66702 \nL 257.553181 207.469861 \nL 259.082646 208.115522 \nL 260.612112 208.42011 \nL 262.141577 208.508773 \nL 263.671043 208.043011 \nL 265.200508 208.546724 \nL 266.729974 209.285061 \nL 268.259439 208.913428 \nL 269.788905 208.744804 \nL 271.31837 209.296009 \nL 272.847836 209.402345 \nL 274.377301 209.06909 \nL 275.906767 209.030882 \nL 278.965698 210.077146 \nL 280.495163 209.834336 \nL 282.024629 209.744749 \nL 283.554094 210.112795 \nL 285.08356 210.799304 \nL 286.613025 210.666789 \nL 289.671956 210.939183 \nL 292.730887 210.985191 \nL 294.260353 211.368081 \nL 297.319284 211.481942 \nL 300.378215 211.365927 \nL 303.437146 212.200815 \nL 304.966611 211.824269 \nL 306.496077 211.932945 \nL 308.025542 212.330195 \nL 309.555008 212.54983 \nL 311.084474 212.322151 \nL 312.613939 212.452134 \nL 314.143405 212.970277 \nL 315.67287 212.989507 \nL 317.202336 212.594056 \nL 318.731801 212.738952 \nL 320.261267 213.187293 \nL 321.790732 213.464089 \nL 323.320198 213.23314 \nL 324.849663 213.269443 \nL 327.908594 213.986149 \nL 330.967525 213.684013 \nL 332.496991 214.052785 \nL 334.026456 213.985125 \nL 335.555922 213.736577 \nL 337.085387 214.016092 \nL 338.614853 214.467366 \nL 340.144318 214.756364 \nL 340.144318 214.756364 \n\" style=\"fill:none;stroke:#ffed6f;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_19\">\n    <path clip-path=\"url(#pb6df0567b4)\" d=\"M 35.780682 23.510736 \nL 38.839613 34.623531 \nL 41.898544 44.980508 \nL 44.957475 54.594861 \nL 48.016406 63.604594 \nL 51.075337 72.019217 \nL 54.134268 79.900419 \nL 57.193199 87.207865 \nL 61.781595 97.355317 \nL 66.369992 106.624273 \nL 69.428923 112.408051 \nL 74.01732 120.662367 \nL 80.135182 130.74783 \nL 84.723578 137.614044 \nL 87.782509 141.843238 \nL 92.370906 147.702475 \nL 95.429837 151.167665 \nL 98.488768 154.453907 \nL 103.077164 158.791929 \nL 106.136095 161.396304 \nL 110.724492 165.027441 \nL 113.783423 166.976794 \nL 116.842354 168.874961 \nL 124.489681 173.137129 \nL 129.078078 175.18403 \nL 133.666474 177.040851 \nL 136.725405 178.245135 \nL 139.784336 179.275381 \nL 142.843267 180.429082 \nL 152.020061 182.8341 \nL 158.137923 184.236991 \nL 159.667388 184.681853 \nL 162.726319 185.186125 \nL 165.78525 186.023765 \nL 168.844181 186.453272 \nL 173.432578 187.250725 \nL 174.962043 187.290229 \nL 179.55044 188.226369 \nL 182.609371 188.703344 \nL 184.138836 188.799134 \nL 188.727233 189.674276 \nL 191.786164 189.955281 \nL 194.845095 190.432028 \nL 196.37456 190.526163 \nL 199.433491 191.145522 \nL 200.962957 191.187927 \nL 204.021888 191.729644 \nL 207.080819 191.853826 \nL 211.669215 192.492328 \nL 214.728146 192.81865 \nL 219.316543 193.405152 \nL 222.375474 193.708712 \nL 226.96387 194.292019 \nL 228.493336 194.499387 \nL 231.552267 194.709018 \nL 237.670129 195.387104 \nL 240.72906 195.590509 \nL 242.258526 195.939477 \nL 245.317457 196.129731 \nL 257.553181 197.271135 \nL 259.082646 197.487967 \nL 260.612112 197.521306 \nL 262.141577 197.699071 \nL 263.671043 198.017858 \nL 265.200508 198.162788 \nL 268.259439 198.297362 \nL 271.31837 198.443778 \nL 277.436232 199.23512 \nL 282.024629 199.480066 \nL 283.554094 199.665789 \nL 285.08356 199.738715 \nL 286.613025 199.67888 \nL 291.201422 200.244026 \nL 297.319284 200.857069 \nL 300.378215 201.199131 \nL 306.496077 201.535339 \nL 309.555008 201.918332 \nL 312.613939 202.105807 \nL 314.143405 202.367725 \nL 315.67287 202.513656 \nL 320.261267 202.687935 \nL 335.555922 203.744155 \nL 337.085387 203.701148 \nL 338.614853 203.806158 \nL 340.144318 204.02601 \nL 340.144318 204.02601 \n\" style=\"fill:none;stroke:#ccebc5;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 20.5625 224.64 \nL 20.5625 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 355.3625 224.64 \nL 355.3625 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 20.5625 224.64 \nL 355.3625 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 20.5625 7.2 \nL 355.3625 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 277.221875 44.834375 \nL 348.3625 44.834375 \nQ 350.3625 44.834375 350.3625 42.834375 \nL 350.3625 14.2 \nQ 350.3625 12.2 348.3625 12.2 \nL 277.221875 12.2 \nQ 275.221875 12.2 275.221875 14.2 \nL 275.221875 42.834375 \nQ 275.221875 44.834375 277.221875 44.834375 \nz\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n    </g>\n    <g id=\"line2d_20\">\n     <path d=\"M 279.221875 20.298437 \nL 299.221875 20.298437 \n\" style=\"fill:none;stroke:#ffed6f;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_21\"/>\n    <g id=\"text_18\">\n     <!-- loss -->\n     <g transform=\"translate(307.221875 23.798437)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 603 4863 \nL 1178 4863 \nL 1178 0 \nL 603 0 \nL 603 4863 \nz\n\" id=\"DejaVuSans-6c\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" id=\"DejaVuSans-6f\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 2834 3397 \nL 2834 2853 \nQ 2591 2978 2328 3040 \nQ 2066 3103 1784 3103 \nQ 1356 3103 1142 2972 \nQ 928 2841 928 2578 \nQ 928 2378 1081 2264 \nQ 1234 2150 1697 2047 \nL 1894 2003 \nQ 2506 1872 2764 1633 \nQ 3022 1394 3022 966 \nQ 3022 478 2636 193 \nQ 2250 -91 1575 -91 \nQ 1294 -91 989 -36 \nQ 684 19 347 128 \nL 347 722 \nQ 666 556 975 473 \nQ 1284 391 1588 391 \nQ 1994 391 2212 530 \nQ 2431 669 2431 922 \nQ 2431 1156 2273 1281 \nQ 2116 1406 1581 1522 \nL 1381 1569 \nQ 847 1681 609 1914 \nQ 372 2147 372 2553 \nQ 372 3047 722 3315 \nQ 1072 3584 1716 3584 \nQ 2034 3584 2315 3537 \nQ 2597 3491 2834 3397 \nz\n\" id=\"DejaVuSans-73\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"27.783203\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"88.964844\" xlink:href=\"#DejaVuSans-73\"/>\n      <use x=\"141.064453\" xlink:href=\"#DejaVuSans-73\"/>\n     </g>\n    </g>\n    <g id=\"line2d_22\">\n     <path d=\"M 279.221875 34.976562 \nL 299.221875 34.976562 \n\" style=\"fill:none;stroke:#ccebc5;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_23\"/>\n    <g id=\"text_19\">\n     <!-- val_loss -->\n     <g transform=\"translate(307.221875 38.476562)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 191 3500 \nL 800 3500 \nL 1894 563 \nL 2988 3500 \nL 3597 3500 \nL 2284 0 \nL 1503 0 \nL 191 3500 \nz\n\" id=\"DejaVuSans-76\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" id=\"DejaVuSans-61\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 3263 -1063 \nL 3263 -1509 \nL -63 -1509 \nL -63 -1063 \nL 3263 -1063 \nz\n\" id=\"DejaVuSans-5f\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-76\"/>\n      <use x=\"59.179688\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"120.458984\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"148.242188\" xlink:href=\"#DejaVuSans-5f\"/>\n      <use x=\"198.242188\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"226.025391\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"287.207031\" xlink:href=\"#DejaVuSans-73\"/>\n      <use x=\"339.306641\" xlink:href=\"#DejaVuSans-73\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pb6df0567b4\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"20.5625\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "km = kmd.build()\n",
    "\n",
    "optimizer=\"adam\"\n",
    "learn_rate=3e-4\n",
    "params = {\"optimizer\": tf.optimizers.get(optimizer).from_config({\"learning_rate\":learn_rate})}\n",
    "params.setdefault(\"loss\", tf.nn.softmax_cross_entropy_with_logits)\n",
    "params.setdefault(\"metrics\", tf.keras.metrics.CategoricalAccuracy(name=\"cat_ACC\"))\n",
    "\n",
    "km.compile(optimizer=params[\"optimizer\"],\n",
    "                loss=params[\"loss\"],\n",
    "                metrics=params[\"metrics\"])\n",
    "\n",
    "import mneflow\n",
    "import_opt = dict(savepath='../tfr/',\n",
    "                  out_name='mne_sample_epochs',\n",
    "                  fs=600,\n",
    "                  input_type='trials',\n",
    "                  target_type='int',\n",
    "                  picks={'meg':'grad'},\n",
    "                  scale=True,  # apply baseline_scaling\n",
    "                  crop_baseline=True,  # remove baseline interval after scaling\n",
    "                  decimate=None,\n",
    "                  scale_interval=(0, 60),  # indices in time axis corresponding to baseline interval\n",
    "                #   n_folds=5,  # validation set size set to 20% of all data\n",
    "                  n_folds=5,\n",
    "                  overwrite=True,\n",
    "                  segment=False,\n",
    "                #   test_set='holdout'\n",
    ")\n",
    "\n",
    "\n",
    "#write TFRecord files and metadata file to disk\n",
    "meta = mneflow.produce_tfrecords((original_X, original_Y), **import_opt)  \n",
    "dataset = mneflow.Dataset(meta, train_batch=100)\n",
    "\n",
    "train_size = dataset.h_params['train_size']\n",
    "eval_step = train_size // dataset.h_params['train_batch'] + 1\n",
    "min_delta=1e-6\n",
    "early_stopping=3\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                      min_delta=min_delta,\n",
    "                                                      patience=early_stopping,\n",
    "                                                      restore_best_weights=True)\n",
    "\n",
    "km.fit(dataset.train,\n",
    "      validation_data=dataset.val,\n",
    "      epochs=200, steps_per_epoch=eval_step,\n",
    "      shuffle=True, \n",
    "      validation_steps=dataset.validation_steps,\n",
    "      callbacks=[stop_early], verbose=2)\n",
    "\n",
    "ma = ModelAnalyzer(km)\n",
    "ma.plot_metrics(['cat_ACC', 'val_cat_ACC'])\n",
    "ma.plot_metrics(['loss', 'val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val acc 0.125531914893617\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as sm\n",
    "from utils.machine_learning import one_hot_decoder\n",
    "from utils.machine_learning.confusion import ConfusionEstimator\n",
    "\n",
    "y_p_val = km(X).numpy()\n",
    "\n",
    "print(\n",
    "    'val acc',\n",
    "    sm.accuracy_score(\n",
    "        one_hot_decoder(Y),\n",
    "        one_hot_decoder(y_p_val),\n",
    "    )\n",
    ")\n",
    "\n",
    "# tn, fp, fn, tp = sm.confusion_matrix(one_hot_decoder(y_t_val), one_hot_decoder(y_p_val)).ravel()\n",
    "# ce = ConfusionEstimator(tp, tn, fp, fn)\n",
    "\n",
    "# print(\n",
    "#     f'\\tT\\tF\\n'\\\n",
    "#     f'P\\t{tp}\\t{fp}\\n'\\\n",
    "#     f'N\\t{tn}\\t{fn}\\n'\n",
    "#     f'Accuracy: {ce.acc}\\n'\\\n",
    "#     f'Specificity: {ce.spec}\\n'\\\n",
    "#     f'Sensitivity: {ce.sens}'\n",
    "# )\n",
    "# y_t_train, y_p_train = km.predict(dataset.train)\n",
    "\n",
    "# print(\n",
    "#     'train acc',\n",
    "#     sm.accuracy_score(\n",
    "#         one_hot_decoder(y_t_train),\n",
    "#         one_hot_decoder(y_p_train),\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# tn, fp, fn, tp = sm.confusion_matrix(one_hot_decoder(y_t_train), one_hot_decoder(y_p_train)).ravel()\n",
    "# ce = ConfusionEstimator(tp, tn, fp, fn)\n",
    "\n",
    "# print(\n",
    "#     f'\\tT\\tF\\n'\\\n",
    "#     f'P\\t{tp}\\t{fp}\\n'\\\n",
    "#     f'N\\t{tn}\\t{fn}\\n'\n",
    "#     f'Accuracy: {ce.acc}\\n'\\\n",
    "#     f'Specificity: {ce.spec}\\n'\\\n",
    "#     f'Sensitivity: {ce.sens}'\n",
    "# )\n",
    "\n",
    "# y_t = np.concatenate([y_t_val, y_t_train], axis=0)\n",
    "# y_p = np.concatenate([y_p_val, y_p_train], axis=0)\n",
    "\n",
    "\n",
    "# print(\n",
    "#     'total acc',\n",
    "#     sm.accuracy_score(\n",
    "#         one_hot_decoder(y_t),\n",
    "#         one_hot_decoder(y_p),\n",
    "#     )\n",
    "# )\n",
    "# tn, fp, fn, tp = sm.confusion_matrix(one_hot_decoder(y_t), one_hot_decoder(y_p)).ravel()\n",
    "# ce = ConfusionEstimator(tp, tn, fp, fn)\n",
    "\n",
    "# print(\n",
    "#     f'\\tT\\tF\\n'\\\n",
    "#     f'P\\t{tp}\\t{fp}\\n'\\\n",
    "#     f'N\\t{tn}\\t{fn}\\n'\n",
    "#     f'Accuracy: {ce.acc}\\n'\\\n",
    "#     f'Specificity: {ce.spec}\\n'\\\n",
    "#     f'Sensitivity: {ce.sens}'\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 2.8302 - cat_ACC: 0.2074 - val_loss: 2.9959 - val_cat_ACC: 0.0000e+00\n",
      "Epoch 2/25\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 2.7189 - cat_ACC: 0.2181 - val_loss: 3.1969 - val_cat_ACC: 0.0000e+00\n",
      "Epoch 3/25\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 2.6102 - cat_ACC: 0.2039 - val_loss: 3.4478 - val_cat_ACC: 0.0000e+00\n",
      "Epoch 4/25\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 2.5197 - cat_ACC: 0.2447 - val_loss: 3.6942 - val_cat_ACC: 0.0000e+00\n",
      "Epoch 5/25\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 2.4592 - cat_ACC: 0.2553 - val_loss: 3.9114 - val_cat_ACC: 0.0000e+00\n",
      "Epoch 6/25\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 2.4171 - cat_ACC: 0.2163 - val_loss: 4.0860 - val_cat_ACC: 0.0000e+00\n",
      "Epoch 7/25\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 2.3745 - cat_ACC: 0.2128 - val_loss: 4.2153 - val_cat_ACC: 0.0000e+00\n",
      "Epoch 8/25\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 2.3502 - cat_ACC: 0.2270 - val_loss: 4.3007 - val_cat_ACC: 0.0000e+00\n",
      "Epoch 9/25\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 2.3146 - cat_ACC: 0.2287 - val_loss: 4.3594 - val_cat_ACC: 0.0000e+00\n",
      "Epoch 10/25\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 2.2837 - cat_ACC: 0.2411 - val_loss: 4.3918 - val_cat_ACC: 0.0000e+00\n",
      "Epoch 11/25\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 2.2613 - cat_ACC: 0.2323 - val_loss: 4.4073 - val_cat_ACC: 0.0000e+00\n",
      "Epoch 12/25\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 2.2341 - cat_ACC: 0.2270 - val_loss: 4.4153 - val_cat_ACC: 0.0000e+00\n",
      "Epoch 13/25\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 2.2044 - cat_ACC: 0.2624 - val_loss: 4.4106 - val_cat_ACC: 0.0000e+00\n",
      "Epoch 14/25\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 2.1880 - cat_ACC: 0.2128 - val_loss: 4.4084 - val_cat_ACC: 0.0000e+00\n",
      "Epoch 15/25\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 2.1663 - cat_ACC: 0.2145 - val_loss: 4.4019 - val_cat_ACC: 0.0000e+00\n",
      "Epoch 16/25\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 2.1348 - cat_ACC: 0.2287 - val_loss: 4.3983 - val_cat_ACC: 0.0000e+00\n",
      "Epoch 17/25\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 2.1169 - cat_ACC: 0.2340 - val_loss: 4.3896 - val_cat_ACC: 0.0000e+00\n",
      "Epoch 18/25\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 2.0963 - cat_ACC: 0.2110 - val_loss: 4.3778 - val_cat_ACC: 0.0000e+00\n",
      "Epoch 19/25\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 2.0756 - cat_ACC: 0.2376 - val_loss: 4.3672 - val_cat_ACC: 0.0000e+00\n",
      "Epoch 20/25\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 2.0587 - cat_ACC: 0.2092 - val_loss: 4.3492 - val_cat_ACC: 0.0000e+00\n",
      "Epoch 21/25\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 2.0370 - cat_ACC: 0.2553 - val_loss: 4.3376 - val_cat_ACC: 0.0000e+00\n",
      "Epoch 22/25\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 2.0260 - cat_ACC: 0.2270 - val_loss: 4.3208 - val_cat_ACC: 0.0000e+00\n",
      "Epoch 23/25\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 2.0085 - cat_ACC: 0.2145 - val_loss: 4.3047 - val_cat_ACC: 0.0000e+00\n",
      "Epoch 24/25\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 1.9940 - cat_ACC: 0.2252 - val_loss: 4.2933 - val_cat_ACC: 0.0000e+00\n",
      "Epoch 25/25\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 1.9772 - cat_ACC: 0.2216 - val_loss: 4.2793 - val_cat_ACC: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdab2ef9df0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km.fit(\n",
    "    X,\n",
    "    Y,\n",
    "    epochs=25,\n",
    "    validation_split=0.4,\n",
    "    shuffle=True,\n",
    "    batch_size=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset element_spec=(TensorSpec(shape=(None, 1, 361, 204), dtype=tf.float32, name=None), TensorSpec(shape=(None, 8), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(dataset.train.as_numpy_iterator())\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "25b6c1d617e3cb25e4067864bcd46322e1b7da41afdae0cf7c23b941b0b9b767"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
